/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:19:43 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:20:25 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 21:21:39 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 21:23:00 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 21:24:11 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 21:25:23 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 380.15345644950867 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:26:44 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 21:27:56 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 21:29:18 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 21:30:30 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 21:31:41 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 379.6656186580658 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:33:04 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 21:34:15 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 21:35:38 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 21:36:52 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 21:38:07 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 386.45685052871704 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:39:29 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 21:40:40 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 21:42:05 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 21:43:20 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 21:44:31 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 381.90104722976685 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:45:52 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 21:47:04 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 21:48:24 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 21:49:34 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 21:50:44 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 373.5944468975067 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:05 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 21:53:15 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 21:54:35 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 21:55:46 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 21:56:59 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 376.02813696861267 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:58:21 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 21:59:32 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:00:54 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:02:06 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 22:03:17 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 376.82175159454346 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:04:39 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 22:05:53 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:07:15 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:08:30 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 22:09:41 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 384.71511220932007 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:11:03 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 22:12:14 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:13:34 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:14:47 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 22:15:58 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 378.02872014045715 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:17:21 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 22:18:32 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:19:57 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:21:08 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 22:22:19 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 379.8547830581665 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:23:41 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 22:24:51 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:26:12 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:27:24 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 22:28:36 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 377.152379989624 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:29:58 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 22:31:10 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:32:32 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:33:42 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 22:34:53 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 378.9676616191864 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:36:17 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 22:37:28 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:38:51 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:40:04 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 22:41:14 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 382.50693798065186 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:42:40 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 22:43:53 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:45:20 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:46:33 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 22:47:45 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 387.59094500541687 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:49:07 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 22:50:21 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:51:45 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:52:57 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 22:54:09 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 383.4247009754181 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:55:30 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 22:56:43 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:58:06 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:59:17 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 23:00:29 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 380.95276284217834 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:01:51 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 23:03:04 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:04:26 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:05:40 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 23:06:52 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 382.26507592201233 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:08:13 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 23:09:24 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:10:50 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:12:03 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 23:13:15 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 383.320011138916 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:14:37 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 23:15:49 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:17:12 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:18:26 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 23:19:38 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 383.98314666748047 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:21:03 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 23:22:17 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:23:40 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:24:53 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 23:26:05 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 386.66891837120056 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:27:28 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 23:28:38 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:30:04 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:31:15 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 23:32:27 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 381.9542624950409 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:33:49 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 23:35:03 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:36:30 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:37:41 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 23:38:54 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 386.60304260253906 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:40:18 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 23:41:31 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:42:53 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:44:06 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 23:45:20 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 386.56368231773376 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:46:44 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 23:47:58 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:49:22 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:50:34 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 23:51:45 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 384.6955888271332 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:53:09 2024]  Iteration number: 0 with current cost as 0.23406141329689656 and parameters 
[-1.63616705  2.2374346  -2.12427964 -0.11653105  0.55388706 -2.77010901
  3.06858494  2.18960143  1.18551998 -1.06648312]. 
Working on 0.4 fold... 
[Thu Apr  4 23:54:22 2024]  Iteration number: 0 with current cost as 0.2863878789566188 and parameters 
[-1.73704301  2.23743466 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:55:47 2024]  Iteration number: 0 with current cost as 0.2408600749914852 and parameters 
[-1.68710712  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:56:58 2024]  Iteration number: 0 with current cost as 0.2741586743573372 and parameters 
[-1.65148662  2.23743462 -2.12427962 -0.11653105  0.55388708 -2.77010901
  3.06858496  2.18960145  1.18551998 -1.06648313]. 
Working on 1.0 fold... 
[Thu Apr  4 23:58:11 2024]  Iteration number: 0 with current cost as 0.2752326878922806 and parameters 
[-1.70282185  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858496  2.18960147  1.18551998 -1.06648311]. 
Training complete taking 385.79276514053345 seconds. 
Discarding model... 

Training complete taking 9549.6626162529 total seconds. 
Now scoring model... 
Scoring complete taking 1.9064409732818604 seconds. 
Saved predicted values as M_ESU2_predicted_values.csv
Model scores: {'MSE_train': (0.43748237853426597,), 'R2_train': 0.12886959318967328, 'MAE_train': 0.5706732372370578, 'MSE_test': 0.42926183110804894, 'R2_test': 0.1994417304486713, 'MAE_test': 0.5867220795407111}. 
Saved model results as M_ESU2_results.json. 
