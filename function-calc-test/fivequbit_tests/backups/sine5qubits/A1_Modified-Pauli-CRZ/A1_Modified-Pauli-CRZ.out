/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:38 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:59 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:38:42 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:39:35 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:40:05 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:40:47 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 213.64508414268494 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:41:32 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:42:15 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:43:09 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:43:38 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:44:23 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 213.32920098304749 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:45:06 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:45:51 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:46:43 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:47:12 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:47:57 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 216.14111042022705 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:48:40 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:49:24 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:50:17 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:50:46 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:51:33 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 216.08592438697815 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:16 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:53:00 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:53:54 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:54:23 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:55:06 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 213.44610214233398 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:55:51 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:56:34 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:57:28 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:57:57 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:58:40 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 215.23827862739563 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:59:27 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:00:09 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:01:03 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:01:32 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:02:15 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 213.7627091407776 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:03:00 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:03:43 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:04:37 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:05:06 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:05:50 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 222.24410390853882 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:06:40 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:07:25 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:08:17 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:08:46 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:09:32 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 214.72572541236877 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:10:15 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:10:59 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:11:53 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:12:22 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:13:06 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 213.7538502216339 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:13:49 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:14:34 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:15:27 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:15:56 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:16:39 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 215.11346912384033 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:17:28 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:18:10 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:19:04 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:19:33 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:20:17 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 216.44915056228638 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:21:02 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:21:45 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:22:39 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:23:09 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:23:54 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 214.64685726165771 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:24:37 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:25:20 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:26:14 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:26:43 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:27:27 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 213.57357740402222 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:28:10 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:28:55 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:29:47 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:30:16 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:31:02 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 216.15936636924744 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:31:45 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:32:32 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:33:26 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:33:56 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:34:39 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 217.7346179485321 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:35:24 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:36:07 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:37:02 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:37:31 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:38:16 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 216.15075278282166 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:39:00 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:39:43 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:40:37 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:41:06 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:41:49 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 213.5858211517334 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:42:35 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:43:18 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:44:12 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:44:41 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:45:26 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 214.9910433292389 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:46:09 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:46:54 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:47:46 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:48:15 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:49:00 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 215.7752332687378 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:49:43 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:50:27 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:51:20 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:51:50 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:52:35 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 214.47949409484863 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:53:18 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:54:02 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:54:56 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:55:26 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:56:09 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 214.16001653671265 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:56:52 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:57:48 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:58:41 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:59:10 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:59:55 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 224.73208928108215 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:00:38 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:01:21 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:02:15 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:02:44 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:03:32 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 218.33630990982056 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:04:15 2024]  Iteration number: 0 with current cost as 0.327102041616976 and parameters 
[-1.76826899  2.23743464 -2.12427959 -0.11653098  0.55388713 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:04:59 2024]  Iteration number: 0 with current cost as 0.3293175096829455 and parameters 
[-1.81187896  2.23743464 -2.12427953 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.1896015   1.18552004 -1.06648308  0.60271513  1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:05:57 2024]  Iteration number: 0 with current cost as 0.30292187129097725 and parameters 
[-1.61224     2.2374346  -2.12427961 -0.116531    0.55388711 -2.770109
  3.06858501  2.18960145  1.18552001 -1.06648312  0.6027151   1.14432445
  1.31029895 -1.87354674  0.72965074  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:06:26 2024]  Iteration number: 0 with current cost as 0.31411556519087475 and parameters 
[-1.73764244  2.23743464 -2.12427956 -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18552004 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354675  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:07:10 2024]  Iteration number: 0 with current cost as 0.3277804633357756 and parameters 
[-1.79022484  2.23743459 -2.12427961 -0.116531    0.55388708 -2.770109
  3.06858498  2.18960145  1.18552001 -1.06648316  0.60271508  1.14432448
  1.31029899 -1.87354678  0.72965075  2.88578414 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 218.62824654579163 seconds. 
Discarding model... 

Training complete taking 5396.889376401901 total seconds. 
Now scoring model... 
Scoring complete taking 0.7252848148345947 seconds. 
Saved predicted values as A1_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (0.5020917393304167,), 'R2_train': 0.00021714564955466198, 'MAE_train': 0.6187141090668566, 'MSE_test': 0.574227248650512, 'R2_test': -0.07091369228484545, 'MAE_test': 0.6784097616781415}. 
Saved model results as A1_Modified-Pauli-CRZ_results.json. 
