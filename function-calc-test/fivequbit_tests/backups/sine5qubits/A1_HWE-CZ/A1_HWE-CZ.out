/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 22:08:28 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:08:36 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 22:09:27 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:10:16 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 22:11:18 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:12:30 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 285.51965260505676 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:13:21 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 22:14:11 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:15:00 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 22:16:01 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:17:15 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 282.1999361515045 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:18:04 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 22:18:55 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:19:46 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 22:20:47 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:22:01 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 288.11991477012634 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:22:52 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 22:23:42 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:24:32 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 22:25:34 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:26:46 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 284.6903405189514 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:27:36 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 22:28:26 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:29:17 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 22:30:18 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:31:31 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 285.453736782074 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:32:22 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 22:33:13 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:34:02 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 22:35:04 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:36:18 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 284.75229144096375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:37:06 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 22:37:57 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:38:47 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 22:39:49 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:41:02 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 285.4802715778351 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:41:52 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 22:42:43 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:43:33 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 22:44:34 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:45:47 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 285.48374104499817 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:46:38 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 22:47:28 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:48:18 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 22:49:19 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:50:32 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 284.74519395828247 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:51:22 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 22:52:12 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:53:01 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 22:54:03 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:55:18 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 284.2856924533844 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:56:07 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 22:56:57 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:57:52 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 22:58:54 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:00:06 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 297.7635736465454 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:01:04 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:01:55 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:02:50 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:03:52 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:05:05 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 292.536598443985 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:05:57 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:06:48 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:07:38 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:08:40 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:09:53 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 286.10030603408813 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:10:43 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:11:34 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:12:25 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:13:27 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:14:40 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 287.32458329200745 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:15:30 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:16:45 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:17:53 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:18:55 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:20:08 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 328.0362639427185 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:20:58 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:21:49 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:22:39 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:23:57 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:25:09 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 301.07500553131104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:25:59 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:26:49 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:27:56 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:29:00 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:30:14 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 303.5250332355499 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:31:03 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:31:53 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:32:43 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:33:48 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:35:00 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 287.34733963012695 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:35:50 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:36:40 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:37:30 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:38:31 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:39:43 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 282.5862765312195 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:40:33 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:41:23 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:42:12 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:43:14 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:44:27 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 282.9904074668884 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:45:17 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:46:06 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:46:58 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:47:59 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:49:11 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 285.03780245780945 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:50:01 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:50:51 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:51:47 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:52:49 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:54:02 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 290.95196652412415 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:54:52 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Thu Apr  4 23:55:42 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:56:32 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Thu Apr  4 23:57:34 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:58:46 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 283.69519662857056 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:59:35 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Fri Apr  5 00:00:25 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 00:01:16 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Fri Apr  5 00:02:17 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:03:30 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 283.05046033859253 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:04:20 2024]  Iteration number: 0 with current cost as 0.6528021142125073 and parameters 
[-3.25347269  2.4979825  -1.76240746 -0.11653104  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   0.6027151   1.14432446
  1.31029899 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Fri Apr  5 00:05:08 2024]  Iteration number: 0 with current cost as 0.6585832141274375 and parameters 
[-3.27210495  2.53814119 -1.7638136  -0.11653104  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18552    -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354682  0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 00:06:02 2024]  Iteration number: 0 with current cost as 0.6699793281858972 and parameters 
[-3.27442174  2.51094894 -1.73871149 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.8 fold... 
[Fri Apr  5 00:07:03 2024]  Iteration number: 0 with current cost as 0.8943730419022189 and parameters 
[-5.89217616  4.99504333  0.543882   -0.11653103  0.55388693 -2.77010897
  3.06858498  2.18960145  1.18552013 -1.06648316  0.6027151   1.14432452
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:08:17 2024]  Iteration number: 0 with current cost as 0.6432791488031603 and parameters 
[-3.27657712  2.51320025 -1.73699384 -0.11653104  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 287.4696545600891 seconds. 
Discarding model... 

Training complete taking 7230.222801208496 total seconds. 
Now scoring model... 
Scoring complete taking 0.9497382640838623 seconds. 
Saved predicted values as A1_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (0.20115291768332896,), 'R2_train': 0.5994571859107749, 'MAE_train': 0.38103202453912105, 'MSE_test': 0.21157399789310735, 'R2_test': 0.6054219095181357, 'MAE_test': 0.3960824836525293}. 
Saved model results as A1_HWE-CZ_results.json. 
