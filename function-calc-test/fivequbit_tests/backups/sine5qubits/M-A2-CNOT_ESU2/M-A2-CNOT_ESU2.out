/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 22:04:27 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:05:43 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:07:46 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 22:09:32 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:11:37 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Thu Apr  4 22:13:57 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 632.2457225322723 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:16:15 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:18:19 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 22:20:11 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:22:12 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Thu Apr  4 22:24:27 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 629.1022226810455 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:26:44 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:28:47 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 22:30:35 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:32:37 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Thu Apr  4 22:34:54 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 626.808589220047 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:37:10 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:39:11 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 22:40:55 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:42:54 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Thu Apr  4 22:45:08 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 613.6868150234222 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:47:22 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:49:24 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 22:51:11 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:53:10 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Thu Apr  4 22:55:23 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 613.6757872104645 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:57:36 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:59:36 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 23:01:25 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:03:25 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Thu Apr  4 23:05:41 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 618.3654079437256 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:07:56 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:09:59 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 23:11:42 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:13:40 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Thu Apr  4 23:16:00 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 622.7710466384888 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:18:20 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:20:22 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 23:22:10 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:24:16 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Thu Apr  4 23:26:35 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 632.8816149234772 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:28:54 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:30:58 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 23:32:47 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:34:53 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Thu Apr  4 23:37:16 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 642.1997842788696 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:39:36 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:41:41 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 23:43:31 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:45:37 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Thu Apr  4 23:47:57 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 642.4920282363892 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:50:19 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:52:25 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 23:54:14 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:56:21 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Thu Apr  4 23:58:39 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 640.6601405143738 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:01:02 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:03:08 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 00:04:56 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 00:07:02 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 00:09:25 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 647.0567662715912 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:11:47 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:13:51 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 00:15:40 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 00:17:48 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 00:20:13 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 648.4862742424011 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:22:38 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:24:42 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 00:26:34 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 00:28:41 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 00:31:02 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 649.0706486701965 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:33:28 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:35:35 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 00:37:28 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 00:39:34 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 00:41:56 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 651.3830282688141 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:44:17 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:46:23 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 00:48:13 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 00:50:17 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 00:52:37 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 640.8775758743286 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:54:54 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:56:57 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 00:58:45 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 01:00:50 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 01:03:10 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 634.6593108177185 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:05:30 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:07:36 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 01:09:23 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 01:11:29 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 01:13:51 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 641.8179564476013 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:16:16 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:18:23 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 01:20:15 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 01:22:19 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 01:24:38 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 646.8525972366333 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:27:00 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:29:07 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 01:30:59 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 01:33:08 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 01:35:28 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 650.0134179592133 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:37:49 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:39:54 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 01:41:43 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 01:43:54 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 01:46:18 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 650.1591827869415 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:48:46 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:50:59 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 01:52:54 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 01:55:04 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 01:57:25 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 666.0681884288788 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:59:48 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 02:01:55 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 02:03:49 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 02:05:55 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 02:08:19 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 654.5636501312256 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:10:41 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 02:12:48 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 02:14:38 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 02:16:50 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 02:19:22 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 663.7425525188446 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:21:45 2024]  Iteration number: 0 with current cost as 0.4366518708235766 and parameters 
[-1.35720432  2.23743474 -2.12427942 -0.11653092  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 02:23:51 2024]  Iteration number: 0 with current cost as 0.46226584567809664 and parameters 
[-1.4892778   2.23743448 -2.12427932 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 02:25:45 2024]  Iteration number: 0 with current cost as 0.47850363934845586 and parameters 
[-1.48225014  2.23743464 -2.12427932 -0.11653071  0.55388724 -2.77010913
  3.06858498  2.18960161  1.1855203  -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 02:28:00 2024]  Iteration number: 0 with current cost as 0.41949711355402264 and parameters 
[-1.49337787  2.23743441 -2.12427952 -0.11653103  0.55388697 -2.7701092
  3.06858476  2.18960145  1.18551998 -1.06648331]. 
Working on 1.0 fold... 
[Fri Apr  5 02:30:25 2024]  Iteration number: 0 with current cost as 0.44293779037422165 and parameters 
[-1.48232878  2.23743464 -2.12427941 -0.11653103  0.55388708 -2.77010909
  3.06858487  2.18960145  1.18551998 -1.06648331]. 
Training complete taking 665.0860290527344 seconds. 
Discarding model... 

Training complete taking 16024.72733092308 total seconds. 
Now scoring model... 
Scoring complete taking 2.268988847732544 seconds. 
Saved predicted values as M-A2-CNOT_ESU2_predicted_values.csv
Model scores: {'MSE_train': (0.7549655214171505,), 'R2_train': -0.5033140854800855, 'MAE_train': 0.7543688848473469, 'MSE_test': 0.7601795222830399, 'R2_test': -0.4177081650524952, 'MAE_test': 0.7984880735574814}. 
Saved model results as M-A2-CNOT_ESU2_results.json. 
