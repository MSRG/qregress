/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/gjones/scratch/sine5qubits/sine_train.bin... 
Successfully loaded /home/gjones/scratch/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /home/gjones/scratch/sine5qubits/sine_test.bin... 
Successfully loaded /home/gjones/scratch/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /home/gjones/scratch/sine5qubits/sine_train.bin 
 at time Mon Apr  8 15:02:34 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 15:02:47 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 15:10:11 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Mon Apr  8 15:15:13 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 15:22:54 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Mon Apr  8 15:27:46 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 15:29:46 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 15:37:47 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Mon Apr  8 15:38:46 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 15:46:12 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 2998.9314510822296 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  8 15:52:46 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 15:59:35 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Mon Apr  8 16:06:06 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 16:14:54 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Mon Apr  8 16:20:48 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 16:22:54 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 16:31:26 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Mon Apr  8 16:32:33 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 16:41:03 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3292.1469032764435 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  8 16:47:53 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 16:56:46 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Mon Apr  8 17:01:57 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 17:08:55 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Mon Apr  8 17:13:33 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 17:15:11 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 17:22:37 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Mon Apr  8 17:23:41 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 17:30:04 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 2892.7377755641937 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  8 17:35:56 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 17:42:30 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Mon Apr  8 17:48:48 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 17:57:22 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Mon Apr  8 18:03:11 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 18:05:17 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 18:13:55 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Mon Apr  8 18:14:51 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 18:21:37 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3099.1329617500305 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  8 18:27:30 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 18:35:52 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Mon Apr  8 18:41:26 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 18:49:47 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Mon Apr  8 18:54:23 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 18:56:37 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 19:06:29 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Mon Apr  8 19:07:21 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 19:15:06 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3255.992644071579 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 19:21:46 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 19:28:40 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Mon Apr  8 19:34:26 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 19:42:09 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Mon Apr  8 19:47:24 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 19:49:58 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 19:57:52 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Mon Apr  8 19:58:44 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:06:36 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3092.7471878528595 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  8 20:13:18 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:21:16 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Mon Apr  8 20:26:37 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:34:32 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Mon Apr  8 20:39:33 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 20:41:41 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 20:49:20 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Mon Apr  8 20:50:17 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:57:16 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 2998.043561697006 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  8 21:03:20 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 21:10:09 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Mon Apr  8 21:14:51 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 21:22:09 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Mon Apr  8 21:26:47 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 21:28:58 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 21:38:38 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Mon Apr  8 21:40:08 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 21:49:07 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3090.002913236618 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  8 21:54:49 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 22:02:42 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Mon Apr  8 22:08:45 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 22:16:46 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Mon Apr  8 22:22:22 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 22:24:03 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 22:32:51 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Mon Apr  8 22:34:18 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 22:41:53 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3275.396204471588 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  8 22:49:22 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 22:57:50 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Mon Apr  8 23:04:22 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 23:12:13 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Mon Apr  8 23:17:44 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 23:19:26 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 23:27:34 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Mon Apr  8 23:28:31 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 23:36:07 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3152.992933511734 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 23:41:56 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 23:49:03 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Mon Apr  8 23:53:58 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 00:00:50 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 00:05:33 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 00:07:36 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 00:17:01 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 00:18:02 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 00:26:13 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3112.3067326545715 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 00:34:03 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 00:42:14 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 00:47:17 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 00:56:28 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 01:01:58 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 01:04:26 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 01:13:36 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 01:14:20 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 01:21:47 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3202.089861392975 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 01:27:11 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 01:35:02 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 01:40:08 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 01:47:03 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 01:52:11 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 01:54:00 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 02:04:13 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 02:05:23 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 02:13:19 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3093.332914829254 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 02:18:43 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 02:25:24 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 02:30:08 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 02:36:50 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 02:41:23 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 02:43:34 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 02:52:31 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 02:53:25 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:01:22 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 2946.957548379898 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 03:08:06 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:16:12 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 03:21:32 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:29:45 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 03:34:13 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 03:35:57 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 03:44:06 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 03:45:03 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:52:04 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3031.0483541488647 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 03:58:24 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 04:06:22 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 04:11:48 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 04:18:38 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 04:24:16 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 04:26:11 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 04:35:26 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 04:36:34 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 04:43:30 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3057.59783411026 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 04:49:30 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 04:56:36 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 05:01:39 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:09:19 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 05:14:09 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 05:16:39 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 05:26:02 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 05:27:26 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:35:12 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3059.32369184494 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 05:40:18 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:47:45 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 05:52:51 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:59:40 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 06:04:22 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 06:06:13 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 06:15:03 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 06:15:47 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 06:23:22 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 2899.5987343788147 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 06:28:50 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 06:37:05 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 06:42:32 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 06:49:04 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 06:54:08 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 06:56:45 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 07:06:06 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 07:06:49 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 07:14:54 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3228.3120126724243 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 07:22:29 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 07:31:02 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 07:37:09 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 07:44:55 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 07:50:11 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 07:52:24 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 08:01:39 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 08:02:40 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 08:09:36 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3203.320437192917 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 08:15:49 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 08:23:21 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 08:29:22 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 08:37:21 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 08:43:02 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 08:45:03 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 08:53:46 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 08:54:29 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 09:01:44 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3209.298031806946 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 09:09:22 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 09:17:18 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 09:22:18 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 09:29:57 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 09:35:22 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 09:38:03 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 09:48:35 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 09:49:32 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 09:56:58 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3260.7711296081543 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 10:03:47 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:10:30 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 10:15:21 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:22:19 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 10:28:05 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 10:30:03 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 10:39:11 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 10:39:55 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:46:41 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 2949.4986884593964 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 10:52:48 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:59:53 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 11:05:46 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 11:13:57 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 11:19:43 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 11:22:34 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 11:32:08 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 11:33:11 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 11:40:35 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 3317.837390899658 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 11:48:06 2024]  Iteration number: 0 with current cost as 0.12792299551926095 and parameters 
[-3.18717104  1.97474887 -2.04998534 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.4106211   1.14432445
  1.67479343 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 11:55:19 2024]  Iteration number: 50 with current cost as 0.07170854336316873 and parameters 
[-3.40065646  0.3540752  -2.91712845 -0.11653097  0.55388415 -2.77011044
  3.0685833   2.1896014   1.18551988 -1.06648211  1.3308841   1.14432672
  1.5239515  -1.8735465   0.72965083  2.88578622 -0.54534448 -0.47522432
 -2.02654527  0.72897005  1.60512479  2.83076962 -1.26456749 -0.25136259]. 
Working on 0.4 fold... 
[Tue Apr  9 12:00:47 2024]  Iteration number: 0 with current cost as 0.1284581353740586 and parameters 
[-3.1209988   2.00062605 -2.05699642 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.42452544  1.14432445
  1.5944119  -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 12:08:13 2024]  Iteration number: 50 with current cost as 0.05895185083170383 and parameters 
[-0.02244397 -1.55095403 -3.12901241 -0.11653107  0.55393696 -2.77017449
  3.0685987   2.18960356  1.18555885 -1.06657968  3.12813784  1.14436917
  1.58576277 -1.87343218  0.72968193  2.88583213 -0.54531229 -0.47524847
 -2.02652266  0.72904042  1.60512668  2.83073756 -1.26452829 -0.25128933]. 
Working on 0.6 fold... 
[Tue Apr  9 12:13:58 2024]  Iteration number: 0 with current cost as 0.13120133215694052 and parameters 
[-3.14171943  1.99488032 -2.05485103 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.41841474  1.14432445
  1.61815861 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 12:16:08 2024]  Iteration number: 0 with current cost as 0.11246431285648922 and parameters 
[-3.1421338   1.98796607 -2.05470688 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.42533107  1.14432445
  1.62501997 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 12:24:23 2024]  Iteration number: 50 with current cost as 0.04660529134892864 and parameters 
[-1.60404457 -1.27822162 -3.1403056  -0.11653086  0.55388708 -2.77010748
  3.06858385  2.18960155  1.1855223  -1.06648174  2.88804362  1.14432383
  1.56607507 -1.87354711  0.72965041  2.88578604 -0.54534053 -0.47522503
 -2.02654283  0.7289738   1.60512762  2.83077263 -1.2645668  -0.2513599 ]. 
Working on 1.0 fold... 
[Tue Apr  9 12:25:20 2024]  Iteration number: 0 with current cost as 0.1239342955521424 and parameters 
[-3.17424875  1.97400938 -2.0490214  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.40681238  1.14432445
  1.6581232  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 12:31:35 2024]  Iteration number: 50 with current cost as 0.07561999204392804 and parameters 
[-3.51645024  1.42126132 -3.00188955 -0.11651708  0.55389434 -2.77009623
  3.06858353  2.18960883  1.18553035 -1.06648443  0.16703007  1.14432828
  1.55939611 -1.87354696  0.72965294  2.88579085 -0.54534252 -0.47522384
 -2.02654552  0.72897201  1.60512762  2.83077361 -1.26456949 -0.25136624]. 
Training complete taking 2927.6051733493805 seconds. 
Discarding model... 

Training complete taking 77647.02490568161 total seconds. 
Now scoring model... 
Scoring complete taking 0.6714956760406494 seconds. 
Saved predicted values as A1-A1-CZ_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (0.09292025117528274,), 'R2_train': 0.814973904826885, 'MAE_train': 0.2538067155526725, 'MSE_test': 0.07446192502836167, 'R2_test': 0.8611311196844768, 'MAE_test': 0.2360509843194709}. 
Saved model results as A1-A1-CZ_Full-Pauli-CRZ_results.json. 
