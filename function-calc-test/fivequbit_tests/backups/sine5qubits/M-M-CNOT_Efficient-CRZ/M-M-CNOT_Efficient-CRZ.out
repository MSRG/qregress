/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:31 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:40:06 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:43:22 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:46:54 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:51:33 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:55:03 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1199.3766312599182 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:59:55 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:03:06 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:06:37 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:11:12 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:14:46 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1182.0742270946503 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:19:38 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:22:50 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:26:21 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:30:59 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:34:30 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1186.370952129364 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:39:23 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:42:32 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:46:05 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:50:38 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:54:09 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1179.6645834445953 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:59:08 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:02:24 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:05:59 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:10:45 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:14:21 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1207.616711616516 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:19:19 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:22:32 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:26:07 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:30:44 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:34:16 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1198.6129863262177 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:39:12 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:42:20 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:46:01 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:50:50 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:54:31 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1222.2728970050812 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:59:40 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:02:59 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:06:36 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:11:25 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:15:07 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1229.8572220802307 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:20:07 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:23:24 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:27:00 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:31:52 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:35:37 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1236.9700169563293 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:40:51 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:44:05 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:47:38 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:52:25 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:56:04 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1223.0727427005768 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:01:18 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:04:31 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:08:17 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:12:57 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:16:38 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1238.092945098877 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:21:55 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:25:14 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:28:54 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:33:35 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:37:25 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1261.5409915447235 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:42:53 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:46:11 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:49:57 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:54:46 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:58:28 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1242.3910856246948 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:03:29 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:06:47 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:10:32 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:15:12 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:18:57 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1238.4423730373383 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:24:08 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:27:26 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:31:13 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:35:59 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:39:40 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1236.8387362957 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:44:50 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:48:11 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:51:53 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:56:27 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:59:55 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1210.1295359134674 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 03:04:52 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:08:11 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:11:50 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:16:30 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:20:17 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1234.5082819461823 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:25:32 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:28:50 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:32:32 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:37:21 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:41:07 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1248.6572556495667 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:46:31 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:49:52 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:53:36 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:58:19 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:01:48 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1231.813592672348 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 04:06:57 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:10:10 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:13:53 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:18:27 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:22:02 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1210.735942363739 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 04:27:00 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:30:11 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:33:44 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:38:15 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:41:50 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1190.0171263217926 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 04:47:01 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:50:31 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:54:08 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:58:50 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:02:27 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1247.9209849834442 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 05:07:40 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:11:00 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:14:36 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:19:21 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:22:53 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1214.2073776721954 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:27:53 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:31:09 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:34:48 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:39:38 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:43:18 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1228.4283609390259 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 05:48:19 2024]  Iteration number: 0 with current cost as 0.24221701854093985 and parameters 
[ 1.36565611  2.2374348  -2.12427931 -0.1165307   0.55388708 -2.77010881
  3.06858498  2.18960162  1.18552031 -1.06648308  0.6027151   1.14432461
  1.31029915 -1.8735468 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:51:38 2024]  Iteration number: 0 with current cost as 0.3708305461004056 and parameters 
[11.25917784  2.23743527 -2.124279   -0.11653039  0.55388708 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:55:19 2024]  Iteration number: 0 with current cost as 0.37695489813354277 and parameters 
[11.00344206  2.23743527 -2.12427837 -0.11652976  0.55388708 -2.77010834
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:00:05 2024]  Iteration number: 0 with current cost as 0.24931148566575267 and parameters 
[ 1.31247514  2.23743447 -2.12427947 -0.11653086  0.55388691 -2.77010914
  3.06858482  2.18960145  1.18552015 -1.06648325  0.60271527  1.14432428
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:03:33 2024]  Iteration number: 0 with current cost as 0.617660348273975 and parameters 
[12.35305744  2.237434   -2.124279   -0.11653039  0.55388645 -2.77010834
  3.06858435  2.18960145  1.18552062 -1.06648372  0.60271447  1.14432445
  1.31029962 -1.8735468 ]. 
Training complete taking 1206.1677823066711 seconds. 
Discarding model... 

Training complete taking 30505.783138990402 total seconds. 
Now scoring model... 
Scoring complete taking 2.2838354110717773 seconds. 
Saved predicted values as M-M-CNOT_Efficient-CRZ_predicted_values.csv
Model scores: {'MSE_train': (0.4071508973337782,), 'R2_train': 0.18926671283107876, 'MAE_train': 0.5538781924932508, 'MSE_test': 0.41711844780273644, 'R2_test': 0.22208871469207692, 'MAE_test': 0.5713555076055109}. 
Saved model results as M-M-CNOT_Efficient-CRZ_results.json. 
