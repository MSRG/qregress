/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/gjones/scratch/sine5qubits/sine_train.bin... 
Successfully loaded /home/gjones/scratch/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /home/gjones/scratch/sine5qubits/sine_test.bin... 
Successfully loaded /home/gjones/scratch/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /home/gjones/scratch/sine5qubits/sine_train.bin 
 at time Mon Apr  8 15:02:34 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 15:02:48 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  8 15:05:15 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Mon Apr  8 15:13:27 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 15:22:42 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Mon Apr  8 15:23:55 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  8 15:34:10 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 15:44:20 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2993.80841588974 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  8 15:52:50 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  8 15:55:43 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Mon Apr  8 16:07:31 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 16:17:11 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Mon Apr  8 16:18:50 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  8 16:30:23 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 16:38:39 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 3217.8885254859924 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  8 16:46:20 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  8 16:49:23 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Mon Apr  8 16:58:59 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 17:08:17 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Mon Apr  8 17:09:26 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  8 17:19:01 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 17:27:41 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2988.6754338741302 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  8 17:36:10 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  8 17:39:11 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Mon Apr  8 17:50:11 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 17:59:21 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Mon Apr  8 18:00:48 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  8 18:10:19 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 18:18:10 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2982.1801438331604 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  8 18:25:53 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  8 18:28:44 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Mon Apr  8 18:37:23 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 18:47:45 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Mon Apr  8 18:48:53 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  8 18:59:58 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 19:08:59 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 3174.1216266155243 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 19:18:47 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  8 19:22:30 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Mon Apr  8 19:32:22 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 19:43:14 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Mon Apr  8 19:44:41 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  8 19:55:08 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:05:25 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 3284.1519782543182 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  8 20:13:31 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  8 20:16:20 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Mon Apr  8 20:27:16 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 20:36:00 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Mon Apr  8 20:37:59 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  8 20:48:36 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:58:19 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 3137.861629486084 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  8 21:05:48 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  8 21:09:09 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Mon Apr  8 21:20:58 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 21:29:58 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Mon Apr  8 21:31:24 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  8 21:40:51 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 21:49:11 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 3121.904045343399 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  8 21:57:48 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  8 22:00:17 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Mon Apr  8 22:09:19 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 22:17:45 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Mon Apr  8 22:19:08 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  8 22:29:59 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 22:38:13 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2882.261855840683 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  8 22:45:59 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  8 22:48:41 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Mon Apr  8 22:57:27 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 23:05:48 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Mon Apr  8 23:07:00 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  8 23:15:44 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 23:25:32 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2889.900729417801 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 23:34:00 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  8 23:37:11 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Mon Apr  8 23:48:22 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Mon Apr  8 23:58:12 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Mon Apr  8 23:59:46 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 00:09:38 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 00:21:03 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 3265.952109336853 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 00:28:31 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 00:31:12 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 00:40:17 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 00:49:39 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 00:50:55 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 00:59:39 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 01:08:49 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2968.5998075008392 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 01:17:55 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 01:20:26 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 01:30:06 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 01:38:41 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 01:40:19 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 01:48:53 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 01:57:06 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2810.1507823467255 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 02:04:45 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 02:07:30 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 02:17:29 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 02:25:29 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 02:26:55 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 02:35:55 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 02:45:02 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2877.9483885765076 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 02:52:43 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 02:55:37 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 03:04:59 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 03:14:22 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 03:15:50 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 03:25:04 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:33:24 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2913.5435922145844 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 03:41:17 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 03:44:20 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 03:53:23 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 04:02:22 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 04:03:46 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 04:12:20 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 04:21:22 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2851.5951738357544 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 04:28:52 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 04:31:21 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 04:40:28 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 04:49:02 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 04:50:13 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 04:59:21 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:08:16 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2816.7807080745697 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 05:15:58 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 05:18:26 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 05:26:58 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 05:36:09 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 05:37:46 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 05:48:03 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:56:46 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2959.310827732086 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 06:05:07 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 06:07:28 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 06:16:20 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 06:25:16 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 06:27:09 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 06:37:31 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 06:47:16 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 3025.567511320114 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 06:55:32 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 06:58:07 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 07:07:00 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 07:15:14 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 07:16:31 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 07:25:44 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 07:34:54 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2810.8044397830963 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 07:42:25 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 07:46:03 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 07:55:17 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 08:03:39 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 08:05:16 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 08:13:59 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 08:22:10 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2913.6535851955414 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 08:30:59 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 08:34:11 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 08:43:59 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 08:54:18 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 08:55:37 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 09:05:35 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 09:14:37 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 3070.740433692932 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 09:22:05 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 09:24:56 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 09:34:23 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 09:43:37 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 09:45:23 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 09:54:42 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:05:03 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 3140.435251712799 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 10:14:32 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 10:17:16 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 10:25:56 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 10:35:34 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 10:36:54 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 10:47:30 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:57:00 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 3079.147377729416 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 11:05:47 2024]  Iteration number: 0 with current cost as 0.3223331019187723 and parameters 
[-2.85680028  2.31111251 -2.10460999 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.54354738  1.14432445
  1.22711113 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  9 11:08:51 2024]  Iteration number: 0 with current cost as 0.34186794864673686 and parameters 
[-2.8316898   2.335367   -2.0950794  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51668262  1.14432445
  1.18812629 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Tue Apr  9 11:18:05 2024]  Iteration number: 0 with current cost as 0.35144544345764384 and parameters 
[-2.82913455  2.3434757  -2.09482662 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.51578932  1.14432445
  1.18428048 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Tue Apr  9 11:26:18 2024]  Iteration number: 50 with current cost as 0.23927751661252036 and parameters 
[-4.67417612  7.62031388 -1.56949456 -0.11652643  0.55389147 -2.77010363
  3.06859972  2.1896123   1.18552389 -1.06648066  3.35923465  1.14433535
 -0.1584828  -1.87353429  0.72966363  2.88579584 -0.54534384 -0.47521624
 -2.0265316   0.72898938  1.60513395  2.83077908 -1.26456291 -0.25136153]. 
Working on 0.8 fold... 
[Tue Apr  9 11:27:36 2024]  Iteration number: 0 with current cost as 0.29349845584578976 and parameters 
[-2.83455124  2.30480498 -2.09636862 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648308  0.51630122  1.14432445
  1.19347132 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  9 11:36:45 2024]  Iteration number: 0 with current cost as 0.3331562809159545 and parameters 
[-2.85819867  2.32132399 -2.10496591 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.54635919  1.14432445
  1.2288887  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 11:45:11 2024]  Iteration number: 50 with current cost as 0.28920909584768767 and parameters 
[-4.00023357  4.52947011 -2.95008272 -0.1164951   0.55392811 -2.77016274
  3.06849078  2.18952586  1.18551378 -1.06652401  2.26990414  1.14429886
 -0.72450726 -1.87354683  0.72960844  2.88573671 -0.54538359 -0.4752784
 -2.02658064  0.72893408  1.60503503  2.83068041 -1.26457051 -0.25141535]. 
Training complete taking 2838.9022188186646 seconds. 
Discarding model... 

Training complete taking 75015.88874483109 total seconds. 
Now scoring model... 
Scoring complete taking 1.4169418811798096 seconds. 
Saved predicted values as A1-A1-CNOT_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.40011266044427163,), 'R2_train': 0.2032814994044837, 'MAE_train': 0.5448422438265071, 'MSE_test': 0.45544724052748126, 'R2_test': 0.15060685967014809, 'MAE_test': 0.6001647786553852}. 
Saved model results as A1-A1-CNOT_Full-Pauli-CRX_results.json. 
