/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 22:04:29 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:04:51 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:12:34 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Thu Apr  4 22:13:03 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Thu Apr  4 22:20:14 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Thu Apr  4 22:20:44 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 22:28:20 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Thu Apr  4 22:29:03 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:36:20 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Thu Apr  4 22:36:49 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2317.595946073532 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:43:28 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:50:52 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Thu Apr  4 22:51:21 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Thu Apr  4 22:58:46 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Thu Apr  4 22:59:14 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 23:06:48 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Thu Apr  4 23:07:32 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:14:56 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Thu Apr  4 23:15:24 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2311.707460641861 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:22:00 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:29:17 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Thu Apr  4 23:29:46 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Thu Apr  4 23:36:57 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Thu Apr  4 23:37:25 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 23:44:58 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Thu Apr  4 23:45:42 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:52:54 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Thu Apr  4 23:53:23 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2284.382632493973 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:00:04 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:07:22 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 00:07:51 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 00:15:06 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 00:15:34 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 00:22:55 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 00:23:39 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:30:59 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 00:31:31 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2280.0933175086975 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:38:04 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:45:24 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 00:45:53 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 00:53:13 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 00:53:42 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 01:01:10 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 01:01:53 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:09:06 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 01:09:34 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2282.7747910022736 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:16:07 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:23:22 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 01:23:51 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 01:31:13 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 01:31:42 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 01:39:06 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 01:39:49 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:47:04 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 01:47:32 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2289.683828353882 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:54:17 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:01:32 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 02:02:02 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 02:09:11 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 02:09:39 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 02:17:07 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 02:17:50 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:25:16 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 02:25:45 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2282.233285665512 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 02:32:19 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:39:35 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 02:40:04 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 02:47:16 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 02:47:45 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 02:55:22 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 02:56:05 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:03:15 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 03:03:43 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2279.1844539642334 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:10:18 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:17:44 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 03:18:13 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 03:25:22 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 03:25:51 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 03:33:14 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 03:33:58 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:41:06 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 03:41:34 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2270.1219568252563 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 03:48:09 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:55:28 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 03:55:57 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 04:03:08 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 04:03:36 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 04:11:00 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 04:11:44 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:19:07 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 04:19:36 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2281.442261695862 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 04:26:11 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:33:44 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 04:34:13 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 04:41:23 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 04:41:53 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 04:49:14 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 04:49:57 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:57:08 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 04:57:36 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2310.168430328369 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 05:04:40 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:11:57 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 05:12:25 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 05:19:33 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 05:20:02 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 05:28:13 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 05:28:56 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:36:34 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 05:37:03 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2339.2033739089966 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 05:43:39 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:50:54 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 05:51:24 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 05:58:36 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 05:59:05 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 06:06:32 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 06:07:15 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:14:26 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 06:14:54 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2271.5202057361603 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 06:21:32 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:28:49 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 06:29:18 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 06:36:29 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 06:36:58 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 06:44:23 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 06:45:06 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:52:15 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 06:52:48 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2275.2257475852966 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 06:59:26 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:06:44 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 07:07:13 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 07:14:24 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 07:14:53 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 07:22:18 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 07:23:05 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:30:14 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 07:30:42 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2268.8779077529907 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 07:37:15 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:44:31 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 07:44:59 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 07:52:09 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 07:52:38 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 08:00:01 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 08:00:44 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:07:54 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 08:08:23 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2262.866905927658 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 08:14:57 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:22:20 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 08:22:48 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 08:29:58 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 08:30:27 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 08:38:33 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 08:39:17 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:46:47 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 08:47:16 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2354.529887199402 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 08:54:13 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:01:28 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 09:01:57 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 09:09:05 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 09:09:34 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 09:16:56 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 09:17:41 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:24:52 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 09:25:20 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2261.5903735160828 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 09:31:54 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:39:11 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 09:39:39 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 09:46:49 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 09:47:18 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 09:54:41 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 09:55:24 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:02:32 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 10:03:01 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2261.8336114883423 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 10:09:35 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:16:52 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 10:17:21 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 10:24:33 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 10:25:01 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 10:32:27 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 10:33:10 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:40:19 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 10:40:48 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2264.9084799289703 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 10:47:21 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:54:35 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 10:55:03 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 11:02:14 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 11:02:42 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 11:10:07 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 11:10:50 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:18:02 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 11:18:31 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2264.1757991313934 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 11:25:05 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:32:23 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 11:32:51 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 11:40:02 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 11:40:31 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 11:47:56 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 11:48:39 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:55:50 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 11:56:19 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2270.2760593891144 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 12:02:55 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 12:10:12 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 12:10:41 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 12:17:51 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 12:18:20 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 12:25:43 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 12:26:26 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 12:33:37 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 12:34:05 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2263.5639481544495 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 12:40:39 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 12:47:57 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 12:48:26 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 12:55:35 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 12:56:03 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 13:03:28 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 13:04:11 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 13:11:23 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 13:11:51 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2265.5152311325073 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 13:18:25 2024]  Iteration number: 0 with current cost as 0.10647678331894586 and parameters 
[-3.12328019  2.23975291 -2.12348126 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60994371  1.14432445
  1.5538895  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 13:25:43 2024]  Iteration number: 50 with current cost as 0.04016612103234072 and parameters 
[-4.8022861   6.12038004 -1.48122536 -0.11652854  0.55388727 -2.77010255
  3.06858283  2.18959501  1.18552047 -1.066486   -2.77241439  1.14432476
  0.9106948  -1.87355375  0.72966197  2.88578632 -0.5453439  -0.47522526
 -2.02654035  0.72896896  1.60512756  2.83076877 -1.26457132 -0.25136155]. 
Working on 0.4 fold... 
[Fri Apr  5 13:26:11 2024]  Iteration number: 0 with current cost as 0.20336287281905105 and parameters 
[-3.31067493  2.28036402 -2.12485937 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.64896619  1.14432445
  1.75572562 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 13:33:22 2024]  Iteration number: 50 with current cost as 0.042004054537378294 and parameters 
[-4.6732279   6.03773484 -1.55798683 -0.11652931  0.55388793 -2.77010833
  3.068584    2.18960228  1.18552129 -1.06648205 -2.72738793  1.1443237
  0.90496509 -1.87354638  0.72965163  2.88578683 -0.54534235 -0.47522401
 -2.02654202  0.72897351  1.60512751  2.83077131 -1.26456693 -0.25136134]. 
Working on 0.6 fold... 
[Fri Apr  5 13:33:51 2024]  Iteration number: 0 with current cost as 0.10762365032004081 and parameters 
[-3.11527244  2.24216984 -2.12177764 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6140867   1.14432445
  1.54592299 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 13:41:14 2024]  Iteration number: 50 with current cost as 0.03851104727830952 and parameters 
[-4.73907066  6.11458405 -1.55418785 -0.11653014  0.55388754 -2.77010788
  3.06858506  2.18960183  1.18551948 -1.06648357 -2.65003217  1.14432504
  0.87697514 -1.8735468   0.7296511   2.88578421 -0.54534322 -0.4752243
 -2.02654238  0.72897372  1.605127    2.83077058 -1.26456678 -0.25136135]. 
Working on 0.8 fold... 
[Fri Apr  5 13:41:57 2024]  Iteration number: 0 with current cost as 0.12646785279492728 and parameters 
[-3.1232131   2.25674681 -2.12400615 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.62291991  1.14432445
  1.55046957 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 13:49:05 2024]  Iteration number: 50 with current cost as 0.04167386580646476 and parameters 
[-4.6522887   6.03478519 -1.57121559 -0.11653141  0.55388977 -2.77010631
  3.06858989  2.18960109  1.18552389 -1.06648155 -2.700082    1.14432804
  0.95473196 -1.87354527  0.72965071  2.8857857  -0.54534101 -0.47522355
 -2.02654268  0.7289751   1.60512781  2.83077095 -1.26456733 -0.25135995]. 
Working on 1.0 fold... 
[Fri Apr  5 13:49:34 2024]  Iteration number: 0 with current cost as 0.1179245361064998 and parameters 
[-3.14552708  2.25056689 -2.12434058 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61978823  1.14432445
  1.57704538 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 2263.8672020435333 seconds. 
Discarding model... 

Training complete taking 57077.34457087517 total seconds. 
Now scoring model... 
Scoring complete taking 1.1610620021820068 seconds. 
Saved predicted values as M_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (0.06907865269051498,), 'R2_train': 0.8624481401472397, 'MAE_train': 0.21504299590553116, 'MSE_test': 0.09807661855265261, 'R2_test': 0.8170905439477704, 'MAE_test': 0.28223317210464466}. 
Saved model results as M_Full-Pauli-CRZ_results.json. 
