/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 22:03:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:03:43 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Thu Apr  4 22:07:39 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Thu Apr  4 22:11:51 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Thu Apr  4 22:17:13 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Thu Apr  4 22:18:10 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Thu Apr  4 22:21:44 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1316.1589033603668 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:25:39 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Thu Apr  4 22:29:34 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Thu Apr  4 22:33:50 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Thu Apr  4 22:39:06 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Thu Apr  4 22:40:04 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Thu Apr  4 22:43:39 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1313.2445847988129 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:47:34 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Thu Apr  4 22:51:30 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Thu Apr  4 22:55:43 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Thu Apr  4 23:01:01 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Thu Apr  4 23:01:57 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Thu Apr  4 23:05:32 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1312.4191944599152 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:09:25 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Thu Apr  4 23:13:24 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Thu Apr  4 23:17:38 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Thu Apr  4 23:23:10 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Thu Apr  4 23:24:08 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Thu Apr  4 23:27:40 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1332.5439071655273 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:31:45 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Thu Apr  4 23:35:47 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Thu Apr  4 23:40:00 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Thu Apr  4 23:45:17 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Thu Apr  4 23:46:15 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Thu Apr  4 23:49:51 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1345.9154114723206 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:54:05 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Thu Apr  4 23:57:57 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 00:02:10 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 00:07:22 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 00:08:19 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 00:11:54 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1306.3385767936707 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:15:50 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 00:19:44 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 00:23:56 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 00:29:13 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 00:30:14 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 00:33:45 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1308.8784518241882 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:37:40 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 00:41:38 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 00:46:17 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 00:51:41 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 00:52:39 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 00:56:18 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1356.2367577552795 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:00:16 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 01:04:10 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 01:08:21 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 01:13:54 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 01:14:52 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 01:18:26 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1326.6928403377533 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:22:21 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 01:26:26 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 01:30:42 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 01:35:59 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 01:36:56 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 01:40:33 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1335.4895522594452 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:44:37 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 01:48:31 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 01:52:57 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 01:58:12 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 01:59:09 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 02:02:42 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1317.641088962555 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:06:35 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 02:10:47 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 02:15:05 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 02:20:19 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 02:21:16 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 02:24:47 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1327.3860688209534 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 02:28:43 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 02:32:37 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 02:36:54 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 02:42:21 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 02:43:19 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 02:46:50 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1320.1856763362885 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:50:42 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 02:54:54 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 02:59:29 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 03:05:08 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 03:06:05 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 03:09:37 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1379.7736794948578 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 03:13:42 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 03:17:39 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 03:21:51 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 03:27:04 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 03:28:01 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 03:31:33 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1306.7991733551025 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 03:35:29 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 03:39:26 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 03:43:54 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 03:49:14 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 03:50:11 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 03:53:43 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1330.694581747055 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 03:57:39 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 04:01:33 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 04:05:44 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 04:11:01 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 04:11:59 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 04:15:32 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1317.4532964229584 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 04:19:37 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 04:23:36 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 04:27:51 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 04:33:06 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 04:34:04 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 04:37:34 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1310.1386864185333 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 04:41:29 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 04:45:24 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 04:49:35 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 04:54:49 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 04:55:46 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 04:59:17 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1304.950546503067 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 05:03:12 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 05:07:05 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 05:11:15 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 05:16:29 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 05:17:27 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 05:21:02 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1302.591536283493 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 05:24:56 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 05:29:24 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 05:33:39 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 05:38:57 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 05:39:54 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 05:43:26 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1343.7973475456238 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 05:47:19 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 05:51:17 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 05:55:29 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 06:00:47 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 06:01:45 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 06:05:40 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1335.6877930164337 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 06:09:36 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 06:13:35 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 06:18:08 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 06:23:21 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 06:24:18 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 06:27:52 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1333.6531500816345 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 06:31:48 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 06:35:50 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 06:40:03 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 06:45:22 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 06:46:21 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 06:49:53 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1320.0616517066956 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 06:53:48 2024]  Iteration number: 0 with current cost as 0.24673943885347627 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04416853  0.54879073 -2.69311604
  3.03760002  2.28104586  1.18685913 -1.0535722   0.71759129  1.19591369
  1.44113956 -1.75378471  0.71954704]. 
Working on 0.4 fold... 
[Fri Apr  5 06:57:42 2024]  Iteration number: 0 with current cost as 0.2503253290911409 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.03619439  0.54881018 -2.68370919
  3.04148795  2.28896871  1.17564447 -1.05203097  0.72422631  1.19985905
  1.43918827 -1.75733728  0.71337377]. 
Working on 0.6 fold... 
[Fri Apr  5 07:01:58 2024]  Iteration number: 0 with current cost as 0.24493363605548113 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.02927227  0.54759319 -2.67750221
  3.04978444  2.2900773   1.16071036 -1.04296547  0.72406902  1.21081437
  1.43374429 -1.7628904   0.71175327]. 
[Fri Apr  5 07:07:37 2024]  Iteration number: 50 with current cost as 0.09923638649972796 and parameters 
[-2.90318415  2.23743802 -2.12427855 -0.04076435 -0.09838169 -3.09990085
  2.04247171  3.15832532  2.03815818 -1.14173982  1.59152751  1.58118744
  3.11263071  0.11350617  0.02482443]. 
Working on 0.8 fold... 
[Fri Apr  5 07:08:36 2024]  Iteration number: 0 with current cost as 0.24688424160544353 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04977308  0.55016609 -2.69752241
  3.03257065  2.28583371  1.19280286 -1.07116375  0.7224126   1.17606694
  1.44646444 -1.74772489  0.72338099]. 
Working on 1.0 fold... 
[Fri Apr  5 07:12:09 2024]  Iteration number: 0 with current cost as 0.2411043304164613 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.04503639  0.5486963  -2.6942864
  3.03497428  2.27934194  1.19235616 -1.04782428  0.71615184  1.20244095
  1.442694   -1.75300483  0.71712534]. 
Training complete taking 1340.0330412387848 seconds. 
Discarding model... 

Training complete taking 33144.76702809334 total seconds. 
Now scoring model... 
Scoring complete taking 0.8877675533294678 seconds. 
Saved predicted values as A1-A1-CZ_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (0.15577569929659404,), 'R2_train': 0.6898139103246732, 'MAE_train': 0.32410416284954646, 'MSE_test': 0.1379387932859813, 'R2_test': 0.7427489852242932, 'MAE_test': 0.3275631057811774}. 
Saved model results as A1-A1-CZ_HWE-CNOT_results.json. 
