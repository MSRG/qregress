/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:26 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:43 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:41:57 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:46:04 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:49:43 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:53:49 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1179.5406184196472 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:57:21 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:01:34 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:05:31 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:09:04 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:13:16 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1168.5191009044647 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:16:49 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:21:06 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:25:03 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:28:36 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:32:42 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1173.375969171524 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:36:23 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:40:36 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:44:34 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:48:09 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:52:18 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1170.810037612915 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:55:53 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:00:06 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:04:02 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:07:34 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:11:43 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1161.4367933273315 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:15:15 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:19:25 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:23:22 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:26:58 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:31:02 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1169.859794139862 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:34:46 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:39:00 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:42:56 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:46:29 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:50:32 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1159.728770017624 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:54:04 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:58:15 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:02:12 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:05:46 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:09:50 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1159.0372903347015 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:13:23 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:17:35 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:21:31 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:25:14 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:29:26 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1176.261373758316 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:33:00 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:37:11 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:41:06 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:44:39 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:48:43 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1155.8681070804596 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:52:19 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:56:31 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:00:33 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:04:07 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:08:12 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1199.1785082817078 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:12:15 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:16:29 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:20:25 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:24:09 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:28:18 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1175.6637544631958 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:31:52 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:36:04 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:40:00 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:43:32 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:47:36 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1159.288150548935 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:51:10 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:55:21 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:59:18 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:02:53 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:06:56 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1175.6628065109253 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:10:46 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:14:58 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:18:55 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:22:28 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:26:35 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1162.605212211609 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:30:08 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:34:19 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:38:16 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:41:50 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:46:01 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1169.2496786117554 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:49:37 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:54:04 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:58:02 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:01:50 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:05:56 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1189.7971675395966 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:09:27 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:14:01 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:17:57 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:21:29 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:25:36 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1189.9824929237366 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:29:17 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:33:30 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:37:49 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:41:28 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:45:40 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1194.1359486579895 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 03:49:11 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:53:25 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:57:20 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:00:55 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:04:59 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1159.0892770290375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 04:08:30 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:12:51 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:16:54 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:20:26 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:24:31 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1173.2270104885101 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 04:28:05 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:32:16 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:36:12 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:39:45 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:43:50 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1159.4298520088196 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 04:47:23 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:51:35 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:55:31 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:59:04 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:03:08 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1156.5200338363647 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:06:39 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:10:51 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:14:50 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:18:47 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:22:51 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1186.3109760284424 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 05:26:26 2024]  Iteration number: 0 with current cost as 0.13241086563773263 and parameters 
[-3.31614734  2.23274246 -2.18948342 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.33183431  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:30:38 2024]  Iteration number: 0 with current cost as 0.17823687065271618 and parameters 
[-3.25284718  2.23618887 -2.17502364 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  1.23523675  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:34:35 2024]  Iteration number: 0 with current cost as 0.15445067469359092 and parameters 
[-3.27440723  2.23066057 -2.18118122 -0.11653103  0.55388706 -2.770109
  3.06858497  2.18960143  1.18551998 -1.06648311  1.27045483  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:38:08 2024]  Iteration number: 0 with current cost as 0.14246643751354715 and parameters 
[-3.31036061  2.24175296 -2.18019961 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960144  1.18551999 -1.0664831   1.31894867  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:42:12 2024]  Iteration number: 0 with current cost as 0.16444760245790874 and parameters 
[-3.28504506  2.23976118 -2.18431907 -0.11653103  0.55388706 -2.77010899
  3.06858497  2.18960145  1.18551999 -1.0664831   1.28498985  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1158.6570918560028 seconds. 
Discarding model... 

Training complete taking 29283.237169265747 total seconds. 
Now scoring model... 
Scoring complete taking 0.9878990650177002 seconds. 
Saved predicted values as M_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.07061630465571263,), 'R2_train': 0.8593863130938549, 'MAE_train': 0.21872976760371338, 'MSE_test': 0.1049382158985522, 'R2_test': 0.8042939053940651, 'MAE_test': 0.2901540523934529}. 
Saved model results as M_Modified-Pauli-CRX_results.json. 
