/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 22:03:30 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:03:56 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 22:05:24 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 22:07:44 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:10:10 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:11:39 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 558.1976568698883 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:13:14 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 22:14:41 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 22:16:58 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:19:24 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:20:54 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 554.5223531723022 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:22:28 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 22:23:58 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 22:26:17 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:28:43 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:30:10 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 556.9710884094238 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:31:46 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 22:33:15 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 22:35:34 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:38:00 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:39:31 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 560.74201130867 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:41:06 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 22:42:33 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 22:44:53 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:47:21 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:48:52 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 560.0792229175568 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:50:26 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 22:51:54 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 22:54:14 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:57:02 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:58:31 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 580.9419972896576 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:00:06 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 23:01:34 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 23:03:55 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:06:19 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:07:48 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 556.6415112018585 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:09:24 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 23:10:52 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 23:13:13 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:15:47 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:17:16 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 567.4533731937408 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:18:51 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 23:20:21 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 23:22:41 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:25:09 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:26:36 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 560.7517192363739 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:28:12 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 23:29:41 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 23:32:00 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:34:30 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:36:01 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 566.1341545581818 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:37:37 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 23:39:05 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 23:41:25 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:43:53 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:45:23 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 572.0220873355865 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:47:10 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 23:48:40 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Thu Apr  4 23:50:58 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:53:27 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:55:03 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 569.2282917499542 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:56:38 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Thu Apr  4 23:58:07 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 00:00:26 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:02:52 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:04:21 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 569.0613000392914 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:06:07 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 00:07:36 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 00:09:56 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:12:24 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:13:52 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 556.9347960948944 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:15:25 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 00:16:52 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 00:19:09 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:21:33 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:23:01 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 552.518545627594 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:24:36 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 00:26:07 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 00:28:25 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:30:53 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:32:22 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 558.6618504524231 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:33:57 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 00:35:25 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 00:37:42 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:40:05 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:41:35 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 553.8203303813934 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:43:10 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 00:44:37 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 00:47:03 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:49:28 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:50:57 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 569.7213551998138 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:52:39 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 00:54:11 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 00:56:35 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:59:04 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:00:32 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 565.7823970317841 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:02:05 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 01:03:33 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 01:05:51 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:08:15 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:10:00 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 569.9412848949432 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:11:36 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 01:13:15 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 01:15:32 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:17:56 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:19:35 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 572.2729070186615 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:21:08 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 01:22:35 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 01:24:54 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:27:19 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:28:47 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 552.5395798683167 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:30:20 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 01:31:58 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 01:34:16 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:36:50 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:38:18 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 571.1516981124878 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:40:00 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 01:41:28 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 01:43:46 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:46:22 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:47:55 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 577.0750911235809 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:49:30 2024]  Iteration number: 0 with current cost as 0.528381057875289 and parameters 
[-3.28510834  2.47682772 -1.69463205 -0.11653105  0.55388705 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271509  1.14432443
  1.31029896 -1.8735468   0.72965078]. 
Working on 0.4 fold... 
[Fri Apr  5 01:50:58 2024]  Iteration number: 0 with current cost as 0.6706568316159326 and parameters 
[-4.05722302  3.00867165 -0.86363931 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029895 -1.8735468   0.72965077]. 
Working on 0.6 fold... 
[Fri Apr  5 01:53:25 2024]  Iteration number: 0 with current cost as 0.6956576606314467 and parameters 
[-4.09711761  2.99223351 -0.78621154 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:55:49 2024]  Iteration number: 0 with current cost as 0.6752352074297792 and parameters 
[-3.95685875  3.03578104 -1.04724002 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:57:18 2024]  Iteration number: 0 with current cost as 0.5218812661217482 and parameters 
[-3.29775942  2.50503927 -1.69632836 -0.11653104  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.8735468   0.72965079]. 
Training complete taking 563.2035439014435 seconds. 
Discarding model... 

Training complete taking 14096.371540784836 total seconds. 
Now scoring model... 
Scoring complete taking 1.2416503429412842 seconds. 
Saved predicted values as A1-A1-CZ_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (0.13185436981403892,), 'R2_train': 0.7374469088317204, 'MAE_train': 0.3015344467688596, 'MSE_test': 0.12411489736584616, 'R2_test': 0.7685300665930103, 'MAE_test': 0.3083823379476386}. 
Saved model results as A1-A1-CZ_HWE-CZ_results.json. 
