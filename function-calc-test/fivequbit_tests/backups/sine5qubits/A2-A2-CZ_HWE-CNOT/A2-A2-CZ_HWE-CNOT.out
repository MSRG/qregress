/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:34:28 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:34:41 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Thu Apr  4 21:38:12 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Thu Apr  4 21:42:13 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Thu Apr  4 21:46:08 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Thu Apr  4 21:50:16 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1182.6811118125916 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:54:25 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Thu Apr  4 21:57:54 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Thu Apr  4 22:01:56 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Thu Apr  4 22:05:53 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Thu Apr  4 22:10:03 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1188.8381278514862 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:14:13 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Thu Apr  4 22:17:40 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Thu Apr  4 22:21:40 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Thu Apr  4 22:25:33 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Thu Apr  4 22:29:41 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1182.1584250926971 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:33:56 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Thu Apr  4 22:37:26 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Thu Apr  4 22:41:27 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Thu Apr  4 22:45:41 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Thu Apr  4 22:49:53 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1208.2186312675476 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:54:04 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Thu Apr  4 22:57:34 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Thu Apr  4 23:01:36 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Thu Apr  4 23:05:40 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Thu Apr  4 23:10:08 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1213.5042788982391 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:14:17 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Thu Apr  4 23:17:44 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Thu Apr  4 23:21:47 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Thu Apr  4 23:25:42 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Thu Apr  4 23:29:54 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1185.5543410778046 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:34:03 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Thu Apr  4 23:37:34 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Thu Apr  4 23:41:41 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Thu Apr  4 23:45:38 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Thu Apr  4 23:49:49 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1199.3818550109863 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:54:03 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Thu Apr  4 23:57:38 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 00:01:47 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 00:05:45 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 00:10:32 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1239.1185038089752 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:14:42 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 00:18:15 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 00:23:12 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 00:27:57 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 00:32:11 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1299.171433210373 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:36:20 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 00:40:00 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 00:44:05 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 00:48:00 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 00:52:13 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1202.9038631916046 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:56:23 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 00:59:53 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 01:03:56 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 01:07:50 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 01:12:02 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1196.6057267189026 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:16:19 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 01:19:49 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 01:24:14 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 01:28:10 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 01:32:19 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1210.6325104236603 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:36:30 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 01:40:45 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 01:44:52 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 01:49:30 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 01:53:41 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1281.1256194114685 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:57:51 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 02:01:21 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 02:05:33 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 02:09:31 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 02:13:41 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1200.3483431339264 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:17:51 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 02:21:21 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 02:25:23 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 02:29:19 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 02:33:52 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1210.1508042812347 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:38:02 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 02:41:30 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 02:45:40 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 02:49:41 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 02:53:52 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1202.2886159420013 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:58:04 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 03:01:36 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 03:05:38 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 03:09:33 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 03:13:44 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1191.308681488037 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:17:55 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 03:21:24 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 03:25:27 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 03:29:23 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 03:33:54 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1241.8611989021301 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:38:37 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 03:42:09 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 03:46:15 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 03:50:16 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 03:54:27 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1197.552434206009 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 03:58:35 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 04:02:11 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 04:06:16 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 04:10:10 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 04:14:29 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1209.1906180381775 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 04:18:44 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 04:22:11 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 04:26:19 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 04:30:21 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 04:34:32 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1198.9427690505981 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 04:38:43 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 04:42:20 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 04:46:22 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 04:50:19 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 04:54:29 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1195.9474532604218 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 04:58:39 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 05:02:08 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 05:06:10 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 05:10:05 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 05:14:14 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1183.7587101459503 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:18:24 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 05:21:53 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 05:25:56 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 05:30:13 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 05:34:23 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1212.2758646011353 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 05:38:35 2024]  Iteration number: 0 with current cost as 0.32249760293984364 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11097166  0.60435148 -2.68345716
  3.0473839   2.33877916  1.13711314 -1.00057498  0.72190482  1.261595
  1.38661226 -1.80912826  0.70430727]. 
Working on 0.4 fold... 
[Fri Apr  5 05:42:03 2024]  Iteration number: 0 with current cost as 0.31528792348798773 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.1048304   0.60412781 -2.67659137
  3.04345297  2.34874518  1.13821424 -0.99496684  0.7215685   1.26829751
  1.37560859 -1.8201872   0.70162372]. 
Working on 0.6 fold... 
[Fri Apr  5 05:46:35 2024]  Iteration number: 0 with current cost as 0.30337526969785567 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.0999555   0.60631494 -2.66738728
  3.04662043  2.35444557  1.12950731 -0.99701555  0.71722759  1.26445339
  1.37163214 -1.8267227   0.69156416]. 
Working on 0.8 fold... 
[Fri Apr  5 05:50:54 2024]  Iteration number: 0 with current cost as 0.32840146099108164 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10564217  0.60520423 -2.67583697
  3.04733021  2.35058269  1.13048362 -1.01530918  0.72737663  1.24542015
  1.39999255 -1.79503215  0.70989246]. 
Working on 1.0 fold... 
[Fri Apr  5 05:55:13 2024]  Iteration number: 0 with current cost as 0.3192320992444768 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.1179926   0.60263971 -2.6944299
  3.04385561  2.32999761  1.14819684 -0.99450488  0.71698682  1.26742578
  1.38039636 -1.81142821  0.71692202]. 
Training complete taking 1263.730346441269 seconds. 
Discarding model... 

Training complete taking 30297.25213456154 total seconds. 
Now scoring model... 
Scoring complete taking 0.9501466751098633 seconds. 
Saved predicted values as A2-A2-CZ_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (0.13665978863278316,), 'R2_train': 0.7278781886823696, 'MAE_train': 0.3046827070303667, 'MSE_test': 0.15199184660667064, 'R2_test': 0.7165405333354231, 'MAE_test': 0.35510654913443745}. 
Saved model results as A2-A2-CZ_HWE-CNOT_results.json. 
