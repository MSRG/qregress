/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:35 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:56 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:41:49 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:44:42 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Thu Apr  4 21:47:42 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:50:26 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 870.3303320407867 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:26 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:56:20 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:59:13 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Thu Apr  4 22:02:14 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:04:59 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 871.4694418907166 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:06:58 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:10:51 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:13:44 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Thu Apr  4 22:16:51 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:19:38 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 878.9627356529236 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:21:38 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:25:29 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:28:21 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Thu Apr  4 22:31:22 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:34:07 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 869.0217308998108 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:36:07 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:39:58 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:42:51 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Thu Apr  4 22:45:51 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:48:37 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 870.3398826122284 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:50:37 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:54:29 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:57:22 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Thu Apr  4 23:00:22 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:03:09 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 871.4939863681793 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:05:09 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:09:02 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:11:54 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Thu Apr  4 23:14:55 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:17:47 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 878.888091802597 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:19:48 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:23:43 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:26:36 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Thu Apr  4 23:29:36 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:32:29 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 881.7988214492798 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:34:28 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:38:29 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:41:21 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Thu Apr  4 23:44:20 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:47:03 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 874.5242438316345 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:49:03 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:52:57 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:55:50 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Thu Apr  4 23:58:49 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:01:46 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 884.6629712581635 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:03:49 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:07:45 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:10:36 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 00:13:35 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:16:20 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 874.6692807674408 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:18:24 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:22:16 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:25:11 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 00:28:10 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:30:54 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 881.1405689716339 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:33:03 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:36:56 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:39:48 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 00:42:51 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:45:37 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 873.8222043514252 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:47:37 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:51:54 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:54:54 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 00:57:54 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:00:52 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 913.3805272579193 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:02:52 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:06:49 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:09:43 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 01:12:54 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:15:37 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 906.7523005008698 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:18:03 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:22:01 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:24:53 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 01:27:53 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:30:38 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 880.989679813385 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:32:38 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:36:33 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:39:25 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 01:42:32 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:45:17 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 877.1131823062897 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:47:17 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:51:07 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:53:59 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 01:56:59 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:59:43 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 867.5689976215363 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:01:43 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:05:35 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:08:28 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 02:11:37 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:14:22 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 878.002720117569 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:16:22 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:20:20 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:23:34 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 02:26:34 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:29:19 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 896.2005136013031 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:31:19 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:35:10 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:38:03 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 02:41:03 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:43:48 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 869.2374129295349 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:45:48 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:49:39 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:52:32 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 02:55:31 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:58:59 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 913.4393713474274 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:01:01 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:05:01 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:08:00 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 03:10:59 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:13:47 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 906.8202774524689 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:16:09 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:20:00 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:22:53 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 03:26:13 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:28:57 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 889.0375583171844 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 03:30:57 2024]  Iteration number: 0 with current cost as 0.4939543753069137 and parameters 
[-3.39131308  1.28494869 -0.58683817 -0.11653095  0.55388712 -2.77010894
  3.06858498  2.18960153  1.18552002 -1.06648308  0.60271518  1.14432445
  1.31029902 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:34:52 2024]  Iteration number: 0 with current cost as 0.4161094188632901 and parameters 
[-3.32857368  1.25553037 -0.66519768 -0.11653099  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:37:46 2024]  Iteration number: 0 with current cost as 0.44780606991918415 and parameters 
[-3.36119347  1.21395862 -0.57979629 -0.11653095  0.55388712 -2.77010897
  3.06858495  2.18960149  1.18552002 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Fri Apr  5 03:40:57 2024]  Iteration number: 0 with current cost as 0.40724105033719565 and parameters 
[-3.32246264  1.30688815 -0.71541433 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:43:41 2024]  Iteration number: 0 with current cost as 0.4661903164502597 and parameters 
[-3.29872747  1.28162547 -0.7339592  -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648308  0.60271507  1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Training complete taking 883.9746625423431 seconds. 
Discarding model... 

Training complete taking 22063.643012046814 total seconds. 
Now scoring model... 
Scoring complete taking 1.1480083465576172 seconds. 
Saved predicted values as M-A2-CZ_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (0.15596322208342434,), 'R2_train': 0.689440508309888, 'MAE_train': 0.3396397764086346, 'MSE_test': 0.16644189307895518, 'R2_test': 0.689591703133288, 'MAE_test': 0.3685552711448387}. 
Saved model results as M-A2-CZ_HWE-CZ_results.json. 
