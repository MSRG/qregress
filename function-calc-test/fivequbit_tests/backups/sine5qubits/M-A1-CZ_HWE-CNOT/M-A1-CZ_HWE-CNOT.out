/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:34 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:48 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Thu Apr  4 21:42:09 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Thu Apr  4 21:46:20 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Thu Apr  4 21:50:41 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Thu Apr  4 21:54:52 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1269.563315629959 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:58:56 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Thu Apr  4 22:03:27 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Thu Apr  4 22:07:41 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Thu Apr  4 22:11:56 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Thu Apr  4 22:16:17 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1312.4756982326508 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:20:50 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Thu Apr  4 22:25:06 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Thu Apr  4 22:29:14 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Thu Apr  4 22:33:30 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Thu Apr  4 22:37:48 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1260.9374101161957 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:41:51 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Thu Apr  4 22:46:06 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Thu Apr  4 22:50:15 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Thu Apr  4 22:54:34 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Thu Apr  4 22:58:46 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1258.296766757965 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:02:49 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Thu Apr  4 23:07:27 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Thu Apr  4 23:11:52 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Thu Apr  4 23:16:07 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Thu Apr  4 23:20:21 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1296.6803424358368 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:24:26 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Thu Apr  4 23:28:41 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Thu Apr  4 23:32:56 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Thu Apr  4 23:37:13 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Thu Apr  4 23:41:24 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1262.8427393436432 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:45:28 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Thu Apr  4 23:49:48 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Thu Apr  4 23:54:03 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Thu Apr  4 23:58:22 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 00:02:34 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1272.4935972690582 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:06:40 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 00:11:05 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 00:15:14 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 00:19:35 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 00:24:30 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1315.7419564723969 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:28:35 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 00:33:09 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 00:37:20 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 00:41:36 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 00:45:50 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1281.9886536598206 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:49:59 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 00:54:33 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 00:58:45 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 01:03:02 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 01:07:13 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1279.5040860176086 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:11:17 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 01:15:35 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 01:19:47 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 01:24:05 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 01:28:13 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1260.304889202118 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:32:17 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 01:36:36 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 01:41:00 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 01:45:26 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 01:49:38 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1284.2326483726501 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:53:41 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 01:58:00 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 02:02:22 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 02:06:40 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 02:11:15 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1297.0522356033325 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:15:18 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 02:19:35 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 02:23:59 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 02:28:16 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 02:32:29 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1276.5694251060486 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:36:36 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 02:41:34 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 02:45:47 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 02:50:09 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 02:54:20 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1329.1252448558807 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:58:44 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 03:03:02 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 03:07:31 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 03:11:45 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 03:16:00 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1289.22940325737 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 03:20:13 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 03:24:57 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 03:29:22 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 03:33:41 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 03:37:51 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1302.9215307235718 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:41:56 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 03:46:21 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 03:50:52 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 03:55:09 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 03:59:25 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1294.3495993614197 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 04:03:32 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 04:07:59 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 04:12:12 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 04:16:40 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 04:21:16 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1317.7300527095795 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 04:25:28 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 04:30:13 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 04:34:23 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 04:38:45 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 04:42:56 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1305.1877145767212 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 04:47:15 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 04:51:31 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 04:55:42 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 05:00:19 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 05:04:46 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1297.8171441555023 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 05:08:51 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 05:13:12 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 05:17:25 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 05:21:45 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 05:26:12 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1282.7943301200867 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 05:30:16 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 05:34:33 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 05:38:47 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 05:43:04 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 05:47:14 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1262.1713280677795 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:51:18 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 05:55:35 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 05:59:46 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 06:04:02 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 06:08:21 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1267.0232031345367 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 06:12:23 2024]  Iteration number: 0 with current cost as 0.29959241378115364 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.16317562  0.58789564 -2.77096306
  3.10822646  2.27300007  1.06968455 -1.06663478  0.72306952  1.18176999
  1.44482304 -1.76527518  0.66605714]. 
Working on 0.4 fold... 
[Fri Apr  5 06:16:42 2024]  Iteration number: 0 with current cost as 0.30131300103753755 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.15900253  0.58693897 -2.76757512
  3.10850441  2.27064424  1.07054701 -1.06759151  0.72528583  1.18130157
  1.45569656 -1.75858566  0.65353492]. 
Working on 0.6 fold... 
[Fri Apr  5 06:20:52 2024]  Iteration number: 0 with current cost as 0.29442131260906623 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1642553   0.58742944 -2.77297267
  3.10682807  2.27549933  1.07067197 -1.07455844  0.72561166  1.17294637
  1.4569005  -1.75889848  0.64837698]. 
Working on 0.8 fold... 
[Fri Apr  5 06:25:13 2024]  Iteration number: 0 with current cost as 0.3027067918054052 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.17694774  0.59773828 -2.77153054
  3.11430663  2.28623876  1.0516632  -1.07035298  0.7440717   1.183823
  1.43775018 -1.77133798  0.66807538]. 
Working on 1.0 fold... 
[Fri Apr  5 06:29:24 2024]  Iteration number: 0 with current cost as 0.293376739894689 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.15070069  0.58137647 -2.76664459
  3.10494717  2.26508157  1.07984746 -1.05939842  0.71096688  1.18677013
  1.45040136 -1.75963917  0.66752379]. 
Training complete taking 1264.9424090385437 seconds. 
Discarding model... 

Training complete taking 32141.977592229843 total seconds. 
Now scoring model... 
Scoring complete taking 1.0202524662017822 seconds. 
Saved predicted values as M-A1-CZ_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (0.23091089018737163,), 'R2_train': 0.5402020570981596, 'MAE_train': 0.3983303106998178, 'MSE_test': 0.31987327067758475, 'R2_test': 0.40344756162372575, 'MAE_test': 0.47428598829206675}. 
Saved model results as M-A1-CZ_HWE-CNOT_results.json. 
