/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:49 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:12 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:03:33 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 16:04:54 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:06:13 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:07:32 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 387.1846134662628 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:08:39 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:09:59 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 16:11:22 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:12:42 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:14:05 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 394.11152720451355 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:15:13 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:16:34 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 16:17:53 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:19:11 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:20:34 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 390.16294622421265 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:43 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:23:04 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 16:24:26 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:25:48 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:27:16 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 401.7350194454193 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:28:26 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:29:47 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 16:31:11 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:35 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:33:56 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 401.69867610931396 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:35:08 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:36:28 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 16:37:49 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:39:12 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:40:36 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 400.2061676979065 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:41:49 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:43:13 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:38 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:45:59 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:47:22 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 407.9580149650574 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:48:37 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:49:58 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 16:51:21 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:49 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:54:12 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 410.64958214759827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:55:28 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:56:55 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 16:58:18 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:59:43 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:01:08 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 410.6072232723236 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:02:17 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:03:42 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 17:05:05 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:06:29 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:07:53 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 406.93371200561523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:09:04 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:10:30 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 17:11:55 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:13:17 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:41 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 407.01486349105835 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:15:51 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:17:15 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 17:18:38 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:20:01 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:21:24 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 401.16405606269836 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:22:33 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:23:56 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 17:25:16 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:26:35 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:27:56 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 393.74900245666504 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:29:06 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:30:28 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 17:31:49 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:33:11 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:34:32 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 394.42931604385376 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:35:40 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:37:01 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 17:38:21 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:39:44 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:41:07 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 396.8450503349304 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:42:17 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:43:38 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 17:45:00 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:46:22 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:47:43 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 396.6935040950775 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:48:53 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:50:15 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 17:51:36 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:52:57 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:54:20 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 396.6427960395813 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:55:31 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:56:51 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 17:58:12 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:59:32 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:00:57 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 396.58112835884094 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:02:07 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:03:29 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 18:04:49 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:06:08 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:07:26 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 386.6653790473938 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:08:33 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:09:51 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 18:11:09 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:12:30 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:13:49 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 384.5114936828613 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:14:58 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:16:17 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 18:17:36 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:18:54 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:20:13 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 386.50908851623535 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:21:23 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:22:41 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 18:23:59 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:25:16 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:26:34 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 376.50444436073303 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:27:40 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:28:59 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 18:30:17 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:31:37 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:32:54 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 381.61706495285034 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:34:02 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:35:19 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 18:36:37 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:37:55 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:39:13 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 381.3241102695465 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:40:22 2024]  Iteration number: 0 with current cost as 0.2075498772712 and parameters 
[-2.7157713   2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:41:41 2024]  Iteration number: 0 with current cost as 0.19490789649467605 and parameters 
[-2.71957293  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Mon Apr  1 18:42:59 2024]  Iteration number: 0 with current cost as 0.18695019905037563 and parameters 
[-2.73683039  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:44:17 2024]  Iteration number: 0 with current cost as 0.13625564880428864 and parameters 
[-2.77644756  2.23743464 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:45:34 2024]  Iteration number: 0 with current cost as 0.1470892722094368 and parameters 
[-2.77446455  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308]. 
Training complete taking 376.88492488861084 seconds. 
Discarding model... 

Training complete taking 9868.384788036346 total seconds. 
Now scoring model... 
Scoring complete taking 1.827718734741211 seconds. 
Saved predicted values as A1-A1-CNOT_ESU2_predicted_values.csv
Model scores: {'MSE_train': (3.4618950017584176,), 'R2_train': 0.5246557558434428, 'MAE_train': 1.2526023693766641, 'MSE_test': 1.817618864552801, 'R2_test': 0.818800378929691, 'MAE_test': 1.1381974441528366}. 
Saved model results as A1-A1-CNOT_ESU2_results.json. 
