/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:46:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:46:42 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 15:50:02 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 15:53:19 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 15:57:01 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 16:01:09 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1083.4360835552216 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:04:45 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:05 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 16:11:19 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 16:15:01 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 16:19:10 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1079.8286926746368 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:22:45 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 16:26:08 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 16:29:28 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 16:33:13 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 16:37:27 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1103.373496055603 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:41:08 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 16:44:34 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 16:47:56 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 16:51:38 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 16:56:02 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1107.576605796814 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:59:36 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 17:03:00 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 17:06:11 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 17:09:54 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:02 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1082.2231004238129 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:17:38 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 17:20:57 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 17:24:10 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 17:27:56 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 17:32:10 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1087.3578426837921 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:35:45 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 17:39:07 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 17:42:21 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 17:46:03 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 17:50:09 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1079.0470340251923 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:53:44 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 17:57:05 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 18:00:16 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 18:03:59 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 18:08:08 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1080.8864562511444 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:11:45 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 18:15:16 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 18:18:32 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 18:22:11 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 18:26:21 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1106.5477516651154 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:30:12 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 18:33:36 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 18:36:49 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 18:40:28 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 18:44:35 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1077.4511630535126 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:48:09 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 18:51:30 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 18:54:42 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 18:58:21 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 19:02:37 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1083.1388874053955 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:06:12 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 19:09:31 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 19:12:46 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 19:16:24 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 19:20:31 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1071.5492615699768 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:24:06 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 19:27:23 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 19:30:37 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 19:34:23 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 19:38:32 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1081.2012360095978 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:42:07 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 19:45:24 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 19:48:37 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 19:52:15 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 19:56:21 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1070.3032040596008 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:59:55 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 20:03:16 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 20:06:29 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 20:10:11 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 20:14:18 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1077.537228345871 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 20:17:53 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 20:21:13 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 20:24:25 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 20:28:05 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 20:32:12 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1074.4314768314362 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:35:47 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 20:39:07 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 20:42:20 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 20:46:01 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 20:50:23 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1090.555688381195 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:53:58 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 20:57:17 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 21:00:29 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 21:04:11 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 21:08:16 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1072.9747426509857 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 21:11:51 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 21:15:11 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 21:18:24 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 21:22:04 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 21:26:21 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1085.3158469200134 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:29:56 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 21:33:17 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 21:36:29 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 21:40:10 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 21:44:15 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1084.1278865337372 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 21:48:00 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 21:51:20 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 21:54:33 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 21:58:15 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 22:02:22 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1077.2637288570404 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 22:05:58 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 22:09:22 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 22:12:35 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 22:16:16 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 22:20:22 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1078.10027718544 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 22:23:56 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 22:27:15 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 22:30:28 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 22:34:07 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 22:38:16 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1071.7149477005005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:41:50 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 22:45:07 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 22:48:22 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 22:52:01 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 22:56:07 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1073.4330744743347 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:59:43 2024]  Iteration number: 0 with current cost as 0.38442969227425133 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09739366  0.57335016 -2.71670855
  2.93003611  2.21889859  1.40768702 -1.07673973  0.68222083  1.15673207
  1.37530963 -1.78772374  0.81884408]. 
Working on 0.4 fold... 
[Mon Apr  1 23:03:00 2024]  Iteration number: 0 with current cost as 0.36035645507228886 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10438771  0.57208419 -2.72694195
  2.94283235  2.21773958  1.38628698 -1.07461933  0.66795656  1.15484618
  1.36385006 -1.80032073  0.81218345]. 
Working on 0.6 fold... 
[Mon Apr  1 23:06:14 2024]  Iteration number: 0 with current cost as 0.4064991139605232 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11208675  0.57353388 -2.73369299
  2.92125666  2.20286447  1.43195379 -1.07137535  0.68030581  1.16264509
  1.39243523 -1.77824229  0.79534702]. 
Working on 0.8 fold... 
[Mon Apr  1 23:09:53 2024]  Iteration number: 0 with current cost as 0.37072250262065803 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.10046493  0.56845341 -2.72809361
  2.91566527  2.20743932  1.43898774 -1.06646518  0.67845435  1.1680266
  1.39420994 -1.77917267  0.78606385]. 
Working on 1.0 fold... 
[Mon Apr  1 23:14:00 2024]  Iteration number: 0 with current cost as 0.33568551642610683 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12280685  0.57140318 -2.74968027
  2.94096327  2.18816225  1.40635341 -1.06575764  0.6658212   1.16493565
  1.37233406 -1.804955    0.76713721]. 
Training complete taking 1074.6740100383759 seconds. 
Discarding model... 

Training complete taking 27054.051226615906 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 0.8860535621643066 seconds. 
Saved predicted values as M-A1-CNOT_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (2.734608885657008,), 'R2_train': 0.6245176144405938, 'MAE_train': 1.1277695972875819, 'MSE_test': 7.157401669137682, 'R2_test': 0.28647391618328455, 'MAE_test': 1.8771800323195122}. 
Saved model results as M-A1-CNOT_HWE-CNOT_results.json. 
