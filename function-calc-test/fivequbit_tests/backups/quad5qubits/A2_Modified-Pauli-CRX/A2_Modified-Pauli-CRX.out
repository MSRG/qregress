/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:49 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:04 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:05:08 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:08:18 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:11:20 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:14:38 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 947.7367269992828 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:17:53 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:20:55 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:24:05 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:27:06 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:30:25 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 941.2075605392456 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:33:33 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:36:36 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:39:52 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:42:54 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:46:21 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 974.2375798225403 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:49:48 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:52:53 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:56:04 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:59:06 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:02:34 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 973.7911062240601 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:06:01 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:09:32 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:12:42 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:15:44 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:19:02 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 969.7944369316101 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:22:11 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:25:19 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:28:28 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:31:29 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:34:48 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 948.103931427002 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:38:00 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:41:06 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:44:16 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:47:21 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:50:37 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 946.9490959644318 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:53:46 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:56:49 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:00:03 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:03:13 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:06:33 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 956.0556609630585 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:09:42 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:12:47 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:16:04 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:19:08 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:22:35 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 962.4544579982758 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:25:44 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:28:47 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:31:55 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:35:06 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:38:23 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 958.7403392791748 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:41:43 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:45:14 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:48:24 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:51:47 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:55:10 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 996.6922154426575 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:58:20 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:01:21 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:04:31 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:07:31 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:10:46 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 936.118396282196 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:13:57 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:16:58 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:20:07 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:23:10 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:26:35 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 949.2663719654083 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:29:45 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:32:46 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:35:57 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:38:58 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:42:20 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 941.1026229858398 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:45:29 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:48:29 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:51:40 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:54:42 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:58:05 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 951.8687479496002 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 20:01:18 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:04:20 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:07:41 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:10:42 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:14:15 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 966.1520917415619 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:17:24 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:20:25 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:23:41 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:26:41 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:30:04 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 946.8337411880493 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:33:13 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:36:14 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:39:50 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:42:54 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:46:18 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 975.9056193828583 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:49:27 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:52:29 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:55:39 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:58:40 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:01:55 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 935.8551898002625 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:05:05 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:08:06 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:11:15 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:14:16 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:17:34 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 938.4023151397705 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 21:20:43 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:23:52 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:27:00 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:30:04 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:33:22 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 958.3917384147644 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:36:41 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:39:41 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:42:49 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:45:51 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:49:09 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 939.5690417289734 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 21:52:19 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:55:22 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:58:34 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:01:36 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:04:51 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 940.387574672699 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:08:00 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:11:06 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:14:21 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:17:22 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:20:41 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 948.5026397705078 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:23:49 2024]  Iteration number: 0 with current cost as 0.131544022589468 and parameters 
[-3.36129061  2.35702913 -2.1511184  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  1.08785027  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:26:51 2024]  Iteration number: 0 with current cost as 0.14363652588885312 and parameters 
[-3.41731475  2.38955149 -2.152614   -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   1.11341534  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:29:59 2024]  Iteration number: 0 with current cost as 0.14666585894079415 and parameters 
[-3.36304466  2.37130397 -2.14967717 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  1.06454259  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:33:00 2024]  Iteration number: 0 with current cost as 0.12450766153532493 and parameters 
[-3.31947365  2.36758054 -2.14666849 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  1.00459291  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:36:26 2024]  Iteration number: 0 with current cost as 0.13814213355239935 and parameters 
[-3.3974377   2.40775605 -2.14791122 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.0664831   1.0496626   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 947.1812417507172 seconds. 
Discarding model... 

Training complete taking 23851.301874399185 total seconds. 
Now scoring model... 
Scoring complete taking 0.9328398704528809 seconds. 
Saved predicted values as A2_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (1.0930288936188681,), 'R2_train': 0.8499189048152432, 'MAE_train': 0.8489491423389502, 'MSE_test': 1.690228284633201, 'R2_test': 0.8315000296978061, 'MAE_test': 1.0466089267227}. 
Saved model results as A2_Modified-Pauli-CRX_results.json. 
