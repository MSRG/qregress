/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:54:27 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:55:12 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:56:23 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:57:34 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:58:46 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:59:56 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 360.34396481513977 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:01:10 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:02:20 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:03:31 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:04:43 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:05:53 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 357.25223541259766 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:07:04 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:17 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:09:29 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:10:41 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:11:52 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 360.7713351249695 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:13:05 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:14:21 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:15:31 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:16:46 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:17:57 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 362.68294286727905 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:19:09 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:20:19 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:21:30 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:22:45 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:23:56 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 363.741881608963 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:25:13 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:26:26 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:27:36 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:28:48 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:29:58 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 357.6496751308441 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:31:10 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:32:21 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:33:36 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:34:50 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:36:00 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 362.58504915237427 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:37:13 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:38:24 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:39:36 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:40:48 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:41:59 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 358.4250919818878 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:43:12 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:44:23 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:45:34 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:46:46 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:47:56 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 357.5165801048279 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:49:07 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:50:21 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:51:32 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:45 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:53:56 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 359.4901554584503 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:55:07 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:56:19 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:57:29 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:58:40 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:59:51 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 354.5101203918457 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:01:01 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:02:23 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:03:33 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:04:44 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:05:54 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 363.41665172576904 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:07:04 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:08:24 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:09:34 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:10:48 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:11:59 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 370.97912073135376 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:13:22 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:14:32 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:15:44 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:16:54 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:18:05 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 359.4290769100189 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:19:16 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:20:27 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:21:38 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:22:52 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:24:05 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 360.0101709365845 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:25:16 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:26:26 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:27:36 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:28:48 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:29:59 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 356.1165204048157 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:31:14 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:32:33 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:33:45 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:34:55 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:36:04 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 365.75596165657043 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:37:18 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:38:30 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:39:40 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:40:53 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:42:13 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 367.04148626327515 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:43:24 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:44:35 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:45:46 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:46:56 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:48:06 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 352.558650970459 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:49:18 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:50:28 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:51:39 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:52:51 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:54:04 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 358.108922958374 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:55:16 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:56:26 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:57:46 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:58:58 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:00:09 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 364.995756149292 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:01:21 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:02:32 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:03:44 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:04:55 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:06:05 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 355.8322203159332 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:07:17 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:08:27 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:09:38 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:10:51 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:12:01 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 356.0491552352905 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:13:11 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:14:23 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:15:34 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:16:48 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:17:58 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 357.4923174381256 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:19:09 2024]  Iteration number: 0 with current cost as 0.15958078329955624 and parameters 
[-2.49771542  2.23743462 -2.12427965 -0.11653101  0.5538871  -2.77010897
  3.06858496  2.18960145  1.18552    -1.0664831   0.60271512  1.14432447
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:20:21 2024]  Iteration number: 0 with current cost as 0.16883560064035785 and parameters 
[-2.45188492  2.23743462 -2.12427962 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551997 -1.0664831   0.60271508  1.14432443
  1.31029897 -1.8735468   0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:21:32 2024]  Iteration number: 0 with current cost as 0.1642196385903082 and parameters 
[-2.51311811  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354676  0.7296508   2.88578421 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:22:42 2024]  Iteration number: 0 with current cost as 0.12811785337641057 and parameters 
[-2.52172059  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:23:59 2024]  Iteration number: 0 with current cost as 0.14843409407278668 and parameters 
[-2.45687503  2.23743461 -2.12427964 -0.11653105  0.55388708 -2.77010899
  3.06858494  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468   0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 360.4907410144806 seconds. 
Discarding model... 

Training complete taking 9003.247255563736 total seconds. 
Now scoring model... 
Scoring complete taking 0.942887544631958 seconds. 
Saved predicted values as A1-A1-CZ_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (3.3796152478095323,), 'R2_train': 0.5359533854452518, 'MAE_train': 1.2918253753315605, 'MSE_test': 6.433428338324864, 'R2_test': 0.3586472940936024, 'MAE_test': 1.9329044106606676}. 
Saved model results as A1-A1-CZ_Modified-Pauli-CRZ_results.json. 
