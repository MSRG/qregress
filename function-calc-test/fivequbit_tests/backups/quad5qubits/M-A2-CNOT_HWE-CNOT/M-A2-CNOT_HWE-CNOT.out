/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:44:07 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:44:21 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 15:48:03 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 15:52:02 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 15:56:09 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 16:00:16 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1209.4532256126404 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:04:28 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:08 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 16:12:10 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 16:16:29 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 16:20:35 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1218.0683479309082 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:24:48 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 16:28:26 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 16:32:26 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 16:36:33 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 16:40:48 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1220.2397000789642 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:45:06 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 16:48:47 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 16:52:49 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 16:56:59 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 17:01:10 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1239.4391503334045 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:47 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 17:09:28 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 17:13:30 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 17:17:40 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 17:21:45 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1219.6325335502625 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:26:05 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 17:29:42 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 17:33:45 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 17:37:57 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 17:42:03 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1206.9364955425262 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:46:12 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 17:49:46 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 17:53:51 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 17:57:54 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 18:02:02 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1199.841789484024 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:06:12 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 18:09:51 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 18:13:53 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 18:18:09 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 18:22:12 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1208.2697653770447 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:26:22 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 18:30:01 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 18:34:12 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 18:38:17 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 18:42:26 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1218.3495035171509 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:46:39 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 18:50:13 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 18:54:28 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 18:58:31 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 19:02:47 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1235.0139384269714 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:07:14 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 19:10:51 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 19:14:54 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 19:18:59 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 19:23:04 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1199.6150259971619 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:27:13 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 19:30:49 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 19:34:48 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 19:38:53 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 19:43:15 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1224.7513649463654 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:47:38 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 19:51:18 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 19:55:28 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 19:59:35 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 20:03:39 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1212.7314212322235 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:07:51 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 20:11:26 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 20:15:28 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 20:19:33 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 20:23:37 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1195.472196817398 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 20:27:46 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 20:31:20 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 20:35:18 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 20:39:32 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 20:43:48 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1212.4604051113129 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 20:48:00 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 20:51:37 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 20:55:38 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 20:59:42 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 21:03:46 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1201.2544214725494 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:08:02 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 21:11:57 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 21:15:57 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 21:20:03 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 21:24:16 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1237.9631342887878 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 21:28:42 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 21:32:18 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 21:36:18 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 21:40:51 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 21:44:55 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1227.738202571869 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 21:49:07 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 21:52:45 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 21:56:46 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 22:00:53 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 22:04:57 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1205.8248271942139 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:09:13 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 22:12:47 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 22:16:47 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 22:20:51 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 22:24:56 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1193.9951293468475 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 22:29:07 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 22:32:43 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 22:36:42 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 22:40:46 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 22:44:50 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1195.4036095142365 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 22:49:01 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 22:52:38 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 22:56:36 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 23:00:42 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 23:04:48 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1196.5509121418 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 23:08:57 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 23:12:32 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 23:16:30 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 23:20:33 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 23:24:40 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1190.8085725307465 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 23:28:50 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 23:32:27 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 23:36:26 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Mon Apr  1 23:40:31 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Mon Apr  1 23:44:35 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1194.3975512981415 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 23:48:44 2024]  Iteration number: 0 with current cost as 0.3442731417906373 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1510718   0.58574027 -2.76015319
  2.94645029  2.19024523  1.39570782 -1.11386587  0.60161325  1.08646258
  1.42541656 -1.7725256   0.70519137]. 
Working on 0.4 fold... 
[Mon Apr  1 23:52:19 2024]  Iteration number: 0 with current cost as 0.34844310709684356 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14940633  0.58117204 -2.76544725
  2.96337736  2.18792829  1.36784583 -1.10611049  0.5958552   1.09407644
  1.42123784 -1.77891813  0.69632206]. 
Working on 0.6 fold... 
[Mon Apr  1 23:56:19 2024]  Iteration number: 0 with current cost as 0.3707688084867351 and parameters 
[-2.90318345  2.23743463 -2.12427963 -0.14980614  0.58292246 -2.76313846
  2.93678232  2.19549234  1.4093867  -1.0993022   0.59663046  1.10258334
  1.44747804 -1.75291569  0.70139851]. 
Working on 0.8 fold... 
[Tue Apr  2 00:00:24 2024]  Iteration number: 0 with current cost as 0.3395575861256701 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14156151  0.58867626 -2.74430994
  2.94359135  2.18548466  1.40334761 -1.09861178  0.60383186  1.105673
  1.45106427 -1.75227852  0.69165115]. 
Working on 1.0 fold... 
[Tue Apr  2 00:04:29 2024]  Iteration number: 0 with current cost as 0.3189998841196473 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15722151  0.58815587 -2.7635491
  2.97105314  2.17726015  1.36068864 -1.09415324  0.59089862  1.10704149
  1.4322463  -1.77257357  0.68211233]. 
Training complete taking 1197.193142414093 seconds. 
Discarding model... 

Training complete taking 30261.405855178833 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 0.928351879119873 seconds. 
Saved predicted values as M-A2-CNOT_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (2.4599052731542885,), 'R2_train': 0.6622364883480507, 'MAE_train': 1.1126924090292172, 'MSE_test': 6.784662493522516, 'R2_test': 0.32363252995908554, 'MAE_test': 1.8104143452247983}. 
Saved model results as M-A2-CNOT_HWE-CNOT_results.json. 
