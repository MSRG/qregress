/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:05:51 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:06:43 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:17 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:09:31 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:10:53 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:12:21 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 443.13138222694397 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:14:08 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:15:42 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:16:55 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:18:18 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:19:44 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 443.7665991783142 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:30 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:23:05 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:24:17 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:25:41 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:27:01 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 435.2432177066803 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:28:45 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:30:21 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:31:37 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:33:03 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:34:29 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 449.13563561439514 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:36:15 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:37:48 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:39:02 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:40:26 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:41:50 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 441.7651674747467 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:43:39 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:45:14 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:46:27 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:47:50 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:49:16 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 444.4320912361145 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:51:01 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:52:37 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:53:50 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:55:15 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:56:40 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 443.2972209453583 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:58:24 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:00:01 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:01:16 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:02:41 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:04:07 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 449.4613597393036 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:57 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:07:31 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:08:44 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:10:08 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:11:33 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 445.00949454307556 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:13:20 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:14:55 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:16:08 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:17:34 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:19:02 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 448.71211433410645 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:20:50 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:22:24 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:23:38 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:25:02 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:26:27 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 445.161687374115 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:28:13 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:29:48 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:31:03 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:32:29 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:33:52 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 443.31265568733215 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:35:38 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:37:14 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:38:26 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:39:52 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:41:17 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 445.45891070365906 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:42:59 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:44:34 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:45:49 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:47:12 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:48:36 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 439.27066946029663 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:50:21 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:51:55 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:53:10 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:54:36 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:56:01 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 446.36393451690674 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:57:46 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:59:20 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:00:33 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:01:57 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:03:19 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 437.06135749816895 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:05:06 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:06:40 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:07:52 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:09:15 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:10:39 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 439.2788383960724 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:12:23 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:13:59 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:15:14 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:16:38 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:18:01 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 442.15886878967285 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:19:45 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:21:18 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:22:31 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:23:54 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:25:17 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 438.34874081611633 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:27:05 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:28:39 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:29:50 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:31:15 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:32:39 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 439.70714020729065 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:34:23 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:35:59 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:37:14 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:38:39 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:40:02 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 443.8079364299774 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:41:46 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:43:18 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:44:32 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:45:54 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:47:22 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 441.257848739624 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:49:08 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:50:43 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:51:56 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:53:22 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:54:47 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 443.8153064250946 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:56:32 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:58:09 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:59:22 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:00:45 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:02:12 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 443.8624360561371 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:03:58 2024]  Iteration number: 0 with current cost as 0.22370737718576789 and parameters 
[-2.58363733  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010895
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 19:05:31 2024]  Iteration number: 0 with current cost as 0.21423925903454932 and parameters 
[-2.54236877  2.23743462 -2.12427965 -0.11653103  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:06:48 2024]  Iteration number: 0 with current cost as 0.20903756349760488 and parameters 
[-2.74175709  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:08:11 2024]  Iteration number: 0 with current cost as 0.1538269330665162 and parameters 
[-2.77810075  2.23743463 -2.12427963 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:09:34 2024]  Iteration number: 0 with current cost as 0.1645571858757609 and parameters 
[-2.74708956  2.23743464 -2.12427964 -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 443.1716160774231 seconds. 
Discarding model... 

Training complete taking 11075.992989778519 total seconds. 
Now scoring model... 
Scoring complete taking 1.894237995147705 seconds. 
Saved predicted values as A2-A2-CNOT_ESU2_predicted_values.csv
Model scores: {'MSE_train': (4.229172985436823,), 'R2_train': 0.4193027127776294, 'MAE_train': 1.2676606238849146, 'MSE_test': 4.275530836066503, 'R2_test': 0.5737695165480793, 'MAE_test': 1.5612933040703294}. 
Saved model results as A2-A2-CNOT_ESU2_results.json. 
