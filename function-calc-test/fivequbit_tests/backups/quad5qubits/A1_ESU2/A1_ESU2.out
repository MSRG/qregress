/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:44:16 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:44:58 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:46:23 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 15:47:35 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:48:57 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 15:51:12 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 436.668518781662 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:52:18 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:53:44 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 15:55:00 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:56:22 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 15:58:35 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 442.2876718044281 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 15:59:36 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:00:57 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:02:10 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:03:32 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:05:46 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 431.34425473213196 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:06:50 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:19 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:09:33 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:11:02 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:13:17 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 451.2250690460205 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:14:19 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:15:41 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:16:54 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:18:17 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:20:32 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 435.2015917301178 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:34 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:22:59 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:24:11 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:25:31 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:27:47 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 434.6990475654602 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:28:52 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:30:15 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:31:31 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:54 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:35:09 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 442.62484431266785 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:36:15 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:37:38 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:38:49 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:40:16 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:42:30 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 440.6723918914795 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:43:35 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:45:00 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:46:13 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:47:42 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:49:56 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 448.4133448600769 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:51:00 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:52:24 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:53:39 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:55:01 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:57:16 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 436.71309661865234 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:58:17 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:59:41 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:00:55 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:02:21 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:04:37 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 441.5234456062317 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:38 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:07:03 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:08:17 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:09:41 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:11:57 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 441.18372440338135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:13:00 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:14:24 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:15:44 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:17:10 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:19:25 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 447.9423899650574 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:20:28 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:21:53 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:23:16 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:24:38 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:27:05 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 460.0300817489624 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:28:12 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:29:34 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:30:47 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:32:15 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:34:36 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 449.8194031715393 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:35:38 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:37:00 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:38:11 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:39:33 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:41:49 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 433.90769267082214 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:42:54 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:44:19 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:45:30 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:47:02 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:49:15 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 445.1919322013855 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:50:16 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:51:43 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:52:58 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:54:22 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:56:38 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 442.7832832336426 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:57:39 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:59:14 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:00:30 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:01:56 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:04:11 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 453.52027583122253 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:05:14 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:06:36 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:07:48 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:09:12 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:11:27 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 435.5369076728821 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:12:28 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:13:50 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:15:00 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:16:22 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:18:34 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 431.20701146125793 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:19:45 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:21:06 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:22:17 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:23:38 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:25:57 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 439.2592375278473 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:26:57 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:28:24 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:29:39 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:31:02 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:33:18 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 443.9082975387573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:34:26 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:35:47 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:36:58 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:38:24 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:40:39 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 438.0781617164612 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:41:42 2024]  Iteration number: 0 with current cost as 0.3765783681148266 and parameters 
[-2.35845864  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552001 -1.0664831 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:43:03 2024]  Iteration number: 0 with current cost as 0.4571125345568189 and parameters 
[-2.23357965  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:44:19 2024]  Iteration number: 0 with current cost as 0.4260799749393085 and parameters 
[-2.20619484  2.23743467 -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960149  1.18552002 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:45:39 2024]  Iteration number: 0 with current cost as 0.40383311607157263 and parameters 
[-2.38093486  2.23743469 -2.12427958 -0.11653097  0.55388714 -2.77010897
  3.06858501  2.18960151  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:47:53 2024]  Iteration number: 0 with current cost as 0.44550898610183487 and parameters 
[-3.9564665   2.23743867 -2.1242756  -0.11652699  0.5538891  -2.77010696
  3.068587    2.18960347  1.18552402 -1.0664851 ]. 
Training complete taking 434.578373670578 seconds. 
Discarding model... 

Training complete taking 11038.321155548096 total seconds. 
Now scoring model... 
Scoring complete taking 1.7265503406524658 seconds. 
Saved predicted values as A1_ESU2_predicted_values.csv
Model scores: {'MSE_train': (11.409582638074552,), 'R2_train': -0.5666215851383565, 'MAE_train': 2.3444378377848336, 'MSE_test': 9.517617165486012, 'R2_test': 0.05118247972044243, 'MAE_test': 2.255667259546564}. 
Saved model results as A1_ESU2_results.json. 
