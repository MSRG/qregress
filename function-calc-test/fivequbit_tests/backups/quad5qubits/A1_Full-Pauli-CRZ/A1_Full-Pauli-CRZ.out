/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:53 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:07 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 16:05:09 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 16:09:18 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 16:13:48 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 16:18:19 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1277.7800946235657 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:23:23 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 16:26:23 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 16:30:38 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 16:35:01 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 16:39:32 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1274.0138256549835 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:44:38 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 16:47:45 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 16:51:54 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 16:56:21 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 17:00:54 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1283.427791595459 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:06:00 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 17:09:01 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 17:13:07 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 17:17:45 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 17:22:23 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1285.9311501979828 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:27:26 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 17:30:28 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 17:34:36 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 17:39:02 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 17:43:35 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1273.0939424037933 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:48:41 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 17:51:47 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 17:55:53 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 18:00:19 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 18:04:52 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1275.6984734535217 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:09:55 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 18:12:54 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 18:16:55 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 18:21:54 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 18:27:09 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1347.5943615436554 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:32:24 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 18:35:25 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 18:39:30 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 18:43:55 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 18:48:25 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1268.4701550006866 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:53:31 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 18:56:32 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 19:00:36 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 19:05:07 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 19:09:43 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1274.667519569397 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:14:47 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 19:17:47 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 19:21:51 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 19:26:13 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 19:30:47 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1265.1706581115723 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:35:52 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 19:38:52 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 19:42:55 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 19:47:18 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 19:51:46 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1259.4909102916718 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:56:52 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 19:59:55 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 20:04:00 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 20:08:24 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 20:12:54 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1273.7954552173615 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:18:14 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 20:21:16 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 20:25:23 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 20:29:45 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 20:34:16 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1283.9023885726929 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:39:30 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 20:42:30 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 20:46:39 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 20:51:02 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 20:55:34 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1276.127861738205 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:00:44 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 21:03:51 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 21:07:58 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 21:12:27 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 21:16:59 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1276.9779102802277 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 21:22:05 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 21:25:08 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 21:29:42 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 21:34:15 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 21:40:07 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1395.6488800048828 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:45:17 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 21:48:17 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 21:53:44 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 21:58:28 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 22:03:17 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1389.9525299072266 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 22:08:28 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 22:11:30 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 22:15:40 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 22:20:10 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 22:24:45 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1281.4554994106293 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:29:48 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 22:32:52 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 22:37:13 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 22:41:37 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 22:46:09 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1292.3254537582397 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:51:21 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 22:54:23 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 22:58:33 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 23:03:03 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 23:07:51 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1295.4090769290924 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 23:12:56 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 23:15:58 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 23:20:06 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 23:24:28 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 23:28:57 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1268.5899543762207 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 23:34:06 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 23:37:12 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 23:41:28 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  1 23:46:06 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 23:50:39 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1302.724693775177 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 23:55:47 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 23:58:47 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 00:02:59 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  2 00:07:24 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 00:11:55 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1272.511668920517 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 00:16:59 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 00:20:02 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 00:24:21 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  2 00:28:48 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 00:33:19 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1283.2047533988953 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 00:38:23 2024]  Iteration number: 0 with current cost as 0.2638373325964332 and parameters 
[-2.91436337  2.31213948 -2.14328424 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66753289  1.14432445
  1.32338971 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 00:41:24 2024]  Iteration number: 0 with current cost as 0.2864768312356281 and parameters 
[-2.98730995  2.36894547 -2.15042337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71245708  1.14432445
  1.40051025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 00:46:14 2024]  Iteration number: 0 with current cost as 0.29071063534289104 and parameters 
[-2.89783855  2.3678859  -2.15144241 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.70835166  1.14432445
  1.29648866 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  2 00:50:46 2024]  Iteration number: 0 with current cost as 0.24725213853623665 and parameters 
[-2.89018622  2.39519922 -2.15599674 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.72876147  1.14432446
  1.28253408 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 00:55:17 2024]  Iteration number: 0 with current cost as 0.2659738972930844 and parameters 
[-2.99009324  2.45362121 -2.16427233 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.77708762  1.14432445
  1.39120011 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 1336.3911287784576 seconds. 
Discarding model... 

Training complete taking 32314.3573846817 total seconds. 
Now scoring model... 
Scoring complete taking 0.7741143703460693 seconds. 
Saved predicted values as A1_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (4.419506556672699,), 'R2_train': 0.393168480655979, 'MAE_train': 1.6777924064385696, 'MSE_test': 7.2805319727355435, 'R2_test': 0.27419897516604663, 'MAE_test': 2.314835023586921}. 
Saved model results as A1_Full-Pauli-CRZ_results.json. 
