/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:44:07 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:44:57 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:46:34 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:48:17 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:49:58 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:51:26 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 478.6957800388336 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:52:55 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:54:33 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:56:11 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:57:50 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:59:16 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 470.03550362586975 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:00:44 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:02:22 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:04:00 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:05:38 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:07:05 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 467.3440697193146 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:08:44 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:10:22 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:12:09 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:13:46 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:15:24 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 499.32554292678833 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:16:52 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:18:29 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:20:07 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:21:53 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:23:22 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 477.8621551990509 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:24:49 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:26:28 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:28:06 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:29:43 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:31:16 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 475.25630259513855 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:32:45 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:34:35 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:36:36 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:38:13 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:39:40 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 503.0799458026886 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:41:09 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:42:46 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:25 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:46:03 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:47:30 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 496.9147639274597 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:49:26 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:51:04 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:52:40 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:54:17 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:55:46 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 471.0422456264496 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:57:15 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:58:54 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:00:52 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:02:33 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:04:00 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 492.01219940185547 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:28 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:07:06 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:08:43 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:10:20 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:11:48 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 468.8299238681793 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:13:17 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:14:55 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:16:32 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:18:10 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:19:38 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 468.42502760887146 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:21:05 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:22:43 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:24:20 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:25:59 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:27:27 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 469.88033056259155 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:28:56 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:30:33 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:32:10 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:33:55 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:35:37 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 490.7101900577545 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:37:07 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:38:44 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:40:33 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:42:22 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:43:50 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 492.5711314678192 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:45:17 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:46:53 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:48:33 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:50:09 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:51:36 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 464.46879839897156 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:53:05 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:54:47 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:56:45 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:58:22 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:59:48 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 494.46048617362976 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:01:16 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:02:53 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:04:31 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:06:08 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:07:36 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 466.00240182876587 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:09:03 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:10:40 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:12:50 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:14:32 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:15:59 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 503.3511915206909 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:17:25 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:19:06 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:20:41 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:22:20 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:23:47 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 467.793044090271 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:25:15 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:27:13 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:28:59 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:30:38 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:32:05 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 498.0043568611145 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:33:33 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:35:23 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:37:13 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:38:56 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:40:23 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 500.06490421295166 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:41:51 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:43:30 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:45:17 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:47:15 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:48:44 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 499.2315089702606 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:50:11 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:51:50 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:53:27 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:55:09 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:56:36 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 472.07271456718445 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:58:03 2024]  Iteration number: 0 with current cost as 0.1656802648144788 and parameters 
[-2.63993171  2.23743461 -2.12427961 -0.11653103  0.5538871  -2.77010902
  3.06858496  2.18960143  1.18552001 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.87354678  0.72965076  2.88578422 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:59:39 2024]  Iteration number: 0 with current cost as 0.17313270163475394 and parameters 
[-2.62073801  2.2374346  -2.12427962 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:01:22 2024]  Iteration number: 0 with current cost as 0.16753750354151295 and parameters 
[-2.62635376  2.23743456 -2.12427966 -0.11653108  0.55388705 -2.77010903
  3.06858493  2.1896014   1.18551998 -1.06648314  0.60271505  1.1443244
  1.31029896 -1.8735468   0.72965073  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:03:03 2024]  Iteration number: 0 with current cost as 0.1315683515507025 and parameters 
[-2.57114679  2.23743462 -2.12427962 -0.11653106  0.55388708 -2.77010903
  3.06858498  2.18960143  1.18551997 -1.06648312  0.60271508  1.14432445
  1.31029897 -1.8735468   0.72965077  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:04:30 2024]  Iteration number: 0 with current cost as 0.14829497439679118 and parameters 
[-2.4977156   2.23743458 -2.12427966 -0.11653107  0.55388706 -2.77010901
  3.06858496  2.18960141  1.18551998 -1.06648312  0.60271508  1.14432441
  1.31029895 -1.8735468   0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 473.46734619140625 seconds. 
Discarding model... 

Training complete taking 12060.903284311295 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 1.0572764873504639 seconds. 
Saved predicted values as M-M-CZ_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (3.461421919623205,), 'R2_train': 0.5247207135818701, 'MAE_train': 1.4055384775444482, 'MSE_test': 15.279955796458893, 'R2_test': -0.5232688515095418, 'MAE_test': 2.6170934801036188}. 
Saved model results as M-M-CZ_Modified-Pauli-CRZ_results.json. 
