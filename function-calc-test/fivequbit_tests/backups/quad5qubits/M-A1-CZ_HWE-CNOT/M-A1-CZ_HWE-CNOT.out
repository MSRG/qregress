/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:58 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:11 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:06:10 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 16:10:08 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 16:14:28 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 16:18:49 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1295.795026063919 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:23:46 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:27:43 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 16:31:40 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 16:35:59 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 16:40:20 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1289.3140592575073 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:45:15 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:49:12 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 16:53:09 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 16:57:31 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 17:01:53 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1304.7799263000488 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:07:03 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:11:01 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 17:15:04 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 17:19:30 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 17:24:02 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1320.7894639968872 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:29:03 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:33:02 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 17:37:00 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 17:41:19 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 17:45:46 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1306.7071557044983 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:50:48 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:54:46 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 17:58:46 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 18:03:09 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 18:07:32 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1297.877375125885 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:12:26 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:16:23 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 18:20:19 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 18:24:38 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 18:29:18 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1320.8544895648956 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:34:26 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:38:27 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 18:42:39 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 18:47:01 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 18:51:23 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1315.5704953670502 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:56:22 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:00:20 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 19:04:19 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 19:08:35 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 19:13:01 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1294.1972794532776 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:17:56 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:21:57 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 19:25:54 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 19:30:11 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 19:34:44 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1314.6539373397827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:39:51 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:43:48 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 19:47:45 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 19:52:02 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 19:56:24 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1286.7481186389923 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:01:19 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:05:17 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 20:09:14 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 20:13:31 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 20:18:03 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1300.5611095428467 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:22:58 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:27:11 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 20:31:13 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 20:35:30 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 20:39:53 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1328.6653816699982 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:45:07 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:49:04 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 20:53:02 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 20:57:22 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 21:01:56 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1317.5809090137482 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:07:04 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:11:09 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 21:15:07 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 21:19:25 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 21:24:07 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1317.6513185501099 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 21:29:02 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:33:09 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 21:37:06 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 21:41:35 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 21:46:00 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1316.1744153499603 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:50:58 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:54:57 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 21:59:03 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 22:03:27 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 22:07:59 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1317.6398348808289 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 22:12:57 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:16:57 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 22:20:55 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 22:25:11 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 22:29:33 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1289.7776656150818 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:34:27 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:38:27 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 22:42:24 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 22:46:40 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 22:51:03 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1296.09410405159 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:56:02 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:59:59 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 23:03:56 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 23:08:11 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 23:12:37 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1292.3875827789307 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 23:17:34 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:21:32 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 23:25:29 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 23:30:00 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 23:34:27 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1315.746238231659 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 23:39:31 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:43:30 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Mon Apr  1 23:47:27 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Mon Apr  1 23:51:42 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Mon Apr  1 23:56:03 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1287.1426885128021 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 00:00:59 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:05:04 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Tue Apr  2 00:09:01 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Tue Apr  2 00:13:19 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Tue Apr  2 00:17:43 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1310.2410805225372 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 00:22:47 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:27:00 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Tue Apr  2 00:30:57 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Tue Apr  2 00:35:13 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Tue Apr  2 00:39:36 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1302.8451797962189 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 00:44:32 2024]  Iteration number: 0 with current cost as 0.4868415821833432 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13074627  0.58482266 -2.73771122
  3.01595044  2.21824665  1.25994607 -1.09866409  0.71403241  1.14006449
  1.43811578 -1.77629962  0.6490867 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:48:28 2024]  Iteration number: 0 with current cost as 0.4571338375813302 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13146732  0.5874459  -2.7343945
  3.02749311  2.2262307   1.23550014 -1.10089588  0.71976549  1.13914784
  1.41853765 -1.79296592  0.65508825]. 
Working on 0.6 fold... 
[Tue Apr  2 00:52:23 2024]  Iteration number: 0 with current cost as 0.49835693089714145 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.1277295   0.58517663 -2.73360215
  3.0008339   2.22551958  1.28186431 -1.11002882  0.71903616  1.12783345
  1.43869444 -1.77674072  0.64556669]. 
Working on 0.8 fold... 
[Tue Apr  2 00:56:43 2024]  Iteration number: 0 with current cost as 0.45768108535216084 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11838471  0.57980179 -2.73114745
  3.00239175  2.2228591   1.28069382 -1.10263607  0.71705305  1.13618738
  1.45609571 -1.76338693  0.63500786]. 
Working on 1.0 fold... 
[Tue Apr  2 01:01:10 2024]  Iteration number: 0 with current cost as 0.4179064321803346 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.11885745  0.57876793 -2.73334461
  3.02228092  2.22364621  1.24595756 -1.10462133  0.70468215  1.12990964
  1.41418864 -1.79950497  0.64626554]. 
Training complete taking 1297.090006828308 seconds. 
Discarding model... 

Training complete taking 32636.88679099083 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 1.666283369064331 seconds. 
Saved predicted values as M-A1-CZ_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (3.009490820043645,), 'R2_train': 0.5867742555961055, 'MAE_train': 1.356190379502622, 'MSE_test': 4.44647479733071, 'R2_test': 0.5567280005243375, 'MAE_test': 1.6728262956706879}. 
Saved model results as M-A1-CZ_HWE-CNOT_results.json. 
