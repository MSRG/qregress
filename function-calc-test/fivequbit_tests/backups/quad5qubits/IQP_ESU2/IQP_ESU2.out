/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:48 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:20 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:04:18 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:05:57 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:07:45 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:09:35 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 531.8690946102142 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:11:13 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:13:06 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:14:40 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:16:30 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:18:22 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 524.8365521430969 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:19:56 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:21:49 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:23:25 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:25:12 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:27:06 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 523.4391033649445 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:28:41 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:30:28 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:32:04 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:33:53 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:35:41 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 512.593320608139 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:37:12 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:39:04 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:40:44 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:42:32 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:44:20 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 522.8634390830994 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:45:56 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:47:47 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:49:20 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:51:12 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:52:58 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 516.7598371505737 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:54:32 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:56:25 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:57:56 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:59:45 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:01:37 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 517.770133972168 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:03:10 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:04:59 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:06:33 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:08:22 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:10:10 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 516.0594756603241 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:11:45 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:13:38 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:15:13 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:17:03 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:18:55 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 526.1481838226318 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:20:36 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:22:31 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:24:08 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:25:59 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:27:52 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 535.325067281723 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:29:30 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:31:21 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:32:56 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:34:44 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:36:35 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 522.8929574489594 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:38:14 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:40:03 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:41:37 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:43:27 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:45:15 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 522.8497657775879 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:46:54 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:48:49 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:50:23 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:52:12 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:54:03 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 525.6749258041382 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:55:39 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:57:30 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:59:07 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:01:01 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:03:01 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 538.5479393005371 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:04:38 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:06:32 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:08:12 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:10:06 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:11:56 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 534.2361581325531 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:13:32 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:15:22 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:16:57 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:18:48 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:20:36 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 520.0023920536041 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:22:11 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:24:02 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:25:40 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:27:35 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:29:27 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 530.1655938625336 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:31:01 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:32:54 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:34:31 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:36:21 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:38:13 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 526.1368091106415 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:39:48 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:41:41 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:43:16 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:45:08 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:46:58 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 526.1640100479126 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:48:34 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:50:26 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:52:02 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:53:52 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:55:43 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 522.8559489250183 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:57:16 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:59:11 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:00:47 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 19:02:39 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:04:28 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 526.4255149364471 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:06:03 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 19:07:54 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:09:30 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 19:11:19 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:13:11 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 525.0967226028442 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:14:49 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 19:16:45 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:18:22 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 19:20:13 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:22:05 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 533.2156925201416 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:23:41 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 19:25:38 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:27:13 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 19:29:06 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:31:00 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 534.5802900791168 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:32:37 2024]  Iteration number: 0 with current cost as 0.31704093521990667 and parameters 
[-3.82434164  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 19:34:27 2024]  Iteration number: 0 with current cost as 0.31118007483565824 and parameters 
[-3.71452639  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:36:02 2024]  Iteration number: 0 with current cost as 0.32758430962505647 and parameters 
[-3.85383518  2.23743463 -2.12427964 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 19:37:52 2024]  Iteration number: 0 with current cost as 0.2816392520245036 and parameters 
[-3.90833122  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:39:42 2024]  Iteration number: 0 with current cost as 0.2812972492134995 and parameters 
[-3.74854917  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 519.3228874206543 seconds. 
Discarding model... 

Training complete taking 13135.8331990242 total seconds. 
Now scoring model... 
Scoring complete taking 2.3570618629455566 seconds. 
Saved predicted values as IQP_ESU2_predicted_values.csv
Model scores: {'MSE_train': (6.049099613221796,), 'R2_train': 0.1694130867590964, 'MAE_train': 2.0266832607365615, 'MSE_test': 9.820183467894628, 'R2_test': 0.021019445866491626, 'MAE_test': 2.757788169462818}. 
Saved model results as IQP_ESU2_results.json. 
