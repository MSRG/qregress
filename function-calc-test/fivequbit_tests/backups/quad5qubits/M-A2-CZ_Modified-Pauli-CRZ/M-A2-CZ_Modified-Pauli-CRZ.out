/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:44:07 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:45:14 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:46:50 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:48:17 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:49:51 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:51:10 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 468.9308912754059 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:53:04 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:54:40 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:56:08 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:57:45 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:59:02 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 472.95878505706787 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:00:56 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:02:33 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:04:05 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:05:41 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:06:57 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 477.19918394088745 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:08:54 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:10:29 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:11:58 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:13:35 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:14:50 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 472.4804389476776 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:16:48 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:18:25 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:19:51 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:21:38 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:22:53 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 482.5730073451996 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:24:51 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:26:36 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:28:01 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:29:41 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:30:57 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 484.00529503822327 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:32:53 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:34:28 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:35:56 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:37:31 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:38:49 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 471.61572194099426 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:40:44 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:42:20 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:43:46 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:45:21 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:46:38 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 468.30471682548523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:48:32 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:50:11 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:51:37 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:53:14 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:54:30 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 472.82999181747437 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:56:25 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:58:00 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:59:26 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:01:02 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:02:19 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 469.2018630504608 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:04:15 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:05:51 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:07:18 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:08:53 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:10:10 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 469.623477935791 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:12:09 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:14:07 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:15:39 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:17:16 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:18:33 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 505.2450444698334 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:20:32 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:22:09 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:23:35 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:25:13 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:26:29 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 475.3550133705139 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:28:24 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:29:59 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:31:28 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:33:04 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:34:22 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 472.9386656284332 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:36:21 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:37:57 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:39:22 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:40:59 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:42:16 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 472.1117160320282 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:44:31 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:46:11 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:47:35 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:49:11 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:50:33 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 504.23149943351746 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:52:43 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:54:26 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:55:56 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:57:31 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:58:47 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 486.6543023586273 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:00:43 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:02:20 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:03:47 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:05:22 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:06:37 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 472.50628995895386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:08:32 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:10:17 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:11:43 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:13:20 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:14:36 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 477.8181731700897 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:16:30 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:18:04 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:19:30 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:21:05 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:22:23 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 467.3744831085205 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:24:18 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:25:53 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:27:19 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:28:54 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:30:11 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 466.7993414402008 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:32:06 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:33:42 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:35:07 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:36:43 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:37:58 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 467.7132956981659 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:39:52 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:41:30 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:42:56 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:44:39 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:46:00 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 482.0691649913788 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:47:54 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:49:30 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:51:05 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:52:46 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:54:05 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 485.35880184173584 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:56:06 2024]  Iteration number: 0 with current cost as 0.1673453918683545 and parameters 
[-3.83548524  2.23743446 -2.12427955 -0.11653112  0.55388708 -2.77010924
  3.0685848   2.18960127  1.18551998 -1.06648344  0.60271492  1.14432436
  1.31029881 -1.8735468   0.72965044  2.88578401 -0.54534344 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:57:41 2024]  Iteration number: 0 with current cost as 0.1815072731754387 and parameters 
[-3.85734405  2.23743464 -2.12427935 -0.11653088  0.55388722 -2.77010926
  3.06858498  2.18960145  1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029899 -1.87354666  0.72965051  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:59:07 2024]  Iteration number: 0 with current cost as 0.16903398747575626 and parameters 
[-3.80294259  2.23743471 -2.12427935 -0.11653103  0.55388722 -2.77010897
  3.06858498  2.18960152  1.18552013 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.87354666  0.72965066  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:00:42 2024]  Iteration number: 0 with current cost as 0.18023726350582847 and parameters 
[-2.64172258  2.23743464 -2.12427852 -0.11653047  0.55388764 -2.77010897
  3.06858526  2.18960201  1.18552082 -1.06648364  0.60271538  1.14432501
  1.31029926 -1.87354624  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:01:59 2024]  Iteration number: 0 with current cost as 0.19989290840252028 and parameters 
[-2.59250353  2.23743449 -2.12427949 -0.11653103  0.55388715 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.0664833   0.6027151   1.14432445
  1.31029891 -1.87354673  0.72965066  2.88578412 -0.54534342 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 474.95555305480957 seconds. 
Discarding model... 

Training complete taking 11920.856068372726 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 1.1894598007202148 seconds. 
Saved predicted values as M-A2-CZ_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (4.648558159835184,), 'R2_train': 0.36171797128963035, 'MAE_train': 1.549127241965507, 'MSE_test': 12.610030284804779, 'R2_test': -0.2571022197516206, 'MAE_test': 2.503309788785607}. 
Saved model results as M-A2-CZ_Modified-Pauli-CRZ_results.json. 
