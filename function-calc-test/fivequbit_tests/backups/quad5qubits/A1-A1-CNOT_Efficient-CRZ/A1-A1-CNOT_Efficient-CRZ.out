/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/gjones/scratch/quad5qubits/quadratic_train.bin... 
Successfully loaded /home/gjones/scratch/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /home/gjones/scratch/quad5qubits/quadratic_test.bin... 
Successfully loaded /home/gjones/scratch/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /home/gjones/scratch/quad5qubits/quadratic_train.bin 
 at time Thu Mar 28 02:25:34 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 02:26:54 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 02:29:30 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 02:32:08 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 02:34:30 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 02:36:52 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 740.110285282135 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 02:39:13 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 02:41:53 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 02:44:30 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 02:46:51 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 02:49:14 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 742.1563336849213 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 02:51:35 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 02:54:12 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 02:56:49 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 02:59:11 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 03:01:32 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 738.4061760902405 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 03:03:53 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 03:06:29 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 03:09:06 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 03:11:26 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 03:13:48 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 735.8303656578064 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 03:16:09 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 03:18:46 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 03:21:24 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 03:23:46 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 03:26:06 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 738.4971396923065 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 03:28:27 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 03:31:05 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 03:33:42 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 03:36:02 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 03:38:24 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 737.2745599746704 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 03:40:45 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 03:43:21 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 03:45:57 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 03:48:19 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 03:50:40 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 736.4213571548462 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 03:53:01 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 03:55:37 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 03:58:15 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 04:00:36 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 04:03:01 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 742.6695849895477 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 04:05:23 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 04:08:00 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 04:10:37 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 04:12:58 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 04:15:18 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 735.0270140171051 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 04:17:39 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 04:20:16 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 04:22:53 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 04:25:14 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 04:27:36 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 740.3818197250366 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 04:29:59 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 04:32:38 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 04:35:17 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 04:37:43 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 04:40:05 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 746.5871846675873 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 04:42:25 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 04:45:01 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 04:47:37 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 04:49:58 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 04:52:19 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 733.9571900367737 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 04:54:42 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 04:57:18 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 04:59:54 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 05:02:15 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 05:04:36 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 737.6644208431244 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 05:06:59 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 05:09:35 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 05:12:11 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 05:14:34 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 05:16:54 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 737.2471795082092 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 05:19:15 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 05:21:51 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 05:24:27 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 05:26:48 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 05:29:09 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 735.1860756874084 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 05:31:30 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 05:34:07 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 05:36:44 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 05:39:05 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 05:41:26 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 738.0837776660919 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 05:43:48 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 05:46:26 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 05:49:03 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 05:51:26 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 05:53:50 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 744.0326652526855 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 05:56:12 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 05:58:48 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 06:01:28 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 06:03:48 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 06:06:09 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 737.8254544734955 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 06:08:30 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 06:11:07 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 06:13:45 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 06:16:07 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 06:18:28 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 738.3394174575806 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 06:20:48 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 06:23:25 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 06:26:05 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 06:28:25 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 06:30:47 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 739.1997971534729 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 06:33:08 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 06:35:44 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 06:38:20 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 06:40:41 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 06:43:02 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 735.1265277862549 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 06:45:24 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 06:48:00 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 06:50:40 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 06:53:01 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 06:55:21 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 739.318023443222 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 06:57:42 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 07:00:20 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 07:02:57 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 07:05:18 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 07:07:41 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 740.8605787754059 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 07:10:03 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 07:12:40 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 07:15:16 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 07:17:37 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 07:19:58 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 736.6542139053345 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 07:22:20 2024]  Iteration number: 0 with current cost as 0.23376291531725282 and parameters 
[-2.36042348  2.23743464 -2.12427964 -0.11653106  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648312  0.60271507  1.14432442
  1.31029899 -1.8735468 ]. 
Working on 0.4 fold... 
[Thu Mar 28 07:24:57 2024]  Iteration number: 0 with current cost as 0.22056725504487318 and parameters 
[-2.34333035  2.2374346  -2.12427964 -0.11653109  0.55388705 -2.77010904
  3.06858491  2.18960138  1.18551998 -1.06648315  0.60271507  1.14432442
  1.31029899 -1.87354683]. 
Working on 0.6 fold... 
[Thu Mar 28 07:27:34 2024]  Iteration number: 0 with current cost as 0.2156427084414567 and parameters 
[-2.4207786   2.23743462 -2.12427967 -0.11653106  0.55388705 -2.77010902
  3.06858492  2.18960142  1.18551998 -1.06648312  0.60271507  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Thu Mar 28 07:29:56 2024]  Iteration number: 0 with current cost as 0.1592869801760562 and parameters 
[-2.48335819  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960143  1.18552    -1.0664831   0.6027151   1.14432443
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Thu Mar 28 07:32:17 2024]  Iteration number: 0 with current cost as 0.16863640972383354 and parameters 
[-2.43056607  2.23743461 -2.12427964 -0.11653105  0.55388706 -2.77010899
  3.06858494  2.18960143  1.18552001 -1.06648311  0.60271508  1.14432443
  1.31029896 -1.8735468 ]. 
Training complete taking 738.3988699913025 seconds. 
Discarding model... 

Training complete taking 18465.256717920303 total seconds. 
Now scoring model... 
Scoring complete taking 1.8756568431854248 seconds. 
Saved predicted values as A1-A1-CNOT_Efficient-CRZ_predicted_values.csv
Model scores: {'MSE_train': (4.391806230864695,), 'R2_train': 0.39697194391162605, 'MAE_train': 1.3645818630173303, 'MSE_test': 3.592703186578487, 'R2_test': 0.6418410544026336, 'MAE_test': 1.5701882349835734}. 
Saved model results as A1-A1-CNOT_Efficient-CRZ_results.json. 
