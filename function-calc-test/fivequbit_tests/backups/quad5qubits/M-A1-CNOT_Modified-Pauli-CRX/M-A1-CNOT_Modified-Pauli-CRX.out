/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:54:08 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:54:38 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:02:48 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:08:54 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:17:10 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:25:13 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2410.7993729114532 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:34:47 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:42:54 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:49:05 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:57:23 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:05:22 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2408.7026765346527 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:14:57 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:22:56 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:28:57 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:37:12 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:45:33 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2405.271670103073 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:55:03 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:03:03 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:09:11 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:17:52 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:26:03 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2439.4110236167908 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:35:43 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:43:48 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:49:50 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:58:11 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:06:02 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2417.608234643936 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:16:01 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:24:05 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:30:08 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:38:24 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:46:35 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2404.757232904434 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:56:14 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:04:40 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:10:43 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:18:50 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:26:42 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2418.392087459564 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:36:23 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:44:27 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:50:36 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:59:16 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:07:11 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2417.7577300071716 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 21:16:41 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:24:41 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:30:48 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:39:09 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:46:56 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2387.466807126999 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:56:28 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:04:34 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:10:45 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:19:03 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:27:06 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2439.9350056648254 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 22:37:08 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:45:28 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:51:39 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:59:53 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:07:40 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2410.551741838455 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 23:17:18 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:25:28 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:31:38 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 23:39:50 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:47:57 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2419.414370059967 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 23:57:48 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:05:54 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 00:11:57 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 00:20:28 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 00:28:28 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2437.0113711357117 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 00:38:15 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:46:41 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 00:52:58 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 01:01:08 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 01:09:14 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2429.692539691925 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 01:18:45 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 01:26:48 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 01:33:00 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 01:41:29 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 01:49:24 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2408.4571492671967 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 01:58:53 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 02:07:10 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 02:13:17 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 02:21:31 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 02:29:39 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2438.0070395469666 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 02:39:31 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 02:47:56 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 02:54:02 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 03:02:12 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 03:10:27 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2425.5565321445465 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 03:20:05 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 03:28:48 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 03:34:51 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 03:43:31 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 03:51:30 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2460.3632175922394 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 04:00:57 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 04:08:59 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 04:15:05 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 04:24:04 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 04:31:56 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2455.2438564300537 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 04:41:53 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 04:49:55 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 04:56:03 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 05:04:15 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 05:12:10 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2385.5869584083557 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 05:21:38 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 05:29:38 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 05:35:56 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 05:44:16 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 05:52:09 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2411.014748811722 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 06:01:49 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 06:10:16 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 06:16:28 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 06:25:00 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 06:32:54 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2443.2229509353638 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 06:42:33 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 06:50:35 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 06:56:44 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 07:04:56 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 07:12:50 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2388.8319747447968 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 07:22:21 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 07:30:23 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 07:36:27 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 07:44:37 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 07:52:28 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2375.8414511680603 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 08:01:57 2024]  Iteration number: 0 with current cost as 0.20507853792561975 and parameters 
[-3.23817222  2.2718099  -2.21730552 -0.11653102  0.55388708 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.94992021  1.14432447
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 08:09:59 2024]  Iteration number: 0 with current cost as 0.19484036894713974 and parameters 
[-3.20433707  2.26288957 -2.20769344 -0.11653102  0.55388707 -2.770109
  3.06858499  2.18960144  1.18551998 -1.06648309  0.92743971  1.14432446
  1.31029899 -1.87354681  0.7296508   2.88578418 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 08:16:09 2024]  Iteration number: 0 with current cost as 0.18891576102353483 and parameters 
[-3.17772151  2.26535493 -2.20062464 -0.11653103  0.55388707 -2.77010899
  3.06858499  2.18960145  1.18551998 -1.06648308  0.88265901  1.14432447
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 08:24:22 2024]  Iteration number: 0 with current cost as 0.14877907124689949 and parameters 
[-3.11773877  2.27981598 -2.18262138 -0.11653103  0.55388708 -2.770109
  3.06858499  2.18960146  1.18551998 -1.06648309  0.76888059  1.14432446
  1.31029898 -1.8735468   0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 08:32:14 2024]  Iteration number: 0 with current cost as 0.1558778395977825 and parameters 
[-3.09518801  2.25941891 -2.17541066 -0.11653102  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.78045559  1.14432447
  1.31029899 -1.8735468   0.72965081  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2390.7081067562103 seconds. 
Discarding model... 

Training complete taking 60429.6074783802 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 1.0884897708892822 seconds. 
Saved predicted values as M-A1-CNOT_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (3.483751246875086,), 'R2_train': 0.5216547288597226, 'MAE_train': 1.327730626490466, 'MSE_test': 5.210112165101795, 'R2_test': 0.4806004886604611, 'MAE_test': 1.7689889285886433}. 
Saved model results as M-A1-CNOT_Modified-Pauli-CRX_results.json. 
