/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:54:08 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:55:32 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:57:20 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:59:38 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:01:40 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:03:27 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 604.4175298213959 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:05:28 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:07:14 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:09:35 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:11:37 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:13:26 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 598.5740671157837 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:15:30 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:17:17 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:19:36 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:21:40 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:23:29 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 602.5069191455841 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:25:30 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:27:17 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:29:34 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:31:40 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:33:30 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 602.57284283638 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:35:33 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:37:24 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:39:48 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:41:57 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:43:50 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 619.8137185573578 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:45:55 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:47:44 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:50:06 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:12 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:54:04 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 613.6138515472412 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:56:06 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:57:54 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:00:13 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:02:20 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:04:08 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 608.1123559474945 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:06:16 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:08:05 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:10:26 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:12:36 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:30 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 617.2572865486145 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:16:31 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:18:19 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:20:35 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:22:39 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:24:26 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 596.8005986213684 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:26:36 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:28:24 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:30:44 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:32:46 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:34:35 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 607.3149218559265 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:36:35 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:38:25 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:40:46 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:42:54 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:44:41 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 612.6954596042633 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:46:50 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:48:43 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:51:02 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:53:04 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:54:49 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 603.0072536468506 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:56:50 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:58:40 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:00:57 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:03:00 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:04:45 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 594.9917867183685 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:06:46 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:08:36 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:10:54 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:12:56 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:14:48 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 606.5415060520172 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:16:53 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:18:42 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:21:00 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:23:06 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:24:51 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 600.034884929657 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:26:54 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:28:42 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:31:05 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:33:07 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:34:54 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 603.2439248561859 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:36:55 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:38:44 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:41:02 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:43:04 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:44:51 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 597.4866852760315 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:46:54 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:48:41 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:50:59 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:52:59 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:54:45 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 593.7646317481995 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:56:48 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:58:36 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:00:51 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:02:54 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:04:40 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 595.3760077953339 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:06:46 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:08:33 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:10:55 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:13:00 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:14:48 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 606.6990921497345 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:16:50 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:18:40 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:21:07 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:23:09 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:24:57 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 609.1878614425659 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:26:58 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:28:44 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:31:01 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:33:07 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:34:52 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 596.6177797317505 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:36:54 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:38:40 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:40:57 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:43:02 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:44:51 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 600.3130629062653 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:46:56 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:48:42 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:50:57 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:53:02 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:54:47 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 593.3364713191986 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:56:48 2024]  Iteration number: 0 with current cost as 0.10169638681000884 and parameters 
[-4.08085322  2.23743461 -2.12427961 -0.116531    0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311  0.60271508  1.14432445
  1.31029896 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:58:36 2024]  Iteration number: 0 with current cost as 0.09915977597049544 and parameters 
[-4.0819364   2.23743466 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:00:53 2024]  Iteration number: 0 with current cost as 0.10581478338609943 and parameters 
[-4.07412584  2.23743464 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960145  1.18552003 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:02:56 2024]  Iteration number: 0 with current cost as 0.08752176144873064 and parameters 
[-4.05783283  2.23743466 -2.12427958 -0.116531    0.55388714 -2.77010897
  3.06858498  2.18960145  1.18552004 -1.06648308  0.6027151   1.14432448
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:04:49 2024]  Iteration number: 0 with current cost as 0.08855552958450588 and parameters 
[-4.09013748  2.23743466 -2.12427961 -0.11653103  0.55388708 -2.770109
  3.06858498  2.18960145  1.18552004 -1.06648311  0.60271508  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 601.2930266857147 seconds. 
Discarding model... 

Training complete taking 15085.574652671814 total seconds. 
Now scoring model... 
Scoring complete taking 1.7544524669647217 seconds. 
Saved predicted values as A2_Efficient-CRZ_predicted_values.csv
Model scores: {'MSE_train': (2.122479239642794,), 'R2_train': 0.7085676228211635, 'MAE_train': 1.2181502335903913, 'MSE_test': 3.039513837426972, 'R2_test': 0.6969888647611311, 'MAE_test': 1.5096786795725659}. 
Saved model results as A2_Efficient-CRZ_results.json. 
