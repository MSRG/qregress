/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:31:46 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:32:01 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:32:25 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:33:03 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:33:24 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:34:12 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.87951374053955 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:34:34 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:34:58 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:37 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:36:01 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:36:47 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 153.14357566833496 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:08 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:37:34 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:14 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:36 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:22 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 155.66203498840332 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:44 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:10 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:48 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:12 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:58 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 155.99509692192078 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:21 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:46 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:23 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:43 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:29 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 151.43864274024963 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:51 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:15 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:52 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:13 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:57 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 148.00932025909424 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:18 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:43 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:21 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:43 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:27 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.96991991996765 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:49 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:13 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:51 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:13 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:00 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.4884283542633 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:22 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:47 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:25 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:47 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:32 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 151.82316613197327 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:53 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:18 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:55 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:16 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:57:01 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.24377536773682 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:23 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:48 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:24 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:47 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:34 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.63005447387695 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:55 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:00:20 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:00:58 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:01:19 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:02:07 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 154.21809005737305 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:02:29 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:02:54 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:03:30 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:03:53 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:04:38 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 151.98182034492493 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:00 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:05:25 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:06:04 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:26 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:13 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.665283203125 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:07:32 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:07:58 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:08:36 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:08:58 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:09:43 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 150.14155840873718 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:10:03 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:10:29 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:11:08 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:11:31 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:12:19 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 157.1207718849182 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:12:41 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:13:07 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:13:45 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:14:07 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:14:53 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 153.3220980167389 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:15:15 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:15:39 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:16:18 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:16:37 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:17:23 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 150.16868591308594 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:17:46 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:18:12 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:18:49 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:19:10 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:19:56 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 154.06516075134277 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:20:19 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:20:44 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:21:21 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:21:42 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:22:27 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.63927698135376 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:22:49 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:23:14 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:23:51 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:24:13 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:25:00 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.88154816627502 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:25:21 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:25:44 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:26:20 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:26:41 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:27:28 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 148.32243394851685 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:27:49 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:28:12 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:28:49 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:29:10 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:29:55 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 146.834481716156 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:30:16 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:30:41 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:31:19 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:31:42 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:32:28 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 153.0562388896942 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:32:50 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:33:15 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:33:54 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:34:14 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:34:57 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.87980365753174 seconds. 
Discarding model... 

Training complete taking 3797.5821619033813 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.9467060565948486 seconds. 
Saved predicted values as M-A2-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (144.359133358489,), 'R2_train': 0.3006284481012492, 'MAE_train': 10.101884324137085, 'MSE_test': 145.671770686518, 'R2_test': 0.12191767435561351, 'MAE_test': 9.756547317239868}. 
Saved model results as M-A2-CZ_Hadamard_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 11:52:51 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:53:06 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:53:29 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:54:05 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 11:54:26 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:55:10 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 144.25371837615967 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:55:31 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:55:55 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:56:32 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 11:56:52 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:57:39 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 148.76927733421326 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:58:00 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:58:26 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:59:05 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 11:59:25 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:00:10 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.103168964386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:00:33 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:00:58 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:01:36 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:01:57 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:02:42 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 150.60525584220886 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:03:03 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:03:27 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:04:05 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:04:28 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:05:16 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 154.5766327381134 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:05:38 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:06:01 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:06:38 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:06:59 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:07:45 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 148.91106390953064 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:08:07 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:08:33 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:09:09 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:09:33 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:10:17 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.51094508171082 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:10:40 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:11:04 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:11:43 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:12:05 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:12:50 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.47252225875854 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:13:13 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:13:38 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:14:15 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:14:36 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:15:20 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 150.72010254859924 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:15:43 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:16:09 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:16:46 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:17:07 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:17:53 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 151.687814950943 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:18:14 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:18:38 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:19:15 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:19:36 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:20:24 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 151.28798460960388 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:20:47 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:21:10 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:21:48 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:22:10 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:22:54 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.73782682418823 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:23:15 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:23:40 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:24:16 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:24:38 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:25:22 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 148.33169317245483 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:25:44 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:26:07 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:26:45 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:27:06 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:27:51 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 148.81493639945984 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:28:12 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:28:35 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:29:11 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:29:33 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:30:17 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 145.8612723350525 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:30:38 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:31:02 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:31:39 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:32:00 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:32:46 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.62807083129883 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:33:08 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:33:31 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:34:07 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:34:28 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:35:12 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 145.9808156490326 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:35:34 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:35:58 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:36:35 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:36:55 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:37:39 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 147.07419109344482 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:38:00 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:38:23 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:39:00 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:39:21 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:40:06 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 145.88971161842346 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:40:26 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:40:51 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:41:28 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:41:49 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:42:35 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.95087695121765 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:42:56 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:43:20 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:43:56 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:44:17 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:45:02 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 146.2177972793579 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:45:21 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:45:45 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:46:22 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:46:44 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:47:29 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 148.08358001708984 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:47:50 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:48:13 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:48:51 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:49:12 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:49:59 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.683598279953 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:50:19 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:50:42 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:51:19 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:51:41 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:52:26 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 147.46732425689697 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:52:47 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:53:11 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:53:48 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Thu Apr  4 12:54:09 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:54:55 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 147.8673939704895 seconds. 
Discarding model... 

Training complete taking 3728.4887235164642 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.9397821426391602 seconds. 
Saved predicted values as M-A2-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (144.359133358489,), 'R2_train': 0.3006284481012492, 'MAE_train': 10.101884324137085, 'MSE_test': 145.671770686518, 'R2_test': 0.12191767435561351, 'MAE_test': 9.756547317239868}. 
Saved model results as M-A2-CZ_Hadamard_results.json. 
