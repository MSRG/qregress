/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:39:05 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:14 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:22 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:32 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:39:42 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:53 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.887125730514526 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:02 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:12 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:22 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:31 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:42 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.914939641952515 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:52 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:00 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:12 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:21 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:31 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 48.83074450492859 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:41:42 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:50 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:01 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:10 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:42:21 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.04237151145935 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:32 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:42 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:53 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:01 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:13 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 51.41072154045105 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:22 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:30 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:42 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:50 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:01 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 48.35248780250549 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:12 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:20 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:31 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:40 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:51 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.950268507003784 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:00 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:09 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:21 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:45:30 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:45:42 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.64625692367554 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:51 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:59 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:11 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:21 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:33 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 51.725013971328735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:44 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:53 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:03 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:13 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:24 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.373169898986816 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:33 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:43 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:53 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:01 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:48:13 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.334078788757324 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:23 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:31 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:43 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:51 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:02 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 48.882771492004395 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:13 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:21 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:32 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:49:41 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:52 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.34977340698242 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:02 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:12 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:22 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:30 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:42 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.787392139434814 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:52 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:00 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:13 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:21 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:51:31 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.39343070983887 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:42 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:51 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:01 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:11 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:22 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.81889843940735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:32 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:43 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:53 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:01 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:14 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 51.966986417770386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:24 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:53:32 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:44 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:52 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:03 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 48.74825954437256 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:14 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:22 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:32 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:42 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:53 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.07989954948425 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:03 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:12 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:23 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:55:31 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:43 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.96133208274841 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:53 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:01 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:13 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:21 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:32 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.00597929954529 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:56:43 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:51 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:02 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:57:11 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:57:22 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.72596979141235 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:32 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:41 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:52 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:00 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:12 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.37814903259277 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:58:22 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:58:30 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:42 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:50 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:01 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 48.49708652496338 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:11 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:59:20 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:59:30 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:39 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:51 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.060067653656006 seconds. 
Discarding model... 

Training complete taking 1248.1243436336517 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.6781158447265625 seconds. 
Saved predicted values as M_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (45.90449499854318,), 'R2_train': 0.7776081280113081, 'MAE_train': 6.070993943421847, 'MSE_test': 93.39513879228551, 'R2_test': 0.4370314832577218, 'MAE_test': 8.006546081928544}. 
Saved model results as M_Hadamard_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 12:22:03 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:22:11 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:22:20 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:22:34 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:22:48 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:23:02 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 62.32048749923706 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:23:13 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:23:22 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:23:36 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:23:45 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:23:59 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 56.67062020301819 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:24:10 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:24:19 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:24:33 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:24:42 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:24:55 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 56.93234133720398 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:25:06 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:25:16 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:25:29 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:25:39 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:25:51 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 54.95043873786926 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:26:03 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:26:13 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:26:26 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:26:36 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:26:48 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 57.02057933807373 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:27:00 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:27:10 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:27:22 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:27:34 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:27:46 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 58.06251835823059 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:27:58 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:28:08 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:28:20 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:28:31 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:28:43 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 56.978310108184814 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:28:54 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:29:05 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:29:17 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:29:31 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:29:43 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 60.158517599105835 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:29:54 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:30:08 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:30:20 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:30:31 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:30:44 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 61.05643105506897 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:30:57 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:31:06 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:31:18 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:31:29 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:31:41 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 57.1830518245697 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:31:52 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:32:03 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:32:15 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:32:24 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:32:38 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 56.92749285697937 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:32:49 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:33:00 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:33:13 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:33:23 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:33:37 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 58.45427680015564 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:33:48 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:33:59 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:34:11 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:34:21 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:34:34 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 57.57132887840271 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:34:45 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:34:54 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:35:08 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:35:17 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:35:34 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 60.174116373062134 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:35:45 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:35:55 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:36:08 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:36:18 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:36:36 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 61.346168994903564 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:36:56 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:37:06 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:37:18 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:37:29 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:37:41 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 65.27131915092468 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:37:52 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:38:03 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:38:15 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:38:24 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:38:40 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 59.183051109313965 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:38:51 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:39:02 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:39:14 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:39:23 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:39:37 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 56.871928453445435 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:39:48 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:39:59 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:40:11 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:40:20 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:40:34 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 57.120110511779785 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:40:45 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:40:54 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:41:09 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:41:19 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:41:33 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 59.235907793045044 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:41:44 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:41:53 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:42:07 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:42:17 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:42:30 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 57.06194806098938 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:42:41 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:42:51 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:43:04 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:43:14 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:43:31 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 60.59144449234009 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:43:42 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:43:53 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:44:06 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:44:16 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:44:30 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 58.65755605697632 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:44:40 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:44:50 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:45:03 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:45:13 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:45:25 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 56.76345610618591 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:45:37 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:45:47 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:46:02 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:46:11 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:46:23 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 58.23611235618591 seconds. 
Discarding model... 

Training complete taking 1464.8005003929138 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.7723994255065918 seconds. 
Saved predicted values as M_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (45.90449499854318,), 'R2_train': 0.7776081280113081, 'MAE_train': 6.070993943421847, 'MSE_test': 93.39513879228551, 'R2_test': 0.4370314832577218, 'MAE_test': 8.006546081928544}. 
Saved model results as M_Hadamard_results.json. 
