/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:56:51 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:05 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 18:04:34 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Sun Mar 24 18:06:21 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 18:13:05 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Sun Mar 24 18:15:14 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 18:21:57 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Sun Mar 24 18:25:57 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 18:32:20 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Sun Mar 24 18:33:04 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 18:39:34 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2682.9457037448883 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:41:50 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 18:49:15 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Sun Mar 24 18:50:52 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 18:57:37 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Sun Mar 24 18:59:47 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 19:06:32 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Sun Mar 24 19:10:32 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 19:17:08 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Sun Mar 24 19:17:54 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 19:24:25 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2691.0956213474274 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 19:26:39 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 19:34:02 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Sun Mar 24 19:35:39 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 19:42:24 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Sun Mar 24 19:44:31 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 19:51:15 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Sun Mar 24 19:55:19 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 20:01:43 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Sun Mar 24 20:02:29 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 20:08:57 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2671.869406938553 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 20:11:11 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 20:19:15 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Sun Mar 24 20:20:52 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 20:27:34 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Sun Mar 24 20:29:47 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 20:36:30 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Sun Mar 24 20:40:28 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 20:46:45 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Sun Mar 24 20:47:30 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 20:53:56 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2697.586865901947 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 20:56:08 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 21:03:27 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Sun Mar 24 21:05:03 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 21:11:43 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Sun Mar 24 21:13:49 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 21:20:32 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Sun Mar 24 21:24:30 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 21:30:46 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Sun Mar 24 21:31:31 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 21:37:59 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2642.989315509796 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 21:40:11 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 21:47:31 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Sun Mar 24 21:49:11 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 21:55:50 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Sun Mar 24 21:57:58 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 22:04:52 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Sun Mar 24 22:08:49 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 22:15:08 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Sun Mar 24 22:15:51 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 22:22:17 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2658.9080407619476 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 22:24:32 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 22:31:46 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Sun Mar 24 22:33:23 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 22:40:03 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Sun Mar 24 22:42:09 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 22:49:04 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Sun Mar 24 22:53:18 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 22:59:37 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Sun Mar 24 23:00:21 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 23:06:47 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2669.305290699005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 23:09:01 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 23:16:17 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Sun Mar 24 23:17:53 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 23:24:35 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Sun Mar 24 23:26:41 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 23:33:38 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Sun Mar 24 23:37:42 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 23:44:07 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Sun Mar 24 23:44:50 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 23:51:23 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2676.4456322193146 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 23:53:37 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 00:00:51 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 00:02:29 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 00:09:10 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 00:11:15 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 00:18:15 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 00:22:15 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 00:28:32 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 00:29:18 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 00:35:46 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2662.4383409023285 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 00:37:58 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 00:45:30 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 00:47:08 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 00:54:00 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 00:56:08 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 01:02:55 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 01:06:52 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 01:13:20 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 01:14:04 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 01:20:30 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2685.1812794208527 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 25 01:22:45 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 01:30:05 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 01:31:43 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 01:38:23 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 01:40:36 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 01:47:22 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 01:51:35 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 01:57:56 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 01:58:42 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 02:05:07 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2675.962649345398 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 02:07:21 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 02:14:38 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 02:16:16 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 02:22:56 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 02:25:03 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 02:31:51 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 02:36:03 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 02:42:27 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 02:43:12 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 02:49:38 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2670.9355778694153 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 02:51:53 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 02:59:10 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 03:00:48 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 03:08:18 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 03:10:24 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 03:17:22 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 03:21:24 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 03:27:45 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 03:28:31 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 03:34:57 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2719.6164462566376 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 03:37:10 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 03:44:38 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 03:46:14 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 03:52:57 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 03:55:05 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 04:01:49 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 04:05:45 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 04:12:04 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 04:12:49 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 04:19:14 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2656.564646959305 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 04:21:28 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 04:28:46 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 04:30:24 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 04:37:04 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 04:39:09 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 04:45:52 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 04:49:47 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 04:56:07 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 04:56:52 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 05:03:16 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2642.5815732479095 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 25 05:05:31 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 05:12:46 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 05:14:24 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 05:21:02 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 05:23:08 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 05:29:57 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 05:34:00 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 05:40:16 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 05:41:02 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 05:47:28 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2651.8216302394867 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 05:49:41 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 05:56:59 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 05:58:35 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 06:05:15 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 06:07:21 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 06:14:45 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 06:18:43 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 06:25:03 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 06:25:47 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 06:32:46 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2718.0924656391144 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 06:35:01 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 06:42:17 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 06:43:55 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 06:50:58 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 06:53:04 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 06:59:42 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 07:03:42 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 07:10:00 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 07:10:44 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 07:17:46 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2700.950375556946 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 07:20:02 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 07:27:20 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 07:28:56 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 07:35:44 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 07:37:50 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 07:44:48 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 07:48:52 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 07:55:12 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 07:55:56 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 08:02:43 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2695.8954157829285 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 08:04:56 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 08:12:15 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 08:13:52 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 08:20:40 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 08:22:48 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 08:29:47 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 08:33:45 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 08:40:11 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 08:40:55 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 08:47:21 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2677.665630340576 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 25 08:49:35 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 08:56:51 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 08:58:27 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 09:05:09 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 09:07:15 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 09:13:53 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 09:17:50 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 09:24:10 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 09:24:54 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 09:31:30 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2649.7556104660034 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 09:33:45 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 09:41:17 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 09:42:53 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 09:49:32 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 09:51:40 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 09:58:45 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 10:02:43 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 10:09:01 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 10:09:46 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 10:16:13 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2682.6184713840485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 10:18:26 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 10:25:45 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 10:27:25 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 10:34:08 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 10:36:18 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 10:43:25 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 10:48:01 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 10:54:49 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 10:55:35 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 11:02:01 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2748.082745075226 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 11:04:16 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 11:11:33 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 11:13:09 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 11:19:51 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 11:21:57 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 11:28:37 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 11:32:35 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 11:38:55 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 11:39:39 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 11:46:05 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2644.4572253227234 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 11:48:20 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 11:55:36 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Mon Mar 25 11:57:12 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 12:03:55 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Mon Mar 25 12:06:01 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 12:12:41 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Mon Mar 25 12:17:06 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 12:23:33 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Mon Mar 25 12:24:19 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 12:31:15 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2708.8348388671875 seconds. 
Discarding model... 

Training complete taking 66982.60314965248 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.8354108333587646 seconds. 
Saved predicted values as M_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (1.6322965536974237,), 'R2_train': 0.992092071022043, 'MAE_train': 0.9887383126444032, 'MSE_test': 54.686806872526105, 'R2_test': 0.6703581048381024, 'MAE_test': 2.9730214758582996}. 
Saved model results as M_Full-Pauli-CRZ_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 12:29:11 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:29:27 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 12:36:51 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 12:38:29 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 12:45:12 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 12:47:19 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 12:54:06 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 12:58:05 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 13:04:28 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 13:05:12 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 13:11:39 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2666.2031710147858 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 13:13:51 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 13:21:07 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 13:22:44 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 13:29:22 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 13:31:34 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 13:38:14 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 13:42:11 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 13:48:36 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 13:49:19 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 13:55:55 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2656.8014335632324 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:58:09 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 14:05:38 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 14:07:13 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 14:13:58 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 14:16:23 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 14:23:26 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 14:27:25 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 14:33:43 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 14:34:26 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 14:40:48 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2693.733871459961 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 14:43:03 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 14:50:18 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 14:51:54 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 14:58:37 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 15:01:12 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 15:08:17 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 15:12:16 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 15:18:55 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 15:19:42 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 15:26:08 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2718.8050968647003 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 15:28:20 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 15:35:39 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 15:37:14 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 15:43:53 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 15:45:58 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 15:52:40 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 15:56:35 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 16:03:04 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 16:03:49 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 16:10:41 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2674.772881269455 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 16:12:55 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 16:20:24 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 16:22:06 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 16:29:07 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 16:31:14 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 16:37:53 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 16:41:52 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 16:48:05 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 16:48:50 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 16:55:13 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2668.2341248989105 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 16:57:25 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 17:04:46 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 17:06:21 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 17:13:13 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 17:15:20 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 17:22:00 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 17:25:59 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 17:32:36 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 17:33:21 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 17:39:59 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2688.230720281601 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 17:42:12 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 17:49:52 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 17:51:27 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 17:59:11 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 18:01:18 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 18:08:01 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 18:12:00 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 18:19:13 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 18:19:58 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 18:26:24 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2784.3895874023438 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 18:28:36 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 18:36:04 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 18:37:39 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 18:44:22 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 18:46:27 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 18:53:05 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 18:57:01 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 19:03:20 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 19:04:05 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 19:10:40 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2658.179445028305 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 19:12:56 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 19:20:17 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 19:21:56 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 19:28:34 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 19:30:40 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 19:37:21 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 19:41:16 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 19:47:36 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 19:48:19 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 19:54:44 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2641.917131662369 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 19:56:58 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 20:04:12 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 20:05:47 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 20:12:26 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 20:14:32 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 20:21:08 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 20:25:05 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 20:31:20 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 20:32:05 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 20:38:30 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2627.0001587867737 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 20:40:43 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 20:48:00 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 20:49:36 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 20:56:27 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 20:58:32 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:05:11 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 21:09:36 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:15:54 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 21:16:39 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:23:04 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2673.1408977508545 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:25:16 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 21:32:34 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 21:34:10 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:41:07 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 21:43:14 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:49:59 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 21:54:22 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:00:41 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 22:01:24 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:07:50 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2690.8756947517395 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:10:09 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 22:17:24 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 22:19:02 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:25:48 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 22:27:54 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:34:40 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 22:38:36 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:45:10 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 22:45:54 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:52:58 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2704.0975511074066 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:55:13 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 23:02:57 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 23:04:40 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:11:22 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 23:13:31 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:21:00 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Thu Apr  4 23:24:57 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:31:31 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Thu Apr  4 23:32:16 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:38:43 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2744.3827447891235 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:40:55 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 23:48:39 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Thu Apr  4 23:50:16 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:56:56 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Thu Apr  4 23:59:01 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:06:12 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Fri Apr  5 00:10:18 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:16:46 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Fri Apr  5 00:17:30 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:24:21 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2737.790955543518 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:26:33 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 00:33:51 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Fri Apr  5 00:35:27 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:42:17 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Fri Apr  5 00:45:29 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:52:45 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Fri Apr  5 00:56:41 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:03:18 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Fri Apr  5 01:04:02 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:11:04 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2804.8956611156464 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:13:20 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 01:20:35 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Fri Apr  5 01:22:13 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:28:51 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Fri Apr  5 01:31:22 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:38:12 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Fri Apr  5 01:42:07 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:48:28 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Fri Apr  5 01:49:12 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:55:50 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2699.5656168460846 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:58:19 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 02:05:44 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Fri Apr  5 02:07:20 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:13:59 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Fri Apr  5 02:16:05 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:22:47 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Fri Apr  5 02:26:42 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:33:01 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Fri Apr  5 02:33:46 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:40:09 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2643.360074520111 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:42:23 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 02:49:39 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Fri Apr  5 02:51:17 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:57:57 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Fri Apr  5 03:00:02 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:06:42 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Fri Apr  5 03:10:38 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:16:56 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Fri Apr  5 03:17:39 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:24:03 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2634.055082321167 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 03:26:15 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 03:33:39 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Fri Apr  5 03:35:14 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:41:58 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Fri Apr  5 03:44:03 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:51:05 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Fri Apr  5 03:55:08 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:01:27 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Fri Apr  5 04:02:11 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:08:35 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2672.1780078411102 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 04:10:47 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 04:18:04 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Fri Apr  5 04:19:40 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:26:21 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Fri Apr  5 04:28:27 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:35:06 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Fri Apr  5 04:39:03 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:45:22 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Fri Apr  5 04:46:06 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:52:31 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2635.97145318985 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 04:54:43 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 05:02:04 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Fri Apr  5 05:03:40 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:10:17 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Fri Apr  5 05:12:24 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:19:06 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Fri Apr  5 05:23:03 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:29:19 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Fri Apr  5 05:30:05 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:36:30 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2639.398714542389 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:38:43 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 05:46:02 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Fri Apr  5 05:47:38 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:54:18 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Fri Apr  5 05:56:24 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:03:05 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Fri Apr  5 06:07:01 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:13:23 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Fri Apr  5 06:14:08 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:20:34 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2645.3013138771057 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 06:22:48 2024]  Iteration number: 0 with current cost as 0.10171643554812954 and parameters 
[-3.32050259  2.1134432  -2.10670102 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53224695  1.14432445
  1.80209317 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 06:30:11 2024]  Iteration number: 50 with current cost as 0.0029644668985670175 and parameters 
[-4.38024617  1.105006   -1.81533042 -0.11653095  0.553887   -2.77010896
  3.06858482  2.18960149  1.18551983 -1.0664833   0.96444374  1.14432454
  1.15386843 -1.87354651  0.72965097  2.88578411 -0.54534358 -0.47522489
 -2.02654257  0.72897348  1.60512674  2.83077073 -1.26456698 -0.25136096]. 
Working on 0.4 fold... 
[Fri Apr  5 06:31:50 2024]  Iteration number: 0 with current cost as 0.007083631004236141 and parameters 
[-3.12553761  2.18423076 -2.1171116  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56958308  1.14432445
  1.56757025 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:38:45 2024]  Iteration number: 50 with current cost as 0.0027035176412061497 and parameters 
[-4.32984558  1.11763696 -1.88437861 -0.1165307   0.55388733 -2.77010878
  3.06858502  2.18960128  1.18551975 -1.0664831   0.95115115  1.14432429
  1.13928067 -1.87354671  0.72965055  2.88578432 -0.54534321 -0.47522455
 -2.02654235  0.72897396  1.60512668  2.83077144 -1.26456713 -0.25136121]. 
Working on 0.6 fold... 
[Fri Apr  5 06:40:50 2024]  Iteration number: 0 with current cost as 0.005397279783658124 and parameters 
[-3.12494939  2.18648137 -2.11684652 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57296251  1.14432445
  1.56763416 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:47:31 2024]  Iteration number: 50 with current cost as 0.0025514767547320425 and parameters 
[-4.06854816  1.22028928 -2.18947305 -0.11653106  0.55388687 -2.77010885
  3.06858488  2.18960136  1.18551986 -1.0664832   0.93425497  1.14432404
  1.09104007 -1.87354708  0.72965049  2.88578417 -0.54534355 -0.47522471
 -2.02654238  0.72897365  1.60512661  2.83077104 -1.26456702 -0.25136108]. 
Working on 0.8 fold... 
[Fri Apr  5 06:51:28 2024]  Iteration number: 0 with current cost as 0.0050285777402740185 and parameters 
[-3.12875541  2.18534552 -2.11679999 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.57159949  1.14432445
  1.57154144 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:57:45 2024]  Iteration number: 50 with current cost as 0.0021351491961589066 and parameters 
[-4.10190224  1.23710375 -2.12311403 -0.11653107  0.55388697 -2.77010901
  3.06858491  2.18960141  1.18551993 -1.06648316  0.92059214  1.14432445
  1.09392531 -1.8735468   0.72965067  2.88578423 -0.54534336 -0.47522489
 -2.02654241  0.72897359  1.60512668  2.83077097 -1.26456705 -0.25136106]. 
Working on 1.0 fold... 
[Fri Apr  5 06:58:28 2024]  Iteration number: 0 with current cost as 0.0069462144840099875 and parameters 
[-3.12374615  2.17989222 -2.11623998 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.56772657  1.14432445
  1.56731449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:05:52 2024]  Iteration number: 50 with current cost as 0.0025062335121730614 and parameters 
[-4.4142581   1.16585436 -1.87333855 -0.1165312   0.55388712 -2.77010898
  3.06858526  2.18960135  1.18551996 -1.06648317  0.83824456  1.14432455
  1.11068268 -1.87354689  0.72965066  2.88578414 -0.54534359 -0.47522496
 -2.02654217  0.72897369  1.6051269   2.83077087 -1.26456707 -0.25136101]. 
Training complete taking 2715.3747189044952 seconds. 
Discarding model... 

Training complete taking 67118.65829992294 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.952307939529419 seconds. 
Saved predicted values as M_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (1.6322965536974237,), 'R2_train': 0.992092071022043, 'MAE_train': 0.9887383126444032, 'MSE_test': 54.686806872526105, 'R2_test': 0.6703581048381024, 'MAE_test': 2.9730214758582996}. 
Saved model results as M_Full-Pauli-CRZ_results.json. 
