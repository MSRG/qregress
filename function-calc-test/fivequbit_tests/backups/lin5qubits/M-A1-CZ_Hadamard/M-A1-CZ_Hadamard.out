/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:35:02 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:35:17 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:35:41 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:58 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:36:18 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:36:39 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.71313142776489 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:56 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:37:20 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:37:37 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:37:57 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:20 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.25512599945068 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:38:36 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:00 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:17 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:39:36 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:58 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 98.39590787887573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:16 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:40 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:57 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:17 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:39 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 102.9374852180481 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:41:58 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:22 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:41 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:59 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:21 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.28416848182678 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:39 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:02 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:21 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:41 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:45:02 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.49007892608643 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:20 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:44 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:01 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:21 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:43 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.9092710018158 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:00 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:23 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:41 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:01 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:48:23 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 99.98461627960205 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:41 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:03 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:21 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:49:42 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:03 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 99.91234421730042 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:21 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:45 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:02 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:22 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:51:44 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.43500065803528 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:01 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:25 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:43 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:02 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:24 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.11396145820618 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:42 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:06 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:24 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:44 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:05 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.95000529289246 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:23 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:47 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:04 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:24 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:46 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.35528945922852 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:03 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:27 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:45 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:03 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:26 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 99.19686150550842 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:58:43 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:59:06 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:59:24 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:44 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:00:05 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 99.225900888443 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:00:24 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:00:47 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:01:05 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:01:25 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:47 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.82001304626465 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:02:04 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:02:29 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:02:47 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:03:06 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:03:28 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.18674802780151 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:03:46 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:04:09 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:04:27 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:04:47 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:05:09 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.65686178207397 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:27 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:05:50 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:06:08 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:28 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:06:50 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.96754455566406 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:07:07 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:07:31 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:07:49 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:08:09 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:08:31 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.48272109031677 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:08:49 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:09:13 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:09:30 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:09:50 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:10:12 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.88741374015808 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:10:29 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:10:53 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:11:12 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:11:31 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:11:53 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.22210597991943 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:12:11 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:12:35 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:12:53 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:13:13 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:13:33 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.1934175491333 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:13:51 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:14:15 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:14:32 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:14:53 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:15:14 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.30956554412842 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:15:31 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:15:55 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:16:13 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:16:32 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:16:55 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.56597185134888 seconds. 
Discarding model... 

Training complete taking 2516.452889442444 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.8546080589294434 seconds. 
Saved predicted values as M-A1-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (177.25816508535758,), 'R2_train': 0.14124368082331995, 'MAE_train': 10.527907281315368, 'MSE_test': 142.45531555627866, 'R2_test': 0.1413058673306904, 'MAE_test': 8.809892052298718}. 
Saved model results as M-A1-CZ_Hadamard_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 12:20:34 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:20:51 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:21:18 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:21:39 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:22:01 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:22:50 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 140.77244186401367 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:23:11 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:23:39 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:23:58 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:24:21 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:24:47 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 116.53819632530212 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:25:07 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:25:34 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:25:54 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:26:18 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:26:43 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 116.37384533882141 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:27:03 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:27:32 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:27:53 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:28:16 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:28:42 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 118.68779921531677 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:29:01 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:29:30 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:29:51 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:30:14 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:30:42 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 120.86076855659485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:31:05 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:31:33 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:31:54 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:32:19 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:32:44 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.47140550613403 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:33:04 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:33:31 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:33:52 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:34:16 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:34:41 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 117.05493474006653 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:35:01 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:35:28 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:35:49 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:36:13 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:36:38 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 116.93988180160522 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:36:57 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:37:25 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:37:46 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:38:09 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:38:33 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 116.82387971878052 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:38:54 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:39:24 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:39:49 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:40:17 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:40:42 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 127.32233452796936 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:41:02 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:41:30 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:41:51 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:42:14 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:42:40 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 118.07776403427124 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:43:00 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:43:27 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:43:48 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:44:12 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:44:36 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 117.11639761924744 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:44:57 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:45:24 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:45:45 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:46:09 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:46:33 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 117.24077248573303 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:46:54 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:47:21 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:47:43 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:48:04 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:48:30 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 115.4492359161377 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:48:51 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:49:19 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:49:40 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:50:01 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:50:27 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 117.00565791130066 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:50:48 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:51:16 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:51:36 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:51:59 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:52:24 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 117.3805992603302 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:52:45 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:53:13 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:53:33 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:53:56 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:54:22 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 117.39434385299683 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:54:43 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:55:10 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:55:30 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:55:53 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:56:19 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 117.40957403182983 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:56:40 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:57:06 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:57:27 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:57:50 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:58:16 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 116.77520442008972 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:58:36 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 12:59:03 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:59:24 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 12:59:48 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 13:00:14 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 117.82429528236389 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 13:00:34 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 13:01:01 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 13:01:22 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 13:01:46 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 13:02:11 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 117.27021050453186 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 13:02:31 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 13:02:59 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 13:03:20 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 13:03:43 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 13:04:07 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 117.7063889503479 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:04:28 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 13:04:56 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 13:05:17 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 13:05:40 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 13:06:04 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 116.84617829322815 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 13:06:25 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 13:06:53 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 13:07:14 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 13:07:36 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 13:08:01 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 115.89496374130249 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 13:08:22 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Thu Apr  4 13:08:50 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 13:09:11 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Thu Apr  4 13:09:33 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 13:09:58 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 116.98992443084717 seconds. 
Discarding model... 

Training complete taking 2969.228001356125 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.9502544403076172 seconds. 
Saved predicted values as M-A1-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (177.25816508535758,), 'R2_train': 0.14124368082331995, 'MAE_train': 10.527907281315368, 'MSE_test': 142.45531555627866, 'R2_test': 0.1413058673306904, 'MAE_test': 8.809892052298718}. 
Saved model results as M-A1-CZ_Hadamard_results.json. 
