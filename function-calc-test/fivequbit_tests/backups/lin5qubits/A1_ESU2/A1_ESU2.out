/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:29:43 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:27 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 17:31:32 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:33:10 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:34:25 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 17:35:43 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 391.67666459083557 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:58 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 17:38:00 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:35 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:48 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 17:42:02 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 378.4628026485443 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:15 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:19 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:57 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:12 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 17:48:30 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 390.1630184650421 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:49 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:56 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:34 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:49 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:03 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 390.90252780914307 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:56:19 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:23 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:59:01 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:00:15 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:30 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 388.23846459388733 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:02:47 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 18:03:51 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:05:32 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:50 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 18:08:04 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 392.6933238506317 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:09:16 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 18:10:22 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:12:02 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:13:18 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 18:14:34 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 390.99966764450073 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:15:50 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 18:16:56 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:18:34 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:19:49 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 18:21:09 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 394.8585889339447 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:22:25 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 18:23:30 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:25:07 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:26:22 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 18:27:37 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 387.6496820449829 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:28:55 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 18:30:02 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:31:44 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:33:02 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 18:34:19 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 401.5592713356018 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:35:32 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 18:36:37 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:38:14 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:39:29 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 18:40:47 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 392.6259207725525 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:42:06 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 18:43:10 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:44:48 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:46:03 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 18:47:18 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 386.830118894577 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:48:33 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 18:49:36 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:51:11 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:52:31 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 18:53:46 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 389.77541279792786 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:55:03 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 18:56:06 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:57:45 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:59:01 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 19:00:20 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 394.89404368400574 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 19:01:36 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 19:02:40 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:04:14 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:05:32 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 19:06:46 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 383.00888109207153 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 19:08:03 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 19:09:06 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:10:43 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:11:57 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 19:13:13 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 389.5987274646759 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 19:14:32 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 19:15:36 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:17:11 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:18:26 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 19:19:40 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 385.0338408946991 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 19:20:56 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 19:22:03 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:23:41 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:24:57 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 19:26:12 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 392.50810170173645 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 19:27:29 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 19:28:32 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:30:09 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:31:26 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 19:32:42 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 389.364382982254 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 19:33:58 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 19:35:05 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:36:44 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:37:59 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 19:39:15 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 402.36034631729126 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 19:40:43 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 19:41:51 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:43:30 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:44:47 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 19:46:00 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 396.8783130645752 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 19:47:16 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 19:48:18 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:49:53 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:51:08 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 19:52:20 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 378.43932914733887 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 19:53:33 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 19:54:35 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:56:10 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:57:23 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 19:58:38 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 384.52528524398804 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 20:00:02 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 20:01:06 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 20:02:41 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 20:03:53 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 20:05:14 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 391.40345287323 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 20:06:33 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Sun Mar 24 20:07:35 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 20:09:12 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Sun Mar 24 20:10:26 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Sun Mar 24 20:11:41 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 383.85505294799805 seconds. 
Discarding model... 

Training complete taking 9748.306431531906 total seconds. 
Now scoring model... 
Scoring complete taking 1.70200777053833 seconds. 
Saved predicted values as A1_ESU2_predicted_values.csv
Model scores: {'MSE_train': (2.355241023237118,), 'R2_train': 0.9885896476987953, 'MAE_train': 1.1430231599288108, 'MSE_test': 1.7886845956334845, 'R2_test': 0.9892181421137658, 'MAE_test': 1.1600953567392476}. 
Saved model results as A1_ESU2_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 11:28:29 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:29:18 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 11:30:26 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 11:32:01 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 11:33:17 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 11:34:32 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 394.3398380279541 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:35:48 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 11:36:50 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 11:38:26 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 11:39:41 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 11:40:53 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 381.3756732940674 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:42:06 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 11:43:09 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 11:44:49 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 11:46:09 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 11:47:24 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 391.7334032058716 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:48:38 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 11:49:43 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 11:51:17 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 11:52:31 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 11:53:45 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 380.42721676826477 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:54:59 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 11:56:04 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 11:57:40 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 11:58:52 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 12:00:06 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 384.4237172603607 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:01:24 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 12:02:28 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:04:10 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:05:24 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 12:06:37 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 387.1824631690979 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:07:51 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 12:08:54 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:10:36 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:11:50 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 12:13:08 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 391.79325914382935 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:14:22 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 12:15:25 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:17:06 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:18:22 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 12:19:38 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 389.7289562225342 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:20:53 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 12:21:58 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:23:34 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:24:50 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 12:26:07 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 389.32740688323975 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:27:23 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 12:28:28 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:30:05 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:31:21 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 12:32:39 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 392.68669414520264 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:33:54 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 12:34:59 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:36:33 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:37:51 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 12:39:06 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 387.1348783969879 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:40:21 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 12:41:25 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:43:03 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:44:16 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 12:45:29 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 381.9318354129791 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:46:46 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 12:47:50 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:49:25 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:50:40 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 12:51:53 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 382.85914421081543 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:53:08 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 12:54:12 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:55:46 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:57:04 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 12:58:19 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 387.3217360973358 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:59:38 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 13:00:42 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:02:24 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:03:46 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 13:05:05 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 405.15114521980286 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 13:06:18 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 13:07:22 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:09:02 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:10:17 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 13:11:31 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 386.42196822166443 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 13:12:45 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 13:13:49 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:15:23 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:16:39 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 13:17:56 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 388.85508584976196 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:19:13 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 13:20:21 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:21:57 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:23:15 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 13:24:30 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 391.52209877967834 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 13:25:46 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 13:26:50 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:28:24 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:29:41 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 13:30:56 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 384.5930242538452 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 13:32:11 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 13:33:14 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:34:53 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:36:11 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 13:37:29 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 392.1804780960083 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 13:38:42 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 13:39:46 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:41:21 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:42:37 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 13:43:52 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 383.7436833381653 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 13:45:06 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 13:46:15 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:47:48 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:49:00 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 13:50:13 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 380.2719955444336 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:51:26 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 13:52:28 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:54:01 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:55:18 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 13:56:30 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 377.1457600593567 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 13:57:43 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 13:58:44 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:00:21 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 14:01:38 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 14:02:52 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 382.85116744041443 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 14:04:08 2024]  Iteration number: 0 with current cost as 0.03362125092033269 and parameters 
[-1.78333278  2.23743465 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18552    -1.06648311]. 
Working on 0.4 fold... 
[Thu Apr  4 14:05:11 2024]  Iteration number: 0 with current cost as 0.18621877672384451 and parameters 
[-2.07651126  2.23743464 -2.12427961 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:06:50 2024]  Iteration number: 0 with current cost as 0.009214640603926624 and parameters 
[-1.6693854   2.23743465 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960146  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 14:08:06 2024]  Iteration number: 0 with current cost as 0.008848310057462684 and parameters 
[-1.65947891  2.23743462 -2.12427962 -0.11653104  0.55388707 -2.770109
  3.06858497  2.18960146  1.18552    -1.06648311]. 
Working on 1.0 fold... 
[Thu Apr  4 14:09:26 2024]  Iteration number: 0 with current cost as 0.006582741627591184 and parameters 
[-1.63734407  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Training complete taking 392.8964328765869 seconds. 
Discarding model... 

Training complete taking 9687.900990009308 total seconds. 
Now scoring model... 
Scoring complete taking 1.7118408679962158 seconds. 
Saved predicted values as A1_ESU2_predicted_values.csv
Model scores: {'MSE_train': (2.355241023237118,), 'R2_train': 0.9885896476987953, 'MAE_train': 1.1430231599288108, 'MSE_test': 1.7886845956334845, 'R2_test': 0.9892181421137658, 'MAE_test': 1.1600953567392476}. 
Saved model results as A1_ESU2_results.json. 
