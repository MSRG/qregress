/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:30:09 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:41 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 17:31:33 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 17:32:42 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:33:27 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 17:34:07 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 259.8228361606598 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:34:57 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 17:35:44 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 17:36:46 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:37:31 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:12 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 245.000727891922 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:02 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:59 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:03 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:49 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 17:42:29 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 258.7394313812256 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:21 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:08 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:12 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:45:57 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:39 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 247.67256450653076 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:29 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:15 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:18 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:03 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:44 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 245.48133635520935 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:34 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:21 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:27 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:14 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:54 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 251.61255979537964 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:46 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:31 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:33 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:20 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:00 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 245.50535559654236 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:53 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:00:40 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:01:48 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:02:32 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:03:14 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 252.9576358795166 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:04:05 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:04:51 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:05:54 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:40 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:20 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 247.06028699874878 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:08:12 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:08:56 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:09:59 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:10:46 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:11:26 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 245.95496344566345 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:12:17 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:13:03 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:14:05 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:14:52 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:15:32 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 245.90965723991394 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:16:24 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:17:10 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:18:12 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:18:57 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:19:37 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 245.40471482276917 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:20:29 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:21:15 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:22:18 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:23:03 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:23:44 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 246.0295536518097 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:24:35 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:25:21 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:26:24 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:27:09 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:27:49 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 246.49935936927795 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:28:41 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:29:26 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:30:29 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:31:16 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:31:55 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 245.5475149154663 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:32:47 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:33:33 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:34:36 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:35:22 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:36:01 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 246.39037442207336 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:36:53 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:37:38 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:38:43 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:39:27 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:40:07 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 245.71151661872864 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:40:59 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:41:46 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:42:48 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:43:34 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:44:15 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 246.10893321037292 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:45:05 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:45:51 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:46:54 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:47:39 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:48:20 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 247.2480125427246 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:49:12 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:49:57 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:51:01 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:51:47 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:52:27 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 247.44050216674805 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:53:20 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:54:05 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:55:08 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:55:55 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:56:35 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 246.9721291065216 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:57:27 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:58:13 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:59:16 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:00:01 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 19:00:42 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 246.20690321922302 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 19:01:33 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 19:02:19 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 19:03:24 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:04:09 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 19:04:50 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 249.06101059913635 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 19:05:40 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 19:06:27 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 19:07:29 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:08:16 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 19:08:56 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 245.80063724517822 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 19:09:48 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 19:10:35 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 19:11:55 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:12:40 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 19:13:21 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 264.9784572124481 seconds. 
Discarding model... 

Training complete taking 6215.118177175522 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.8067395687103271 seconds. 
Saved predicted values as M_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (623.8500269164799,), 'R2_train': -2.0223440064105875, 'MAE_train': 22.449042848325824, 'MSE_test': 528.8326453267025, 'R2_test': -2.187704775583679, 'MAE_test': 20.86029486683957}. 
Saved model results as M_Modified-Pauli-CRZ_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 11:42:50 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:43:20 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 11:44:07 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 11:45:11 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 11:45:57 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 11:46:38 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 251.56292700767517 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:47:31 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 11:48:16 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 11:49:20 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 11:50:08 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 11:50:48 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 249.79312419891357 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:51:41 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 11:52:27 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 11:53:33 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 11:54:18 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 11:54:58 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 249.41822361946106 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:55:50 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 11:56:46 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 11:57:49 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 11:58:36 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 11:59:16 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 258.6424412727356 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:00:09 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:00:55 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:01:59 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:02:46 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:03:26 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 250.3592290878296 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:04:19 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:05:06 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:06:10 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:06:56 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:07:38 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 251.52510786056519 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:08:29 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:09:16 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:10:20 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:11:07 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:11:47 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 248.59881114959717 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:12:39 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:13:25 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:14:30 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:15:18 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:15:58 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 252.02244591712952 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:16:51 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:17:38 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:18:42 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:19:28 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:20:09 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 251.01555609703064 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:21:02 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:21:48 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:22:52 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:23:40 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:24:20 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 250.70507979393005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:25:13 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:25:59 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:27:04 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:27:49 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:28:29 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 249.02700448036194 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:29:22 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:30:09 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:31:15 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:32:00 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:32:42 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 252.9899184703827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:33:35 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:34:20 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:35:24 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:36:11 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:36:51 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 248.28806567192078 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:37:43 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:38:29 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:39:34 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:40:19 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:40:59 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 248.56354904174805 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:41:52 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:42:39 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:43:43 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:44:28 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:45:10 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 250.42594742774963 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:46:01 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:46:48 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:47:51 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:48:38 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:49:18 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 248.301034450531 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:50:10 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:50:56 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:52:01 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:52:49 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:53:29 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 250.8768129348755 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:54:21 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:55:09 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:56:16 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:57:01 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:57:43 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 254.346928358078 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:58:36 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:59:21 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 13:00:24 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:01:12 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:01:52 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 248.9103696346283 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 13:02:45 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 13:03:30 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 13:04:36 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:05:22 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:06:01 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 249.24047589302063 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 13:06:54 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 13:07:41 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 13:08:45 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:09:31 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:10:13 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 251.65641498565674 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 13:11:06 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 13:11:51 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 13:12:55 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:13:43 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:14:23 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 249.83928632736206 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:15:16 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 13:16:02 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 13:17:07 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:17:53 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:18:39 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 254.31878781318665 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 13:19:30 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 13:20:19 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 13:21:27 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:22:14 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:22:54 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 257.017009973526 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 13:23:47 2024]  Iteration number: 0 with current cost as 0.07976172109987256 and parameters 
[-4.85400879  2.23743458 -2.12427958 -0.11653109  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18552004 -1.06648314  0.60271516  1.14432445
  1.31029899 -1.87354674  0.72965074  2.88578425 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 13:24:33 2024]  Iteration number: 0 with current cost as 0.9516194088061359 and parameters 
[-7.95280889  2.23743432 -2.12427932 -0.11653134  0.55388677 -2.77010929
  3.06858467  2.18960145  1.1855203  -1.0664834   0.60271542  1.14432445
  1.31029867 -1.87354649  0.72965049  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 13:25:38 2024]  Iteration number: 0 with current cost as 0.9892562590268816 and parameters 
[-7.91864412  2.23743432 -2.12427964 -0.11653134  0.55388677 -2.7701096
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534366 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:26:23 2024]  Iteration number: 0 with current cost as 1.0342591796196914 and parameters 
[-8.28308274  2.23743464 -2.12427964 -0.11653103  0.55388645 -2.77010929
  3.06858436  2.18960145  1.18551998 -1.06648371  0.6027151   1.14432445
  1.31029867 -1.8735468   0.72965018  2.88578388 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:27:04 2024]  Iteration number: 0 with current cost as 0.9832558896945487 and parameters 
[-7.72371319  2.23743495 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858467  2.18960177  1.18552061 -1.06648308  0.60271542  1.14432476
  1.31029899 -1.87354649  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 249.86175107955933 seconds. 
Discarding model... 

Training complete taking 6277.307349681854 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.8274400234222412 seconds. 
Saved predicted values as M_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (623.8500269164799,), 'R2_train': -2.0223440064105875, 'MAE_train': 22.449042848325824, 'MSE_test': 528.8326453267025, 'R2_test': -2.187704775583679, 'MAE_test': 20.86029486683957}. 
Saved model results as M_Modified-Pauli-CRZ_results.json. 
