/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/gjones/scratch/quad5qubits/quadratic_train.bin... 
Successfully loaded /home/gjones/scratch/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /home/gjones/scratch/quad5qubits/quadratic_test.bin... 
Successfully loaded /home/gjones/scratch/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /home/gjones/scratch/quad5qubits/quadratic_train.bin 
 at time Wed Mar 27 18:28:18 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 18:28:31 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:28:49 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:29:10 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:29:31 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:29:49 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.38277912139893 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 18:30:10 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:30:29 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:30:49 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:31:10 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:31:29 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.3912718296051 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 18:31:49 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:32:08 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:32:28 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:32:49 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:33:08 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.1870288848877 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 18:33:29 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:33:47 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:34:08 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:34:29 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:34:47 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 100.88606905937195 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 18:35:10 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:35:29 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:35:50 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:36:11 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:36:30 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 100.86810040473938 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 18:36:50 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:37:09 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:37:29 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:37:50 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:38:09 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.20599341392517 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 18:38:29 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:38:48 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:39:09 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:39:29 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:39:48 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.25813579559326 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 18:40:09 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:40:27 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:40:48 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:41:09 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:41:27 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.4341390132904 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 18:41:48 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:42:07 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:42:27 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:42:48 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:43:07 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.38584494590759 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 18:43:27 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:43:46 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:44:07 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:44:28 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:44:46 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.4605758190155 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 18:45:07 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:45:25 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:45:46 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:46:07 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:46:26 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.43895530700684 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 18:46:46 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:47:05 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:47:26 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:47:46 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:48:05 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 100.36191916465759 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 18:48:27 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:48:46 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:49:07 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:49:27 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:49:46 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.99270868301392 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 18:50:07 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:50:26 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:50:46 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:51:07 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:51:25 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.45610666275024 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 18:51:46 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:52:06 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:52:27 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:52:48 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:53:06 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 100.6281168460846 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 18:53:27 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:53:46 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:54:06 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:54:27 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:54:46 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.9533965587616 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 18:55:07 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:55:25 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:55:46 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:56:07 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:56:26 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.67236471176147 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 18:56:46 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:57:05 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:57:26 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:57:47 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:58:05 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.72038269042969 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 18:58:26 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 18:58:45 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 18:59:06 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 18:59:26 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 18:59:45 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.51340055465698 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 19:00:06 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 19:00:25 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 19:00:46 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 19:01:06 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 19:01:25 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 100.13027620315552 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 19:01:46 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 19:02:05 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 19:02:26 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 19:02:46 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 19:03:05 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.94977021217346 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 19:03:26 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 19:03:45 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 19:04:05 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 19:04:26 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 19:04:45 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 100.16486549377441 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 19:05:06 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 19:05:25 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 19:05:45 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 19:06:06 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 19:06:25 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 99.35145831108093 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 19:06:45 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 19:07:04 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 19:07:24 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 19:07:44 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 19:08:03 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 98.4989984035492 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 19:08:24 2024]  Iteration number: 0 with current cost as 0.4250977029811074 and parameters 
[-1.79590323  2.23743464 -2.12427926 -0.11653065  0.55388727]. 
Working on 0.4 fold... 
[Wed Mar 27 19:08:43 2024]  Iteration number: 0 with current cost as 0.39376838483331694 and parameters 
[-1.71811785  2.23743464 -2.12427948 -0.11653087  0.55388724]. 
Working on 0.6 fold... 
[Wed Mar 27 19:09:03 2024]  Iteration number: 0 with current cost as 0.441892922505655 and parameters 
[-1.77393979  2.23743464 -2.12427947 -0.11653087  0.5538874 ]. 
Working on 0.8 fold... 
[Wed Mar 27 19:09:24 2024]  Iteration number: 0 with current cost as 0.4118766093779689 and parameters 
[-1.60314872  2.23743496 -2.12427931 -0.11653086  0.5538874 ]. 
Working on 1.0 fold... 
[Wed Mar 27 19:09:42 2024]  Iteration number: 0 with current cost as 0.3676743993547964 and parameters 
[-1.72105752  2.23743478 -2.12427949 -0.11653088  0.55388723]. 
Training complete taking 98.94188046455383 seconds. 
Discarding model... 

Training complete taking 2492.23561501503 total seconds. 
Now scoring model... 
Scoring complete taking 0.9989328384399414 seconds. 
Saved predicted values as A2-A2-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (8.96404201506438,), 'R2_train': -0.23083044808524944, 'MAE_train': 2.6618896767975904, 'MSE_test': 10.451276075466359, 'R2_test': -0.04189459160439801, 'MAE_test': 2.9276134225383372}. 
Saved model results as A2-A2-CZ_Hadamard_results.json. 
