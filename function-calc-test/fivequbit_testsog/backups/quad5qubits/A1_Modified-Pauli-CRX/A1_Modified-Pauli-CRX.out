/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:48:18 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:48:42 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:51:49 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:54:49 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:58:06 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:01:35 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1018.5353050231934 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:05:41 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:46 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:11:47 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:15:06 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:18:35 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1022.4651503562927 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:22:43 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:25:47 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:28:47 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:07 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:35:37 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1019.9197721481323 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:39:43 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:42:52 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:45:53 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:49:10 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:52:42 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1024.751230955124 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:56:46 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:59:49 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:02:50 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:06:07 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:09:34 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1010.2856781482697 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:13:38 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:16:41 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:19:39 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:22:56 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:26:23 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1009.4608941078186 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:30:28 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:33:33 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:36:31 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:39:48 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:43:17 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1014.5058841705322 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:47:21 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:50:28 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:53:26 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:56:42 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:00:10 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1013.6171090602875 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:04:15 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:07:20 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:10:19 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:13:36 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:17:03 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1011.2202501296997 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:21:07 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:24:12 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:27:11 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:30:30 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:33:56 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1014.6254103183746 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:38:01 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:41:06 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:44:09 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:47:25 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:50:53 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1018.2400209903717 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:54:59 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:58:04 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:01:02 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:04:21 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:07:49 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1012.7068531513214 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:11:53 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:14:57 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:17:56 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:21:13 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:24:42 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1012.8558230400085 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:28:45 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:31:52 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:34:52 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:38:09 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:41:38 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1016.3300449848175 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:45:42 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:48:46 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:51:46 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:55:01 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:58:31 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1014.5579273700714 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 20:02:36 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:05:42 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:08:40 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:11:56 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:15:25 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1014.4369118213654 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:19:30 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:22:38 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:25:37 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:28:53 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:32:23 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1016.5696768760681 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:36:28 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:39:33 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:42:35 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:45:52 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:49:21 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1018.4075028896332 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:53:26 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:56:33 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:59:32 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:02:51 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:06:22 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1020.5942621231079 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:10:26 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:13:31 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:16:29 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:19:47 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:23:20 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1019.1325628757477 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 21:27:25 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:30:31 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:33:32 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:36:48 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:40:20 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1019.0040261745453 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:44:25 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:47:29 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:50:26 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:53:44 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:57:10 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1013.1355307102203 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 22:01:19 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:04:26 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:07:25 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:10:42 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:14:10 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1018.1853666305542 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:18:15 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:21:20 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:24:21 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:27:37 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:31:06 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1015.8623616695404 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:35:10 2024]  Iteration number: 0 with current cost as 0.3283305660692255 and parameters 
[-2.96101824  2.1043109  -2.16321177 -0.11653107  0.55388706 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648312  1.18336091  1.14432443
  1.31029896 -1.8735468   0.72965078  2.88578417 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:38:15 2024]  Iteration number: 0 with current cost as 0.3720787532588331 and parameters 
[-3.00861006  2.09647963 -2.14593806 -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960141  1.18551998 -1.06648316  1.48536858  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:41:12 2024]  Iteration number: 0 with current cost as 0.3713011173756436 and parameters 
[-2.9956524   2.09518511 -2.15507235 -0.11653105  0.55388706 -2.77010899
  3.06858496  2.18960143  1.18552    -1.0664831   1.41472861  1.14432443
  1.31029897 -1.87354678  0.72965078  2.88578417 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:44:30 2024]  Iteration number: 0 with current cost as 0.32455979928458734 and parameters 
[-3.00152234  2.17781354 -2.1102392  -0.11653103  0.55388708 -2.77010897
  3.068585    2.18960147  1.18552    -1.0664831   1.25988386  1.14432447
  1.310299   -1.87354676  0.72965078  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:47:59 2024]  Iteration number: 0 with current cost as 0.36625796812441397 and parameters 
[-3.05553277  2.26488673 -2.0389378  -0.11653105  0.55388705 -2.770109
  3.06858493  2.1896014   1.18552001 -1.06648314  1.42466907  1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578414 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1013.1391308307648 seconds. 
Discarding model... 

Training complete taking 25402.54601740837 total seconds. 
Now scoring model... 
Scoring complete taking 0.7188079357147217 seconds. 
Saved predicted values as A1_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (4.40829426483022,), 'R2_train': 0.39470801272971867, 'MAE_train': 1.6778691503422536, 'MSE_test': 7.3223206222599755, 'R2_test': 0.27003303718722294, 'MAE_test': 2.318678761322744}. 
Saved model results as A1_Modified-Pauli-CRX_results.json. 
