/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:59 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:03:37 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 16:07:02 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:10:35 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:14:19 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:18:08 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1070.9181818962097 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:31 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 16:25:08 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:28:44 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:30 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:36:23 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1092.918827533722 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:39:39 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 16:43:25 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:47:01 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:50:35 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:54:14 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1075.4007377624512 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:57:35 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 17:01:08 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:04:33 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:08:23 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:12:25 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1090.866133928299 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:15:54 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 17:20:06 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:23:38 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:27:40 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:31:27 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1141.3542068004608 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:34:58 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 17:38:52 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:42:48 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:46:37 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:50:36 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1152.742222070694 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:54:09 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 17:58:05 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:02:23 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:06:17 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:10:00 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1156.2052240371704 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:13:34 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 18:17:50 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:22:09 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:26:05 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:29:51 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1192.6042358875275 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:33:17 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 18:37:09 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:40:32 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:43:56 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:47:23 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1042.0169377326965 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:50:28 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 18:53:55 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:57:20 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:00:41 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:04:07 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1005.3840420246124 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:07:12 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 19:10:30 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:13:54 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:17:15 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:20:32 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 981.5882565975189 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:23:35 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 19:27:02 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:30:24 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:33:49 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:37:08 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 996.808926820755 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:40:10 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 19:43:28 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:46:45 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:50:04 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:53:22 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 975.2893807888031 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:56:22 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 19:59:42 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:03:06 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:06:26 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:09:41 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 978.8236172199249 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 20:12:45 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 20:16:03 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:19:24 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:22:44 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:26:04 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 981.3807651996613 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 20:29:05 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 20:32:26 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:35:45 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:39:03 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:42:30 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 988.911536693573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:45:31 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 20:48:51 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:52:13 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:55:32 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:58:53 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 982.4186296463013 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 21:01:55 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 21:05:13 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:08:31 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:11:56 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:15:15 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 980.3178927898407 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 21:18:19 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 21:21:58 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:25:28 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:29:12 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:32:42 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1048.2155873775482 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:35:49 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 21:39:10 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:42:31 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:45:50 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:49:05 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 983.6261966228485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 21:52:06 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 21:55:27 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:58:53 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:02:13 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:05:28 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 980.5779893398285 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 22:08:25 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 22:11:37 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:14:56 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:18:18 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:21:33 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 966.0903751850128 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 22:24:33 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 22:27:50 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:31:05 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:34:26 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:37:47 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 974.2574062347412 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:40:51 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 22:44:15 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:47:40 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:51:01 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:54:25 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 998.8201742172241 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:57:25 2024]  Iteration number: 0 with current cost as 0.16374089687555177 and parameters 
[-3.60655912  2.23743461 -2.12427966 -0.11653105  0.55388705 -2.770109
  3.06858493  2.18960142  1.18551998 -1.06648314  0.6027151   1.1443244
  1.31029896 -1.87354683]. 
Working on 0.4 fold... 
[Mon Apr  1 23:00:49 2024]  Iteration number: 0 with current cost as 0.172760883190768 and parameters 
[-3.63298138  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858496  2.18960143  1.18551998 -1.06648311  0.60271508  1.14432443
  1.31029899 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:04:08 2024]  Iteration number: 0 with current cost as 0.17140794867127954 and parameters 
[-3.59744619  2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432442
  1.31029896 -1.8735468 ]. 
Working on 0.8 fold... 
[Mon Apr  1 23:07:34 2024]  Iteration number: 0 with current cost as 0.1322503258060817 and parameters 
[-3.56751037  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:11:22 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427964 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960146  1.18552001 -1.0664831   0.60271513  1.14432445
  1.31029901 -1.8735468 ]. 
Training complete taking 1040.9811635017395 seconds. 
Discarding model... 

Training complete taking 25878.51932144165 total seconds. 
Now scoring model... 
Scoring complete taking 1.962860107421875 seconds. 
Saved predicted values as A2-A2-CZ_Efficient-CRZ_predicted_values.csv
Model scores: {'MSE_train': (3.3812569602261577,), 'R2_train': 0.5357279659719845, 'MAE_train': 1.2525997870114243, 'MSE_test': 6.77673856961591, 'R2_test': 0.3244224711493253, 'MAE_test': 1.8807983670312751}. 
Saved model results as A2-A2-CZ_Efficient-CRZ_results.json. 
