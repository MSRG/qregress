/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:46:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:48:34 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 15:52:10 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 15:55:19 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 15:58:18 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 16:01:15 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 958.0221235752106 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:04:13 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 16:07:42 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 16:11:26 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 16:14:36 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 16:17:44 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 997.7361264228821 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:20:50 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 16:24:18 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 16:27:57 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 16:31:09 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 16:33:54 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 964.3754591941833 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:37:11 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 16:40:29 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:01 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 16:47:03 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 16:50:16 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 983.5389652252197 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:53:30 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 16:57:04 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 17:00:27 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 17:03:48 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 17:07:03 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1022.1769647598267 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:10:27 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 17:13:48 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 17:17:34 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 17:20:43 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 17:23:46 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 985.116664648056 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:26:48 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 17:30:22 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 17:33:51 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 17:37:01 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 17:40:14 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 990.640659570694 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:43:19 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 17:46:32 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 17:49:42 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 17:52:28 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 17:55:15 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 894.9164021015167 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:58:00 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 18:01:06 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 18:04:26 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 18:07:46 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 18:10:49 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 947.6981310844421 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:14:04 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 18:17:47 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 18:21:10 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 18:24:12 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 18:27:15 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 984.7968468666077 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:30:14 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 18:33:39 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 18:37:12 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 18:40:23 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 18:43:35 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 972.7939820289612 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:46:44 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 18:50:12 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 18:53:41 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 18:56:50 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 19:00:15 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1018.4750497341156 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:03:42 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 19:07:35 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 19:11:16 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 19:14:16 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 19:17:34 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1028.3843569755554 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:20:54 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 19:24:17 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 19:27:48 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 19:30:59 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 19:34:10 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1000.1855113506317 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:37:29 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 19:41:30 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 19:45:15 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 19:48:47 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 19:52:11 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1079.1367599964142 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:55:21 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 19:58:45 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 20:02:29 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 20:05:22 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 20:08:30 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 974.2834374904633 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:11:41 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 20:15:22 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 20:18:46 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 20:22:00 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 20:25:21 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1002.230696439743 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:28:27 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 20:31:52 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 20:35:20 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 20:38:34 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 20:41:51 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1003.8872101306915 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:45:02 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 20:48:23 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 20:51:52 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 20:55:05 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 20:58:11 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 972.4874975681305 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:01:14 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 21:04:48 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 21:08:14 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 21:11:20 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 21:14:26 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 991.7202718257904 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 21:17:46 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 21:21:22 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 21:25:02 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 21:28:15 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 21:31:32 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1021.0158677101135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:35:06 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 21:38:48 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 21:42:25 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 21:45:28 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 21:48:39 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1012.6243867874146 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 21:51:45 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 21:55:22 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 21:58:56 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 22:02:06 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 22:05:22 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1015.3026130199432 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:08:50 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 22:12:50 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 22:16:28 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 22:19:24 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 22:22:40 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1040.31103849411 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:26:08 2024]  Iteration number: 0 with current cost as 0.2337629155882658 and parameters 
[-2.36042348  2.23743464 -2.1242796  -0.116531    0.55388708 -2.77010897
  3.06858501  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432448
  1.31029905 -1.87354674]. 
Working on 0.4 fold... 
[Mon Apr  1 22:29:45 2024]  Iteration number: 0 with current cost as 0.22056725547038758 and parameters 
[-2.34333036  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271514  1.14432445
  1.31029899 -1.87354677]. 
Working on 0.6 fold... 
[Mon Apr  1 22:33:16 2024]  Iteration number: 0 with current cost as 0.21564270864488055 and parameters 
[-2.42077861  2.23743465 -2.12427965 -0.11653103  0.55388705 -2.77010899
  3.06858498  2.18960142  1.18551995 -1.06648308  0.60271514  1.14432443
  1.31029902 -1.87354675]. 
Working on 0.8 fold... 
[Mon Apr  1 22:36:16 2024]  Iteration number: 0 with current cost as 0.15928698005330869 and parameters 
[-2.48335818  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010899
  3.068585    2.18960145  1.18551998 -1.06648307  0.60271514  1.14432445
  1.310299   -1.87354678]. 
Working on 1.0 fold... 
[Mon Apr  1 22:39:32 2024]  Iteration number: 0 with current cost as 0.16863640987668166 and parameters 
[-2.43056608  2.23743466 -2.12427961 -0.11653101  0.55388706 -2.77010895
  3.06858498  2.18960147  1.18551996 -1.06648308  0.60271514  1.14432445
  1.31029901 -1.87354676]. 
Training complete taking 1004.8950514793396 seconds. 
Discarding model... 

Training complete taking 24866.753080129623 total seconds. 
Now scoring model... 
Scoring complete taking 2.610038995742798 seconds. 
Saved predicted values as A1-A1-CNOT_Efficient-CRX_predicted_values.csv
Model scores: {'MSE_train': (4.3918062247728615,), 'R2_train': 0.3969719447480806, 'MAE_train': 1.3645818802108987, 'MSE_test': 3.592703217427446, 'R2_test': 0.6418410513272806, 'MAE_test': 1.5701882534512814}. 
Saved model results as A1-A1-CNOT_Efficient-CRX_results.json. 
