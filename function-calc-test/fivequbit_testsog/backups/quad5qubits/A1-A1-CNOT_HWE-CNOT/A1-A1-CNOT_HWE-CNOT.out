/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:35 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:01:43 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 16:04:58 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 16:05:06 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 16:08:35 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:09:24 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 16:12:43 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 16:13:22 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 16:16:33 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 16:17:04 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 16:20:25 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1176.1095135211945 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:19 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 16:24:41 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 16:24:48 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 16:28:17 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:29:09 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 16:32:31 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 16:33:12 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 16:36:22 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 16:36:52 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 16:40:17 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1192.0851383209229 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:41:11 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 16:44:26 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 16:44:35 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 16:48:02 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:48:50 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 16:52:10 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:49 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 16:56:01 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 16:56:31 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 16:59:52 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1175.7803702354431 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:00:46 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 17:04:03 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 17:04:11 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 17:07:36 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:08:26 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 17:11:47 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 17:12:25 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 17:15:39 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 17:16:10 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 17:19:33 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1179.4510171413422 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:20:26 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 17:23:44 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 17:23:51 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 17:27:21 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:28:10 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 17:31:30 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 17:32:09 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 17:35:25 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 17:35:55 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 17:39:18 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1186.2539343833923 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:40:12 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 17:43:26 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 17:43:35 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 17:47:01 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:47:51 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 17:51:11 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 17:51:50 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 17:55:02 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 17:55:33 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 17:58:56 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1177.018343448639 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:59:49 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 18:03:04 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 18:03:12 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 18:06:36 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:07:24 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 18:10:41 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 18:11:19 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 18:14:28 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 18:14:59 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 18:18:19 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1161.802937746048 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:19:12 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 18:22:25 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 18:22:32 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 18:25:57 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:26:46 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 18:30:02 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 18:30:41 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 18:33:51 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 18:34:21 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 18:37:43 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1164.6524686813354 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:38:35 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 18:41:51 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 18:41:58 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 18:45:24 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:46:14 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 18:49:35 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 18:50:13 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 18:53:23 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 18:53:54 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 18:57:14 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1170.8113968372345 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:58:06 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 19:01:20 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 19:01:28 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 19:04:53 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:05:43 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 19:08:58 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 19:09:36 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 19:12:47 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 19:13:16 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 19:16:35 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1162.1369514465332 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:17:28 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 19:20:41 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 19:20:48 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 19:24:15 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:25:04 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 19:28:22 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 19:29:00 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 19:32:10 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 19:32:41 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 19:36:00 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1165.2821536064148 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:36:54 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 19:40:11 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 19:40:18 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 19:43:44 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:44:32 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 19:47:50 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 19:48:27 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 19:51:35 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 19:52:05 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 19:55:27 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1165.6550920009613 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:56:19 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 19:59:30 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 19:59:37 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 20:03:03 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:03:53 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 20:07:08 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 20:07:46 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 20:10:55 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 20:11:26 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 20:14:47 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1159.6499874591827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:15:39 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 20:18:53 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 20:19:00 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 20:22:26 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:23:16 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 20:26:32 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 20:27:09 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 20:30:19 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 20:30:50 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 20:34:09 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1163.6038780212402 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 20:35:03 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 20:38:15 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 20:38:23 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 20:41:47 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:42:36 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 20:45:51 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 20:46:29 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 20:49:36 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 20:50:06 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 20:53:28 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1158.308262348175 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 20:54:22 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 20:57:35 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 20:57:42 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 21:01:21 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:02:09 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 21:05:28 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 21:06:06 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 21:09:17 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 21:09:48 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 21:13:09 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1181.6681518554688 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:14:03 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 21:17:15 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 21:17:24 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 21:20:52 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:21:42 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 21:25:05 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 21:25:42 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 21:28:52 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 21:29:22 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 21:32:41 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1173.2064054012299 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 21:33:36 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 21:36:52 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 21:36:59 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 21:40:29 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:41:18 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 21:44:35 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 21:45:13 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 21:48:24 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 21:48:54 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 21:52:15 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1173.3014223575592 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 21:53:09 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 21:56:24 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 21:56:31 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 21:59:55 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:00:44 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 22:04:04 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 22:04:41 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 22:07:51 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 22:08:21 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 22:11:44 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1168.196004152298 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:12:37 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 22:15:54 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 22:16:01 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 22:19:26 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:20:14 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 22:23:38 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 22:24:15 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 22:27:26 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 22:27:56 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 22:31:16 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1171.7635779380798 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 22:32:09 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 22:35:24 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 22:35:31 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 22:38:59 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:39:48 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 22:43:11 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 22:43:49 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 22:46:58 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 22:47:29 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 22:50:48 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1172.4314815998077 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 22:51:42 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 22:54:56 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 22:55:04 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 22:58:28 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:59:17 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 23:02:36 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 23:03:14 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 23:06:23 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 23:06:53 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 23:10:19 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1171.0016875267029 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 23:11:12 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 23:14:31 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 23:14:39 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 23:18:06 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:18:55 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 23:22:13 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 23:22:50 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 23:26:03 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 23:26:34 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 23:30:08 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1189.8290791511536 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 23:31:03 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 23:34:19 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 23:34:28 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 23:37:55 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:38:44 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Mon Apr  1 23:42:04 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Mon Apr  1 23:42:42 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Mon Apr  1 23:45:54 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Mon Apr  1 23:46:25 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Mon Apr  1 23:49:45 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1176.0914022922516 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 23:50:38 2024]  Iteration number: 0 with current cost as 0.45631075113292463 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13529176  0.5553907  -2.7897807
  2.96371304  2.16354729  1.38115208 -1.05965376  0.68130374  1.17718579
  1.35342577 -1.83376554  0.72741628]. 
[Mon Apr  1 23:53:58 2024]  Iteration number: 50 with current cost as 0.13838886672031397 and parameters 
[-2.9031834   2.2374347  -2.1242794   1.78819462  0.71707981 -4.87741329
  3.24829041  2.77156378  3.2560034  -0.78454327  0.30314825  0.80775069
  0.42518013 -3.40794707  0.43879026]. 
Working on 0.4 fold... 
[Mon Apr  1 23:54:05 2024]  Iteration number: 0 with current cost as 0.4231258761405694 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14312263  0.55501629 -2.79958263
  2.97679303  2.16643538  1.35695803 -1.06163775  0.66945685  1.17107344
  1.34056128 -1.84606286  0.72654066]. 
[Mon Apr  1 23:57:38 2024]  Iteration number: 50 with current cost as 0.13208197852029036 and parameters 
[-2.90318428  2.23743455 -2.12428012  3.21213825  1.87442048 -6.19496539
  3.64484332  2.6383654   3.69875083 -0.59893348  0.23326635  0.61704013
  0.2891843  -4.46550019  0.8046245 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:58:27 2024]  Iteration number: 0 with current cost as 0.49522466071945787 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.14437092  0.55111724 -2.80724035
  2.95857786  2.16315511  1.39022824 -1.05851723  0.68582011  1.17997748
  1.34899355 -1.83803883  0.72698402]. 
[Tue Apr  2 00:01:47 2024]  Iteration number: 50 with current cost as 0.13252311399685665 and parameters 
[-2.90318361  2.23743499 -2.12427944  2.14099368  0.0853446  -5.2798299
  3.38845393  2.37547407  3.4697257  -0.47978089  0.22897542  0.493735
 -0.39351811 -5.12527387  0.78675593]. 
Working on 0.8 fold... 
[Tue Apr  2 00:02:27 2024]  Iteration number: 0 with current cost as 0.4748217076780599 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.13738272  0.55042454 -2.80012332
  2.95522885  2.16444434  1.39526753 -1.05896888  0.68911642  1.18045986
  1.35233792 -1.83764748  0.71716783]. 
[Tue Apr  2 00:05:38 2024]  Iteration number: 50 with current cost as 0.09939774282981195 and parameters 
[-2.90318337  2.23743459 -2.12427967  1.42107804  0.08625053 -4.56928666
  3.30464134  2.21469635  3.39664979 -0.48942631  0.3167861   0.50667863
 -0.14894016 -4.9062898   0.66193254]. 
Working on 1.0 fold... 
[Tue Apr  2 00:06:11 2024]  Iteration number: 0 with current cost as 0.315392388661268 and parameters 
[-2.90318345  2.23743465 -2.1242796  -0.28338195  0.51404782 -3.0295391
  2.63711813  2.05411641  2.0065071  -1.02186268  0.99873442  1.32230692
  1.35092065 -1.84454717  0.697221  ]. 
[Tue Apr  2 00:09:34 2024]  Iteration number: 50 with current cost as 0.1110339840822871 and parameters 
[-2.9031839   2.23743434 -2.12427988  3.29344458  0.22289673 -6.33929036
  3.45538912  2.89344731  3.57320706 -0.62580698  0.40489603  0.77017514
 -0.70016636 -5.33165525  0.86576582]. 
Training complete taking 1187.2758371829987 seconds. 
Discarding model... 

Training complete taking 29323.36799097061 total seconds. 
Now scoring model... 
Scoring complete taking 0.6508300304412842 seconds. 
Saved predicted values as A1-A1-CNOT_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (2.721036119528113,), 'R2_train': 0.6263812574030106, 'MAE_train': 1.1623833281476947, 'MSE_test': 2.7306685564649253, 'R2_test': 0.7277778541202644, 'MAE_test': 1.3974730178687633}. 
Saved model results as A1-A1-CNOT_HWE-CNOT_results.json. 
