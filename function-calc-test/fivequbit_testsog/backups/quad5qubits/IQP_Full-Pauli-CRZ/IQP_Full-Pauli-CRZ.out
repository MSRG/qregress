/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:06:24 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:06:39 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 16:12:26 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 16:17:46 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 16:23:29 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 16:29:26 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1759.5779144763947 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:35:59 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 16:41:44 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 16:47:05 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:52 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 16:58:50 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1761.4480566978455 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:21 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 17:11:05 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 17:16:27 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 17:22:10 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 17:28:09 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1758.8823437690735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:34:39 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 17:40:22 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 17:45:43 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 17:51:27 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 17:57:27 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1759.2972600460052 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:03:59 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 18:09:40 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 18:14:59 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 18:20:39 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 18:26:34 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1740.8726885318756 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:32:59 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 18:38:38 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 18:43:56 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 18:49:36 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 18:55:31 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1737.6476588249207 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:01:57 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 19:07:38 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 19:12:55 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 19:18:35 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 19:24:33 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1743.6433126926422 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:31:01 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 19:36:46 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 19:42:08 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 19:47:49 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 19:53:48 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1752.7732162475586 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:00:13 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 20:05:55 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 20:11:13 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 20:16:54 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 20:22:48 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1743.244266986847 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 20:29:16 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 20:34:58 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 20:40:17 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 20:45:58 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 20:51:54 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1745.4058051109314 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 20:58:21 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 21:04:02 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 21:09:17 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 21:14:58 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 21:20:54 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1740.2869336605072 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:27:21 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 21:33:03 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 21:38:20 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 21:44:02 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 21:49:56 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1743.2648179531097 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 21:56:25 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 22:02:06 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 22:07:23 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 22:13:02 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 22:18:57 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1739.5222806930542 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:25:24 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 22:31:05 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 22:36:23 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 22:42:04 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 22:48:00 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1746.2259690761566 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:54:30 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 23:00:12 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 23:05:33 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 23:11:14 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 23:17:10 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1745.8996489048004 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 23:23:36 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 23:29:15 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 23:34:33 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Mon Apr  1 23:40:13 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Mon Apr  1 23:46:07 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1736.7707133293152 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 23:52:33 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 23:58:15 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 00:03:35 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Tue Apr  2 00:09:14 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Tue Apr  2 00:15:10 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1742.738938331604 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 00:21:36 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 00:27:20 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 00:32:39 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Tue Apr  2 00:38:20 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Tue Apr  2 00:44:16 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1746.5441627502441 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 00:50:42 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 00:56:25 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 01:01:43 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Tue Apr  2 01:07:24 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Tue Apr  2 01:13:20 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1742.5466921329498 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 01:19:45 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 01:25:25 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 01:30:42 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Tue Apr  2 01:36:26 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Tue Apr  2 01:42:21 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1738.936541557312 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 01:48:44 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 01:54:27 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 01:59:45 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Tue Apr  2 02:05:30 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Tue Apr  2 02:11:26 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1747.2627363204956 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 02:17:53 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 02:23:33 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 02:28:50 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Tue Apr  2 02:34:33 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Tue Apr  2 02:40:28 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1743.5091519355774 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 02:46:56 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 02:52:38 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 02:57:53 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Tue Apr  2 03:03:33 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Tue Apr  2 03:09:31 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1743.0171501636505 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 03:15:59 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 03:21:39 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 03:26:58 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Tue Apr  2 03:32:42 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Tue Apr  2 03:38:38 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1744.9898536205292 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 03:45:04 2024]  Iteration number: 0 with current cost as 0.3163699481930967 and parameters 
[-2.83792096  3.06651865 -2.12172904 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13270738  1.14432445
  1.09221143 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 03:50:45 2024]  Iteration number: 0 with current cost as 0.33945305241032375 and parameters 
[-2.81494869  3.05076833 -2.11712324 -0.11653103  0.55388707 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648309  1.14390454  1.14432444
  1.06974606 -1.87354679  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 03:56:03 2024]  Iteration number: 0 with current cost as 0.34738913823890416 and parameters 
[-2.81889417  3.05044028 -2.11558526 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  1.14679007  1.14432445
  1.07381648 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522483
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 0.8 fold... 
[Tue Apr  2 04:01:45 2024]  Iteration number: 0 with current cost as 0.3010639331432477 and parameters 
[-2.83345541  3.06306868 -2.12050623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   1.13564701  1.14432445
  1.08773268 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897371  1.60512664  2.83077107 -1.2645671  -0.25136103]. 
Working on 1.0 fold... 
[Tue Apr  2 04:07:39 2024]  Iteration number: 0 with current cost as 0.3232508960142838 and parameters 
[-2.80310132  3.04115385 -2.11369954 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960144  1.18551998 -1.0664831   1.15132031  1.14432445
  1.05922254 -1.87354681  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Training complete taking 1741.9487953186035 seconds. 
Discarding model... 

Training complete taking 43646.259118556976 total seconds. 
Now scoring model... 
Scoring complete taking 0.8019461631774902 seconds. 
Saved predicted values as IQP_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (2.0945727803547296,), 'R2_train': 0.7123993897553521, 'MAE_train': 1.2128617407255222, 'MSE_test': 3.139424698853635, 'R2_test': 0.6870286852183348, 'MAE_test': 1.5232064177759264}. 
Saved model results as IQP_Full-Pauli-CRZ_results.json. 
