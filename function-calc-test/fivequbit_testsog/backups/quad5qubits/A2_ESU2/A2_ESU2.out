/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/gjones/scratch/quad5qubits/quadratic_train.bin... 
Successfully loaded /home/gjones/scratch/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /home/gjones/scratch/quad5qubits/quadratic_test.bin... 
Successfully loaded /home/gjones/scratch/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /home/gjones/scratch/quad5qubits/quadratic_train.bin 
 at time Thu Mar 28 03:56:33 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 03:57:17 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 03:58:55 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 04:00:11 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 04:01:49 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:03:48 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 456.44901943206787 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 04:04:53 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:06:30 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 04:07:47 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 04:09:24 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:11:24 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 455.5827078819275 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 04:12:29 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:14:06 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 04:15:22 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 04:16:59 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:18:58 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 455.0182111263275 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 04:20:04 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:21:41 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 04:22:57 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 04:24:34 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:26:33 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 454.2278513908386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 04:27:38 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:29:15 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 04:30:31 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 04:32:08 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:34:07 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 454.3544411659241 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 04:35:12 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:36:50 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 04:38:07 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 04:39:44 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:41:44 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 456.4728271961212 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 04:42:49 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:44:27 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 04:45:43 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 04:47:20 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:49:19 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 455.4059908390045 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 04:50:24 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:52:02 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 04:53:17 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 04:54:55 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:56:53 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 454.52091670036316 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 04:57:59 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:59:36 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 05:00:52 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 05:02:29 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 05:04:28 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 454.80824184417725 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 05:05:33 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 05:07:11 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 05:08:27 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 05:10:05 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 05:12:04 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 455.23262548446655 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 05:13:09 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 05:14:46 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 05:16:02 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 05:17:39 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 05:19:38 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 453.9706230163574 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 05:20:42 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 05:22:20 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 05:23:37 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 05:25:15 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 05:27:13 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 455.62686133384705 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 05:28:18 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 05:29:55 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 05:31:11 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 05:32:48 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 05:34:48 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 454.841135263443 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 05:35:53 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 05:37:31 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 05:38:47 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 05:40:24 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 05:42:23 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 455.3023841381073 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 05:43:29 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 05:45:06 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 05:46:21 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 05:47:59 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 05:49:57 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 455.869225025177 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 05:51:07 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 05:52:44 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 05:54:00 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 05:55:37 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 05:57:36 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 456.9867284297943 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 05:58:41 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 06:00:19 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 06:01:34 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 06:03:11 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 06:05:10 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 453.82437658309937 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 06:06:15 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 06:07:52 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 06:09:09 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 06:10:46 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 06:12:46 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 456.4013161659241 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 06:13:52 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 06:15:29 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 06:16:45 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 06:18:23 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 06:20:23 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 456.1115777492523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 06:21:27 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 06:23:05 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 06:24:22 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 06:25:59 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 06:27:58 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 455.73293566703796 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 06:29:03 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 06:30:41 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 06:31:57 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 06:33:34 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 06:35:34 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 456.19354724884033 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 06:36:40 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 06:38:17 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 06:39:33 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 06:41:11 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 06:43:10 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 455.84504795074463 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 06:44:15 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 06:45:53 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 06:47:09 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 06:48:46 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 06:50:45 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 454.62968015670776 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 06:51:50 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 06:53:28 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 06:54:44 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 06:56:22 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 06:58:21 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 455.52526235580444 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 06:59:25 2024]  Iteration number: 0 with current cost as 0.3357537984772103 and parameters 
[-2.26178253  2.23743466 -2.12427959 -0.116531    0.5538871  -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 07:01:03 2024]  Iteration number: 0 with current cost as 0.36909560563478916 and parameters 
[-2.04229695  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858491  2.18960145  1.18552002 -1.06648316]. 
Working on 0.6 fold... 
[Thu Mar 28 07:02:20 2024]  Iteration number: 0 with current cost as 0.36269195287415723 and parameters 
[-2.043309    2.23743464 -2.1242796  -0.11653099  0.55388708 -2.77010897
  3.06858496  2.18960149  1.18552002 -1.06648312]. 
Working on 0.8 fold... 
[Thu Mar 28 07:03:57 2024]  Iteration number: 0 with current cost as 0.33515670562452216 and parameters 
[-2.2221103   2.23743466 -2.12427959 -0.116531    0.55388708 -2.770109
  3.06858494  2.1896015   1.18552005 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 07:05:57 2024]  Iteration number: 0 with current cost as 0.4010254566381948 and parameters 
[-2.04561434  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 456.20275712013245 seconds. 
Discarding model... 

Training complete taking 11385.137131690979 total seconds. 
Now scoring model... 
Scoring complete taking 2.011941909790039 seconds. 
Saved predicted values as A2_ESU2_predicted_values.csv
Model scores: {'MSE_train': (7.872439680936381,), 'R2_train': -0.08094523025742806, 'MAE_train': 2.334670175636332, 'MSE_test': 16.949225781230663, 'R2_test': -0.689679475102571, 'MAE_test': 3.0883298935985066}. 
Saved model results as A2_ESU2_results.json. 
