/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /home/gjones/scratch/quad5qubits/quadratic_train.bin... 
Successfully loaded /home/gjones/scratch/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /home/gjones/scratch/quad5qubits/quadratic_test.bin... 
Successfully loaded /home/gjones/scratch/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /home/gjones/scratch/quad5qubits/quadratic_train.bin 
 at time Thu Mar 28 02:25:33 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 02:26:17 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 02:27:44 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 02:29:03 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 02:30:21 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 02:31:59 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 407.7360506057739 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 02:33:04 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 02:34:32 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 02:35:48 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 02:37:04 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 02:38:43 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 404.3800733089447 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 02:39:49 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 02:41:16 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 02:42:33 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 02:43:49 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 02:45:27 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 403.91355562210083 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 02:46:32 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 02:48:03 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 02:49:19 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 02:50:36 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 02:52:14 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 406.64638090133667 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 02:53:19 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 02:54:46 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 02:56:02 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 02:57:18 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 02:58:57 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 403.0485203266144 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 03:00:02 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 03:01:29 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 03:02:44 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 03:04:00 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 03:05:38 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 401.7252254486084 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 03:06:44 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 03:08:10 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 03:09:26 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 03:10:42 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 03:12:21 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 402.58486008644104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 03:13:27 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 03:14:54 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 03:16:10 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 03:17:26 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 03:19:03 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 401.8157753944397 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 03:20:08 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 03:21:36 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 03:22:52 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 03:24:08 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 03:25:45 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 402.3925898075104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 03:26:51 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 03:28:19 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 03:29:35 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 03:30:52 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 03:32:30 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 404.6515498161316 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 03:33:35 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 03:35:02 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 03:36:18 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 03:37:33 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 03:39:10 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 400.1706621646881 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 03:40:15 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 03:41:43 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 03:42:59 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 03:44:17 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 03:45:56 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 405.91124176979065 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 03:47:02 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 03:48:29 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 03:49:45 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 03:51:01 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 03:52:39 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 402.8653199672699 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 03:53:44 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 03:55:11 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 03:56:28 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 03:57:44 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 03:59:22 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 403.23342776298523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 04:00:27 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:01:54 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 04:03:10 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 04:04:26 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:06:03 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 401.0783474445343 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 04:07:09 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:08:36 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 04:09:51 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 04:11:08 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:12:45 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 402.1187994480133 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 04:13:50 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:15:17 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 04:16:33 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 04:17:49 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:19:28 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 402.1918969154358 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 04:20:33 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:22:00 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 04:23:15 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 04:24:31 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:26:08 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 399.95240116119385 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 04:27:12 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:28:39 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 04:30:00 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 04:31:16 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:32:54 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 405.9830939769745 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 04:33:59 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:35:25 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 04:36:41 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 04:37:57 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:39:34 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 400.86255717277527 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 04:40:40 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:42:06 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 04:43:22 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 04:44:38 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:46:17 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 402.02178049087524 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 04:47:21 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:48:48 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 04:50:04 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 04:51:21 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:52:59 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 402.27314019203186 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 04:54:04 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 04:55:32 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 04:56:48 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 04:58:04 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 04:59:41 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 402.39965081214905 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 05:00:46 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 05:02:13 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 05:03:29 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 05:04:45 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 05:06:23 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 402.47109055519104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 05:07:28 2024]  Iteration number: 0 with current cost as 0.24635463641334676 and parameters 
[-2.38713599  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Mar 28 05:08:55 2024]  Iteration number: 0 with current cost as 0.3105081369954332 and parameters 
[-2.2639537   2.23743462 -2.12427964 -0.11653103  0.55388706 -2.77010901
  3.06858495  2.18960145  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Thu Mar 28 05:10:11 2024]  Iteration number: 0 with current cost as 0.29175159370828485 and parameters 
[-2.30558333  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Mar 28 05:11:26 2024]  Iteration number: 0 with current cost as 0.27620315397723766 and parameters 
[-2.36307878  2.23743464 -2.12427959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Mar 28 05:13:05 2024]  Iteration number: 0 with current cost as 0.34489475908073264 and parameters 
[-2.2570233   2.23743456 -2.12427956 -0.11653103  0.553887   -2.77010905
  3.0685849   2.18960145  1.18551998 -1.06648316]. 
Training complete taking 401.48105096817017 seconds. 
Discarding model... 

Training complete taking 10073.90977549553 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 1.8676977157592773 seconds. 
Saved predicted values as M_ESU2_predicted_values.csv
Model scores: {'MSE_train': (6.417448714775892,), 'R2_train': 0.11883598226140268, 'MAE_train': 1.7623475439041427, 'MSE_test': 16.786480617855197, 'R2_test': -0.6734553026372863, 'MAE_test': 2.9410088287624054}. 
Saved model results as M_ESU2_results.json. 
