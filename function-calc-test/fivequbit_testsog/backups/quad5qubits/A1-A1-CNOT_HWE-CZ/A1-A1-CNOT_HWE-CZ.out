/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:44:20 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:44:30 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:45:53 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:47:20 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:49:03 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 15:52:43 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 631.1500449180603 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:55:01 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:56:23 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:57:56 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:59:40 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:03:15 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 632.639057636261 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:05:35 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:06:55 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:08:23 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:10:06 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:13:46 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 629.9118933677673 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:16:07 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:17:29 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:18:55 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:20:38 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:24:19 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 633.3663356304169 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:26:38 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:28:05 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:29:31 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:31:14 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:34:50 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 629.7260897159576 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:37:08 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:38:29 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:39:56 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:41:41 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:45:17 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 627.9912152290344 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:47:35 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:48:57 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:50:25 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:10 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:55:45 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 627.4670054912567 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:58:02 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:59:25 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:00:52 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:02:35 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:06:13 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 634.9017837047577 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:08:38 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:09:59 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:11:28 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:13:12 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:16:48 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 632.3796479701996 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:19:14 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:20:35 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:22:03 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:23:47 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:27:26 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 642.310337305069 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:29:52 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:31:17 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:32:46 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:34:32 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:38:07 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 638.9270679950714 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:40:30 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:41:53 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:43:20 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:45:02 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:48:42 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 630.2768108844757 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:51:01 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:52:23 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:53:50 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:55:33 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:59:13 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 630.3011219501495 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:01:31 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:02:55 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:04:22 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:06:04 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:09:38 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 626.2778332233429 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:11:57 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:13:22 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:15:00 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:16:47 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:20:24 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 643.7365822792053 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:22:42 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:24:04 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:25:33 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:27:17 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:30:54 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 630.4020712375641 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:33:13 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:34:34 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:36:03 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:37:49 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:41:28 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 633.1026849746704 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:43:46 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:45:09 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:46:39 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:48:22 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:52:08 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 642.5198838710785 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:54:27 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:55:49 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:57:17 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:59:00 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 19:02:36 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 626.9438338279724 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:04:54 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:06:18 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:07:45 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:09:28 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 19:13:05 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 628.2586646080017 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:15:24 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:16:46 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:18:11 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:19:54 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 19:23:30 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 624.5320360660553 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:25:48 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:27:09 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:28:36 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:30:19 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 19:34:02 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 632.4762148857117 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:36:21 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:37:42 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:39:09 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:40:52 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 19:44:28 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 624.6128835678101 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:46:44 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:48:14 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:49:41 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:51:25 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 19:55:00 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 635.3246881961823 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:57:21 2024]  Iteration number: 0 with current cost as 0.3881787738388982 and parameters 
[-3.28194549  2.06902291 -1.37947896 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960146  1.18552    -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:58:42 2024]  Iteration number: 0 with current cost as 0.39852675868899423 and parameters 
[-3.24839622  2.10036013 -1.45834588 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:00:11 2024]  Iteration number: 0 with current cost as 0.3704445270690664 and parameters 
[-3.31305236  2.05705323 -1.31977215 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648307  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:01:54 2024]  Iteration number: 0 with current cost as 0.30574717441088867 and parameters 
[-3.31221179  2.04032453 -1.30799373 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 20:05:36 2024]  Iteration number: 0 with current cost as 0.3450711934197178 and parameters 
[-3.24026447  2.0849643  -1.45940558 -0.11653103  0.55388709 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 633.5906846523285 seconds. 
Discarding model... 

Training complete taking 15803.128292798996 total seconds. 
Now scoring model... 
Scoring complete taking 0.7890806198120117 seconds. 
Saved predicted values as A1-A1-CNOT_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (3.461925370341684,), 'R2_train': 0.524651586008352, 'MAE_train': 1.2525552479039082, 'MSE_test': 1.8176306443246115, 'R2_test': 0.8187992045964851, 'MAE_test': 1.1381704635147476}. 
Saved model results as A1-A1-CNOT_HWE-CZ_results.json. 
