/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:46:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:46:40 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:47:42 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:49:57 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:51:01 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 15:51:54 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 392.7663631439209 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:53:14 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:54:19 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:56:31 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:57:33 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 15:58:26 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 392.37983894348145 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 15:59:45 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:00:47 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:03:00 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:04:02 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:04:55 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 388.4999670982361 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:06:15 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:07:17 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:09:29 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:10:33 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:11:26 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 391.4728834629059 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:12:45 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:13:48 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:16:02 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:17:03 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:17:57 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 390.38961577415466 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:19:17 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:20:19 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:22:31 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:23:36 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:24:29 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 392.8113181591034 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:25:49 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:26:55 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:29:08 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:30:10 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:31:15 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 406.37428736686707 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:32:35 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:33:37 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:35:50 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:36:52 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:37:45 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 389.2903850078583 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:39:04 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:40:06 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:42:20 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:43:26 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:44:19 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 394.5977783203125 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:45:39 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:46:41 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:49:02 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:50:04 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:51:00 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 399.9150457382202 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:52:20 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:53:23 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:55:38 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:56:40 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:57:33 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 393.83049869537354 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:58:53 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:59:55 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:02:10 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:03:13 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:04:06 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 398.09904980659485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:31 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:06:33 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:08:46 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:09:47 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:10:40 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 388.9869282245636 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:12:00 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:13:08 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:15:23 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:16:25 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:17:19 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 399.0533821582794 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:18:39 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:19:41 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:22:18 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:23:20 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:24:12 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 413.35631489753723 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:25:32 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:26:42 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:28:55 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:30:08 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:31:02 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 409.60648798942566 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:32:23 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:33:25 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:35:39 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:36:41 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:37:34 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 391.7082533836365 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:38:53 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:39:55 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:42:08 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:43:12 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:44:05 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 391.0698342323303 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:45:26 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:46:27 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:48:39 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:49:40 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:50:33 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 387.7613127231598 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:51:56 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:52:58 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:55:10 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:56:12 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:57:05 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 390.8231158256531 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:58:24 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:59:40 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:01:52 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:02:55 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:03:50 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 405.72140192985535 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:05:09 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:06:11 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:08:27 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:09:28 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:10:22 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 393.211580991745 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:11:42 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:12:43 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:14:55 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:15:56 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:16:49 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 386.7594940662384 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:18:09 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:19:11 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:21:27 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:22:28 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:23:25 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 395.30274629592896 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:24:44 2024]  Iteration number: 0 with current cost as 0.6160921240895166 and parameters 
[-3.41560039  2.18628589 -1.25542252 -0.11653101  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:25:45 2024]  Iteration number: 0 with current cost as 0.6201640740945981 and parameters 
[-3.39296638  2.20728166 -1.30851545 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:27:57 2024]  Iteration number: 0 with current cost as 0.5790970715798079 and parameters 
[-3.40292011  2.15397422 -1.25055335 -0.11653101  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.06648308  0.60271509  1.14432445
  1.310299   -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:28:59 2024]  Iteration number: 0 with current cost as 0.47909845186621874 and parameters 
[-3.42082983  2.2001097  -1.25782186 -0.11653101  0.55388707 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:29:57 2024]  Iteration number: 0 with current cost as 0.4949153653905289 and parameters 
[-3.42968234  2.22425085 -1.26246463 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 393.6248664855957 seconds. 
Discarding model... 

Training complete taking 9877.414014816284 total seconds. 
Now scoring model... 
Scoring complete taking 0.8202681541442871 seconds. 
Saved predicted values as A2_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (2.100273548133061,), 'R2_train': 0.7116166314252101, 'MAE_train': 1.2135499573366129, 'MSE_test': 3.106194356367432, 'R2_test': 0.6903414399349392, 'MAE_test': 1.5184073053217386}. 
Saved model results as A2_HWE-CZ_results.json. 
