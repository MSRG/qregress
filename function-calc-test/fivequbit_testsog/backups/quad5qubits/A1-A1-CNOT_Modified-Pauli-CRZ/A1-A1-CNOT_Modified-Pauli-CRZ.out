/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:58 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:31 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:03:37 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:04:41 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:05:38 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:06:36 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 302.96876215934753 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:07:33 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:39 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:09:43 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:10:41 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:11:39 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 302.0858974456787 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:12:37 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:13:41 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:14:46 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:15:44 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:16:43 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 305.7034945487976 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:17:40 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:18:45 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:19:49 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:20:48 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:22:09 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 324.83510994911194 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:23:07 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:24:13 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:25:18 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:26:17 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:27:15 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 307.7658336162567 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:28:13 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:29:17 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:30:23 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:31:21 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:32:19 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 304.70020389556885 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:33:18 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:34:23 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:35:27 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:36:28 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:37:34 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 338.24055886268616 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:39:02 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:40:08 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:41:11 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:42:10 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:43:10 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 310.7803704738617 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:44:08 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:45:13 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:46:17 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:47:15 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:48:13 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 308.8444855213165 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:49:16 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:50:20 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:51:28 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:50 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:53:48 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 330.0080907344818 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:54:46 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:55:50 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:56:54 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:57:52 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:58:50 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 302.32383465766907 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:59:48 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:00:52 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:01:56 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:02:55 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:03:53 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 303.0172469615936 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:04:52 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:05:56 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:07:01 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:07:59 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:08:57 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 303.823787689209 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:09:55 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:10:59 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:12:04 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:13:02 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:01 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 303.5412435531616 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:14:58 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:16:01 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:17:05 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:18:03 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:19:02 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 301.643794298172 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:20:02 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:21:06 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:22:12 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:23:11 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:24:08 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 306.0561318397522 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:25:06 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:26:12 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:27:16 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:28:14 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:29:12 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 302.32525610923767 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:30:10 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:31:15 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:32:19 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:33:20 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:34:18 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 307.52281618118286 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:35:16 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:36:28 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:37:32 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:38:30 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:39:28 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 310.4865927696228 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:40:26 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:41:30 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:42:35 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:43:38 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:44:36 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 313.6846168041229 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:45:42 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:46:46 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:47:50 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:48:49 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:49:47 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 305.04886627197266 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:50:45 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:51:50 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:52:54 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:53:52 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:54:51 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 303.84754276275635 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:55:49 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:56:53 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:57:58 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:58:57 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:59:55 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 304.0055320262909 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:00:53 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:01:57 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:03:02 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:04:01 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:04:59 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 303.5023684501648 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:05:56 2024]  Iteration number: 0 with current cost as 0.23376291548458725 and parameters 
[-2.36042348  2.23743464 -2.12427957 -0.11653103  0.55388711 -2.770109
  3.06858498  2.18960145  1.18552002 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:07:01 2024]  Iteration number: 0 with current cost as 0.22056725570340768 and parameters 
[-2.34333037  2.23743467 -2.12427957 -0.11653099  0.55388711 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648308  0.6027151   1.14432449
  1.31029902 -1.87354673  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:08:05 2024]  Iteration number: 0 with current cost as 0.21564270870859914 and parameters 
[-2.42077861  2.23743465 -2.12427959 -0.11653101  0.5538871  -2.77010897
  3.068585    2.18960147  1.18552003 -1.06648307  0.60271512  1.14432447
  1.31029902 -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:09:03 2024]  Iteration number: 0 with current cost as 0.15928698012783593 and parameters 
[-2.48335819  2.23743464 -2.1242796  -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960143  1.18552002 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:10:04 2024]  Iteration number: 0 with current cost as 0.1686364099479361 and parameters 
[-2.43056608  2.2374347  -2.12427955 -0.11653098  0.55388712 -2.77010897
  3.06858498  2.18960149  1.18552005 -1.06648304  0.60271512  1.14432451
  1.31029903 -1.87354676  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 304.9586260318756 seconds. 
Discarding model... 

Training complete taking 7711.722969055176 total seconds. 
Now scoring model... 
Scoring complete taking 0.9494574069976807 seconds. 
Saved predicted values as A1-A1-CNOT_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (4.391806225648303,), 'R2_train': 0.396971944627876, 'MAE_train': 1.3645818777400547, 'MSE_test': 3.5927032129942207, 'R2_test': 0.6418410517692319, 'MAE_test': 1.5701882507973342}. 
Saved model results as A1-A1-CNOT_Modified-Pauli-CRZ_results.json. 
