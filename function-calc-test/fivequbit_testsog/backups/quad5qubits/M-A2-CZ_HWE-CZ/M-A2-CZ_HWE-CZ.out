/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:46:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:46:46 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:48:12 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:49:37 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:50:55 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:52:21 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 412.0179841518402 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:53:42 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:55:07 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:56:32 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:57:48 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:59:14 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 411.9388976097107 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:00:32 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:01:57 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:03:21 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:04:38 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:06:03 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 409.34647941589355 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:07:20 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:44 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:10:09 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:11:28 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:12:54 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 411.6407642364502 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:14:11 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:15:36 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:17:01 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:18:18 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:19:43 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 409.4173471927643 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:02 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:22:28 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:23:54 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:25:10 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:26:35 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 411.05025577545166 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:27:53 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:29:17 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:30:43 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:01 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:33:31 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 418.9403033256531 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:34:50 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:36:16 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:37:43 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:39:02 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:40:27 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 412.91259717941284 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:41:43 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:43:09 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:34 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:45:51 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:47:16 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 409.4286913871765 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:48:34 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:49:59 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:51:25 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:42 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:54:08 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 411.4665319919586 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:55:26 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:56:49 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:58:14 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:59:33 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:01:03 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 414.74265718460083 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:02:19 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:03:43 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:05:08 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:06:26 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:07:49 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 405.8384735584259 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:09:06 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:10:31 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:11:58 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:13:13 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:38 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 409.232923746109 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:15:55 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:17:23 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:18:47 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:20:06 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:21:31 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 415.6701695919037 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:22:49 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:24:14 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:25:44 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:27:06 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:28:31 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 417.69249057769775 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:29:47 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:31:14 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:32:39 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:33:56 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:35:20 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 408.51763558387756 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:36:37 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:38:02 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:39:27 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:40:43 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:42:08 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 408.4093403816223 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:43:24 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:44:51 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:46:16 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:47:33 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:48:56 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 418.2452657222748 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:50:23 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:51:47 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:53:13 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:54:31 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:55:55 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 407.7367765903473 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:57:12 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:58:38 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:00:03 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:01:19 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:02:44 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 410.652352809906 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:04:03 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:05:25 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:06:50 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:08:08 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:09:33 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 407.66973900794983 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:10:48 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:12:13 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:13:39 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:14:55 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:16:20 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 407.08378648757935 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:17:37 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:19:02 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:20:26 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:21:44 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:23:09 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 409.79865765571594 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:24:25 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:25:50 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:27:15 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:28:33 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:29:57 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 409.2001144886017 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:31:15 2024]  Iteration number: 0 with current cost as 0.2350496501965947 and parameters 
[-3.36486998  2.06547971 -1.24258975 -0.11653104  0.55388707 -2.77010899
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:32:40 2024]  Iteration number: 0 with current cost as 0.24495526806496842 and parameters 
[-3.3417736   2.06728734 -1.28136115 -0.11653104  0.55388705 -2.770109
  3.06858497  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:34:06 2024]  Iteration number: 0 with current cost as 0.23453394305434855 and parameters 
[-3.37041678  2.07769668 -1.24321392 -0.11653103  0.55388707 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:35:22 2024]  Iteration number: 0 with current cost as 0.20931661563805382 and parameters 
[-3.37254218  2.08243437 -1.24349743 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960147  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:36:47 2024]  Iteration number: 0 with current cost as 0.2125629535039979 and parameters 
[-3.362094    2.09326682 -1.2689016  -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 408.7875487804413 seconds. 
Discarding model... 

Training complete taking 10277.439188957214 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 1.2726020812988281 seconds. 
Saved predicted values as M-A2-CZ_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (2.3370177528348015,), 'R2_train': 0.6791098699592404, 'MAE_train': 1.073301857187063, 'MSE_test': 7.618707269197635, 'R2_test': 0.2404860572549824, 'MAE_test': 1.856193624622763}. 
Saved model results as M-A2-CZ_HWE-CZ_results.json. 
