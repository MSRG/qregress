/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:45 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:59 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:38:50 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:39:45 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:40:50 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:41:39 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 279.9918692111969 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:42:40 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:43:29 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:44:20 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:45:24 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:46:11 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 272.06154012680054 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:47:12 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:48:02 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:48:53 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:49:57 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:50:44 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 272.9424021244049 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:51:45 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:52:43 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:53:35 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:54:40 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:55:25 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 281.6036961078644 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:56:25 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:57:17 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:58:08 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:59:12 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:59:58 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 273.1249432563782 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:00:58 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:01:49 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:02:44 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:03:48 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:04:34 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 276.6054587364197 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:05:36 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:06:26 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:07:18 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:08:22 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:09:09 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 273.0225098133087 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:10:09 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:10:59 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:11:51 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:12:57 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:13:43 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 273.4979853630066 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:14:43 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:15:33 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:16:24 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:17:28 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:18:15 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 271.9518156051636 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:19:17 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:20:08 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:20:58 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:22:02 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:22:51 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 277.7971258163452 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:23:51 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:24:42 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:25:32 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:26:37 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:27:28 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 277.2504937648773 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:28:28 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:29:20 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:30:12 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:31:16 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:32:04 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 275.2932040691376 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:33:04 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:33:54 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:34:46 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:35:50 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:36:40 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 275.48542881011963 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:37:40 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:38:30 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:39:25 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:40:29 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:41:16 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 275.483517408371 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:42:16 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:43:06 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:43:59 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:45:04 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:45:51 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 275.83974981307983 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:46:50 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:47:41 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:48:31 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:49:35 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:50:22 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 272.04316449165344 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:51:22 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:52:14 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:53:04 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:54:10 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:54:55 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 273.24557065963745 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:55:56 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:56:59 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:57:51 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:58:55 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:59:43 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 286.6523711681366 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:00:43 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:01:38 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:02:28 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:03:32 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:04:19 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 276.67136335372925 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:05:20 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:06:12 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:07:16 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:08:20 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:09:05 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 288.78034830093384 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:10:09 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:10:59 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:11:50 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:12:55 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:13:45 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 276.2218749523163 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:14:45 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:15:35 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:16:26 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:17:30 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:18:18 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 272.33864665031433 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:19:18 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:20:07 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:21:02 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:22:15 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:23:01 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 284.7901825904846 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:24:01 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:24:52 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:25:43 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:26:48 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:27:33 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 272.000385761261 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:28:33 2024]  Iteration number: 0 with current cost as 0.3155073504516818 and parameters 
[-2.34670308  0.58910186 -1.72971507 -0.11653106  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18552006 -1.06648316  0.60271518  1.14432453
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:29:24 2024]  Iteration number: 0 with current cost as 0.22375739711616927 and parameters 
[-2.1724805   0.56999894 -1.99646776 -0.1165311   0.55388708 -2.77010897
  3.06858506  2.18960153  1.18552006 -1.06648308  0.60271518  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:30:17 2024]  Iteration number: 0 with current cost as 0.2433177856626284 and parameters 
[-2.4216477   0.88402913 -1.8401338  -0.11653108  0.55388708 -2.77010908
  3.06858493  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:31:25 2024]  Iteration number: 0 with current cost as 0.13589812266738793 and parameters 
[-2.08969963  0.75251358 -2.27367942 -0.11653106  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18552002 -1.06648312  0.60271514  1.14432445
  1.31029899 -1.87354673  0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:32:13 2024]  Iteration number: 0 with current cost as 0.2916127740002451 and parameters 
[-2.51625179  1.03477929 -1.80552957 -0.11653103  0.55388713 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.60271516  1.14432451
  1.31029899 -1.87354675  0.7296508 ]. 
Training complete taking 278.36824893951416 seconds. 
Discarding model... 

Training complete taking 6913.065222263336 total seconds. 
Now scoring model... 
Scoring complete taking 0.8371820449829102 seconds. 
Saved predicted values as M_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (0.1109682368035289,), 'R2_train': 0.7790361166235836, 'MAE_train': 0.27626336688581843, 'MSE_test': 0.15384662900204138, 'R2_test': 0.7130814291774796, 'MAE_test': 0.3395734892036046}. 
Saved model results as M_HWE-CZ_results.json. 
