/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:45 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:00 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:39:00 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:40:04 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:41:02 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:42:06 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 310.75265741348267 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:43:11 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:44:09 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:45:13 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:46:11 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:47:20 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 317.61061429977417 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:48:26 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:49:31 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:50:34 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:51:33 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:52:36 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 312.6692850589752 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:53:40 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:54:45 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:55:49 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:56:47 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:57:51 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 318.6096975803375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:58:57 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:59:55 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:01:14 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:02:12 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:03:16 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 322.83968591690063 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:04:20 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:05:18 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:06:22 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:07:20 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:08:24 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 307.9979798793793 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:09:29 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:10:26 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:11:39 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:12:37 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:13:48 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 325.2402033805847 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:14:53 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:15:52 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:16:56 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:17:56 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:19:00 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 309.00946021080017 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:20:04 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:21:03 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:22:07 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:23:05 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:24:11 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 311.7091112136841 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:25:14 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:26:11 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:27:15 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:28:12 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:29:16 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 305.08876395225525 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:30:19 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:31:16 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:32:22 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:33:22 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:34:25 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 309.9874188899994 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:35:29 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:36:26 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:37:29 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:38:27 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:39:32 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 304.80343556404114 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:40:35 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:41:33 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:42:36 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:43:34 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:44:38 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 306.50042819976807 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:45:42 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:46:39 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:47:44 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:48:46 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:49:49 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 311.99518036842346 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:50:52 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:51:50 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:52:55 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:53:54 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:55:00 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 310.85730266571045 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:56:05 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:57:01 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:58:06 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:59:04 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:00:12 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 312.15310645103455 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:01:15 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:02:13 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:03:17 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:04:15 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:05:19 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 306.98554825782776 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:06:22 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:07:19 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:08:25 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:09:23 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:10:27 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 308.6845316886902 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:11:31 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:12:28 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:13:38 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:14:35 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:15:49 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 333.5231716632843 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:17:07 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:18:04 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:19:08 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:20:05 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:21:09 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 306.50226163864136 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:22:12 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:23:12 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:24:16 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:25:13 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:26:16 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 309.0252957344055 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:27:20 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:28:18 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:29:22 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:30:19 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:31:23 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 306.3883445262909 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:32:31 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:33:35 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:34:44 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:35:49 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:36:53 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 330.6785409450531 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:37:57 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:38:59 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:40:06 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:41:03 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:42:10 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 316.68953585624695 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:43:15 2024]  Iteration number: 0 with current cost as 0.22498075400034673 and parameters 
[-3.03720212  2.08902659 -1.79099111 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648309  0.6027151   1.14432446
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:44:16 2024]  Iteration number: 0 with current cost as 0.22956873585784077 and parameters 
[-3.02367881  2.08796647 -1.81202861 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:45:19 2024]  Iteration number: 0 with current cost as 0.2196925714256832 and parameters 
[-3.02103457  2.07541486 -1.80644756 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:46:20 2024]  Iteration number: 0 with current cost as 0.2236396284584556 and parameters 
[-3.02942837  2.10766681 -1.81820196 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:47:24 2024]  Iteration number: 0 with current cost as 0.22792756371274625 and parameters 
[-3.02747236  2.08917834 -1.80684538 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 313.6710875034332 seconds. 
Discarding model... 

Training complete taking 7829.974575281143 total seconds. 
Now scoring model... 
Scoring complete taking 2.6430561542510986 seconds. 
Saved predicted values as M-A2-CNOT_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (0.316453734478764,), 'R2_train': 0.36986611580392903, 'MAE_train': 0.4829825761042129, 'MSE_test': 0.36655441638065117, 'R2_test': 0.31638886104404684, 'MAE_test': 0.5287969075435596}. 
Saved model results as M-A2-CNOT_HWE-CZ_results.json. 
