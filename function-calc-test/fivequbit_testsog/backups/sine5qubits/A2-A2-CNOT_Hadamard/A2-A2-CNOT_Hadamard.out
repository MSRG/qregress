/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:45:43 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:45:49 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:46:02 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:46:14 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:46:27 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:46:38 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.094690799713135 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:46:51 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:47:13 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:47:26 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:47:38 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:47:49 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 72.37380909919739 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:48:02 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:48:14 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:48:27 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:48:39 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:48:51 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.75375199317932 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:49:03 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:49:15 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:49:28 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:49:39 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:49:52 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.56142783164978 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:50:04 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:50:15 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:50:29 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:50:40 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:50:53 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.21354126930237 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:51:05 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:51:17 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:51:55 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:52:06 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:52:18 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 86.52179956436157 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:31 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:52:43 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:52:56 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:53:08 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:53:19 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.711074352264404 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:53:33 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:53:45 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:53:58 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:54:09 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:54:23 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.56274485588074 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:54:35 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:54:46 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:54:59 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:55:11 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:55:24 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.83703351020813 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:55:36 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:55:47 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:56:00 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:56:12 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:56:25 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.04421854019165 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:56:37 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:56:48 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:57:01 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:57:13 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:57:26 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.98383402824402 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:57:38 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:57:49 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:58:02 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:58:14 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:58:27 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.91231679916382 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:58:39 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:58:50 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 21:59:03 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 21:59:15 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 21:59:28 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.90610337257385 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:59:39 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 21:59:53 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:00:04 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:00:16 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:00:30 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 62.563270807266235 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:00:42 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 22:00:55 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:01:07 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:01:18 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:01:31 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.90958619117737 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:01:43 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 22:01:57 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:02:09 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:02:21 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:02:34 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.04192018508911 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:02:46 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 22:02:59 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:03:11 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:03:24 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:03:35 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.13023376464844 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:03:47 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 22:04:00 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:04:12 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:04:25 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:04:37 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.332854986190796 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:04:48 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 22:05:01 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:05:13 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:05:26 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:05:38 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.366214752197266 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:05:50 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 22:06:03 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:06:15 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:06:29 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:06:41 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 62.512585401535034 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:06:54 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 22:07:05 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:07:17 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:07:30 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:07:42 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.53048253059387 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:07:55 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 22:08:07 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:08:19 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:08:32 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:08:44 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.6212899684906 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:08:59 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 22:09:11 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:09:24 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:09:35 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:09:47 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.62023305892944 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:10:00 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 22:10:12 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:10:25 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:10:36 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:10:48 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 62.25701928138733 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:11:02 2024]  Iteration number: 0 with current cost as 0.24874871622218664 and parameters 
[-2.80271999  2.23743462 -2.12427964 -0.11653105  0.55388706]. 
Working on 0.4 fold... 
[Thu Apr  4 22:11:14 2024]  Iteration number: 0 with current cost as 0.24672815298158662 and parameters 
[-2.81973271  2.23743464 -2.12427963 -0.11653104  0.55388709]. 
Working on 0.6 fold... 
[Thu Apr  4 22:11:27 2024]  Iteration number: 0 with current cost as 0.23993500999949122 and parameters 
[-2.85348878  2.23743464 -2.12427963 -0.11653103  0.55388709]. 
Working on 0.8 fold... 
[Thu Apr  4 22:11:39 2024]  Iteration number: 0 with current cost as 0.24297592245251926 and parameters 
[-2.75408367  2.23743463 -2.12427964 -0.11653103  0.55388707]. 
Working on 1.0 fold... 
[Thu Apr  4 22:11:50 2024]  Iteration number: 0 with current cost as 0.2545063957369744 and parameters 
[-2.81117483  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.17650580406189 seconds. 
Discarding model... 

Training complete taking 1574.5393979549408 total seconds. 
Now scoring model... 
Scoring complete taking 0.9487612247467041 seconds. 
Saved predicted values as A2-A2-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (0.4137383728014704,), 'R2_train': 0.1761494983657781, 'MAE_train': 0.54357358991704, 'MSE_test': 0.5402759192660672, 'R2_test': -0.007595652964138111, 'MAE_test': 0.6353730136586325}. 
Saved model results as A2-A2-CNOT_Hadamard_results.json. 
