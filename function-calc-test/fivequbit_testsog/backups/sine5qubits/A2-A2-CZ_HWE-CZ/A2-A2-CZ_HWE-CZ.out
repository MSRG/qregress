/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:31 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:48 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:40:16 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 21:42:34 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:44:45 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 21:47:03 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 703.8142952919006 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:49:31 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:51:56 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 21:54:09 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:56:20 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 21:58:33 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 689.7619450092316 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:01:00 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:03:26 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:05:40 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:07:51 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 22:10:04 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 691.1479694843292 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:12:31 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:14:58 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:17:13 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:19:25 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 22:21:37 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 694.6847920417786 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:24:06 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:26:33 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:28:45 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:30:58 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 22:33:11 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 692.0037410259247 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:35:38 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:38:07 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:40:19 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:42:30 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 22:44:43 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 692.6297218799591 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:47:11 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:49:38 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 22:51:50 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:54:04 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 22:56:18 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 695.5157556533813 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:58:46 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:01:18 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:03:31 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:05:44 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 23:07:56 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 700.6898427009583 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:10:26 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:12:53 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:15:10 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:17:22 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 23:19:36 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 706.0019016265869 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:22:13 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:24:41 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:26:53 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:29:07 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 23:31:19 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 693.372230052948 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:33:46 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:36:14 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:38:26 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:40:40 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 23:42:52 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 693.1826639175415 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:45:19 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:47:47 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Thu Apr  4 23:49:59 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:52:13 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Thu Apr  4 23:54:25 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 692.7596275806427 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:56:51 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:59:17 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 00:01:27 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:03:40 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 00:05:50 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 684.1831171512604 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:08:16 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:10:41 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 00:12:52 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:15:03 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 00:17:15 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 686.0084154605865 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:19:42 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:22:06 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 00:24:19 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:26:30 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 00:28:45 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 688.724449634552 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:31:11 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:33:44 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 00:35:55 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:38:05 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 00:40:17 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 692.1187484264374 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:42:43 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:45:07 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 00:47:19 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:49:29 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 00:51:41 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 683.6421842575073 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:54:05 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:56:30 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 00:58:41 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:00:52 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 01:03:03 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 683.6000051498413 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:05:29 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:07:56 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 01:10:10 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:12:27 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 01:14:41 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 696.7236838340759 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:17:06 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:19:32 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 01:21:43 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:23:55 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 01:26:05 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 686.7540512084961 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:28:32 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:30:58 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 01:33:09 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:35:21 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 01:37:37 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 690.6086413860321 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:40:03 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:42:28 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 01:44:39 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:46:51 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 01:49:04 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 687.2396829128265 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:51:30 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:53:57 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 01:56:26 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:58:38 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 02:00:53 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 710.2397558689117 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:03:22 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:06:05 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 02:08:21 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:10:35 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 02:12:47 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 712.7243013381958 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:15:13 2024]  Iteration number: 0 with current cost as 0.43480559552076126 and parameters 
[-3.16244435  2.3139417  -1.76508396 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:17:39 2024]  Iteration number: 0 with current cost as 0.4255113865797603 and parameters 
[-3.17885331  2.33598445 -1.75585834 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Fri Apr  5 02:19:58 2024]  Iteration number: 0 with current cost as 0.40390872818776946 and parameters 
[-3.20168444  2.33872765 -1.72108988 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:22:15 2024]  Iteration number: 0 with current cost as 0.4422795209366236 and parameters 
[-3.13948253  2.32829461 -1.81349015 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Fri Apr  5 02:24:27 2024]  Iteration number: 0 with current cost as 0.4463079445239242 and parameters 
[-3.14686137  2.3181556  -1.7935943  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 697.7534739971161 seconds. 
Discarding model... 

Training complete taking 17345.887531995773 total seconds. 
Now scoring model... 
Scoring complete taking 1.0153555870056152 seconds. 
Saved predicted values as A2-A2-CZ_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (0.4602662086272731,), 'R2_train': 0.08350162375484482, 'MAE_train': 0.569982197429064, 'MSE_test': 0.4344822764984245, 'R2_test': 0.1897057827702615, 'MAE_test': 0.58699202432245}. 
Saved model results as A2-A2-CZ_HWE-CZ_results.json. 
