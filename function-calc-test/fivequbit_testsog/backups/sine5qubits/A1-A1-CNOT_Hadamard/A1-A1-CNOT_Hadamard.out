/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:45 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:53 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:38:16 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:38:33 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:38:49 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:39:05 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 90.81293630599976 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:39:24 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:39:47 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:40:04 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:40:19 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:40:36 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 90.51251745223999 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:40:54 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:41:17 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:41:39 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:41:54 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:42:11 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 94.93546915054321 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:42:30 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:42:53 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:43:09 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:43:25 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:43:42 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 91.12728953361511 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:44:00 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:44:24 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:44:41 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:44:56 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:45:13 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 96.76756501197815 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:45:39 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:46:00 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:46:34 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:46:52 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:47:10 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 111.27448916435242 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:47:28 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:47:52 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:48:09 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:48:24 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:48:42 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 93.68292045593262 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:49:05 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:49:26 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:49:43 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:49:58 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:50:15 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 91.18135261535645 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:50:35 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:50:56 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:51:13 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:51:29 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:51:47 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 92.06792783737183 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:20 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:52:43 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:52:59 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:53:18 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:53:35 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 108.37137484550476 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:53:54 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:54:17 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:54:32 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:54:49 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:55:06 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 90.80031657218933 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:55:24 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:55:47 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:56:04 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:56:20 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:56:37 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 96.31106805801392 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:57:07 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:57:29 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:57:46 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:58:02 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:58:18 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 96.15760540962219 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:58:39 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:59:00 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:59:17 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:59:32 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:59:49 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 90.86027407646179 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:00:09 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:00:31 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:00:48 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:01:05 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:01:20 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 91.19153165817261 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:01:41 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:02:04 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:02:20 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:02:37 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:02:52 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 93.89089798927307 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:03:13 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:03:36 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:03:52 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:04:09 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:04:24 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 91.22823429107666 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:04:44 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:05:07 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:05:22 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:05:42 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:05:58 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 93.76211905479431 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:06:18 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:06:41 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:06:56 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:07:13 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:07:28 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 90.53741598129272 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:07:48 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:08:12 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:08:27 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:08:44 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:09:08 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 97.72050547599792 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:09:26 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:09:49 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:10:06 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:10:21 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:10:38 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 90.65389585494995 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:10:57 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:11:20 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:11:38 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:11:53 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:12:10 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 92.28601264953613 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:12:29 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:12:52 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:13:10 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:13:26 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:13:43 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 91.87921595573425 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:14:01 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:14:24 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:14:41 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:14:56 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:15:13 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 91.03478932380676 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:15:32 2024]  Iteration number: 0 with current cost as 0.34530961988020836 and parameters 
[ 0.20076835  2.23743464 -2.124279   -0.11653071  0.5538874 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:15:55 2024]  Iteration number: 0 with current cost as 0.3052304686339816 and parameters 
[-1.74864834  2.23743451 -2.12427951 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:16:12 2024]  Iteration number: 0 with current cost as 0.30605647403796593 and parameters 
[-1.8347675   2.23743451 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:16:28 2024]  Iteration number: 0 with current cost as 0.28205643888792103 and parameters 
[ 1.06850593  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:16:45 2024]  Iteration number: 0 with current cost as 0.36427018829657964 and parameters 
[-0.08412707  2.23743432 -2.12427932 -0.11653103  0.55388708]. 
Training complete taking 91.61426877975464 seconds. 
Discarding model... 

Training complete taking 2350.6632492542267 total seconds. 
Now scoring model... 
Scoring complete taking 0.8061909675598145 seconds. 
Saved predicted values as A1-A1-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (0.5019386280025916,), 'R2_train': 0.0005220263483897147, 'MAE_train': 0.6188856884077225, 'MSE_test': 0.5681003024397053, 'R2_test': -0.059487152348843386, 'MAE_test': 0.6783910571826182}. 
Saved model results as A1-A1-CNOT_Hadamard_results.json. 
