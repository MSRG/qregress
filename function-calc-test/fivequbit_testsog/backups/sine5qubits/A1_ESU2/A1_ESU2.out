/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:03:29 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:04:15 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:05:30 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:06:55 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:07:58 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 21:09:31 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 404.9493851661682 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:10:56 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:12:11 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:13:37 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:14:43 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 21:16:19 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 406.5315887928009 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:17:41 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:18:54 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:20:18 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:21:21 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 21:22:57 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 398.23534893989563 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:24:22 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:25:36 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:27:01 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:28:03 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 21:29:36 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 399.6259572505951 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:31:01 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:32:18 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:33:45 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:34:50 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 21:36:27 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 411.2714214324951 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:54 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:39:08 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:40:37 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:41:40 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 21:43:14 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 406.87524151802063 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:44:39 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:45:58 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:47:23 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:48:26 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 21:50:00 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 407.2803244590759 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:51:32 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:52:49 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:54:18 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:55:21 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 21:56:56 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 416.83952927589417 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:58:24 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:59:38 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:01:05 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:02:08 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:03:45 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 409.35912895202637 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:05:13 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:06:31 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:08:00 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:09:05 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:10:41 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 413.65716338157654 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:12:05 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:13:22 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:14:51 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:15:58 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:17:41 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 423.96059584617615 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:19:10 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:20:27 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:21:52 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:22:56 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:24:31 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 405.5624575614929 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:25:56 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:27:11 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:28:36 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:29:41 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:31:15 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 405.09992575645447 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:32:41 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:33:56 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:35:24 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:36:26 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:38:02 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 406.52231884002686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:39:27 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:40:42 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:42:13 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:43:17 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:44:53 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 411.2971603870392 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:46:19 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:47:37 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:49:03 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:50:07 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:51:44 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 412.7583086490631 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:53:10 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:54:26 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:55:52 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:56:58 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:58:38 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 411.2465353012085 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:00:04 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:01:19 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:02:48 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:03:52 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:05:28 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 408.5487582683563 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:06:50 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:08:11 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:09:39 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:10:43 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:12:17 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 410.771865606308 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:13:40 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:14:52 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:16:14 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:17:19 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:18:54 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 397.9017667770386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:20:18 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:21:32 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:22:55 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:23:59 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:25:31 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 395.1431052684784 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:26:54 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:28:08 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:29:30 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:30:32 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:32:06 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 396.3005180358887 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:33:31 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:34:43 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:36:06 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:37:11 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:38:45 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 396.9877951145172 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:40:12 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:41:24 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:42:49 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:43:51 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:45:23 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 402.344957113266 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:46:50 2024]  Iteration number: 0 with current cost as 0.1172059294489016 and parameters 
[-1.69967122  2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:48:06 2024]  Iteration number: 0 with current cost as 0.16612895384362208 and parameters 
[-1.78553543  2.23743465 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:49:30 2024]  Iteration number: 0 with current cost as 0.12785433225876144 and parameters 
[-1.77376133  2.23743465 -2.12427962 -0.11653101  0.55388709 -2.77010899
  3.06858497  2.18960146  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:50:35 2024]  Iteration number: 0 with current cost as 0.3380680445651542 and parameters 
[-2.1892259   2.23743465 -2.12427962 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:52:09 2024]  Iteration number: 0 with current cost as 0.15145439025407192 and parameters 
[-1.74184616  2.23743465 -2.12427962 -0.11653103  0.55388709 -2.77010899
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 402.012079000473 seconds. 
Discarding model... 

Training complete taking 10161.08440709114 total seconds. 
Now scoring model... 
Scoring complete taking 1.719907522201538 seconds. 
Saved predicted values as A1_ESU2_predicted_values.csv
Model scores: {'MSE_train': (0.22042188848936806,), 'R2_train': 0.5610881287768168, 'MAE_train': 0.38694633565212666, 'MSE_test': 0.20009929219056405, 'R2_test': 0.6268218334692746, 'MAE_test': 0.38457343388490617}. 
Saved model results as A1_ESU2_results.json. 
