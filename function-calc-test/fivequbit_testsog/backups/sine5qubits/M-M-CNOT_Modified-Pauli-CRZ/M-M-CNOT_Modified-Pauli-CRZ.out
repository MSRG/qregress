/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:26 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:24 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:39:36 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:40:58 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:42:44 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:44:06 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 457.07922625541687 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:46:00 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:47:13 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:48:35 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:50:20 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:51:42 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 456.5691349506378 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:53:37 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:54:49 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:56:12 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:58:13 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:59:34 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 483.53922414779663 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:01:41 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:02:55 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:04:16 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:06:05 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:07:27 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 460.28457736968994 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:09:20 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:10:34 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:11:56 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:13:43 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:15:05 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 460.75489497184753 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:17:01 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:18:14 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:19:35 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:21:22 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:22:44 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 457.74852108955383 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:24:39 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:25:53 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:27:15 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:29:02 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:30:23 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 458.4086740016937 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:32:17 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:33:32 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:34:57 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:36:46 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:38:09 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 466.869854927063 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:40:04 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:41:19 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:42:45 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:44:31 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:45:51 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 462.54600644111633 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:47:47 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:49:01 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:50:22 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:52:10 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:53:49 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 479.1743516921997 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:55:46 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:57:00 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:58:21 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:00:08 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:01:30 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 459.20146679878235 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:03:24 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:04:39 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:06:01 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:07:47 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:09:12 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 461.10716938972473 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:11:06 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:12:19 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:13:42 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:15:30 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:16:51 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 459.21394443511963 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:18:46 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:20:00 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:21:20 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:23:08 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:24:31 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 459.58195328712463 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:26:25 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:27:39 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:29:05 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:30:51 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:32:15 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 465.65617203712463 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:34:10 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:35:23 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:36:46 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:38:42 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:40:04 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 468.03447008132935 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:41:59 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:43:14 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:44:40 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:46:24 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:47:45 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 460.7277400493622 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:49:39 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:50:51 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:52:13 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:53:58 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:55:27 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 463.05427384376526 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:57:22 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:58:35 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:59:55 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:01:42 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:03:05 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 457.2926115989685 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:04:58 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:06:12 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:07:39 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:09:23 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:10:45 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 458.7461779117584 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:12:55 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:14:09 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:15:29 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:17:22 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:18:43 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 479.07302737236023 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:20:38 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:21:50 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:23:22 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:25:35 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:26:58 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 494.5782539844513 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:28:59 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:30:13 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:31:37 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:33:22 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:34:44 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 465.7203540802002 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:36:37 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:37:49 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:39:10 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:40:55 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:42:16 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 454.11137223243713 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:44:12 2024]  Iteration number: 0 with current cost as 0.24221702609725143 and parameters 
[ 1.36565597  2.23743447 -2.12427947 -0.11653119  0.55388692 -2.77010914
  3.06858466  2.18960129  1.18552031 -1.06648325  0.6027151   1.14432429
  1.31029915 -1.87354664  0.72965064  2.88578403 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:45:25 2024]  Iteration number: 0 with current cost as 0.3708304824455289 and parameters 
[11.25917721  2.237434   -2.12427964 -0.11653103  0.55388708 -2.77010961
  3.06858498  2.18960145  1.18552125 -1.06648372  0.6027151   1.14432445
  1.31029962 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:46:53 2024]  Iteration number: 0 with current cost as 0.37695502242163886 and parameters 
[11.00344079  2.23743337 -2.12427964 -0.11653166  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552125 -1.06648308  0.6027151   1.14432445
  1.31030025 -1.87354553  0.72965017  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:48:47 2024]  Iteration number: 0 with current cost as 0.24931148480363183 and parameters 
[ 1.31247515  2.23743464 -2.1242793  -0.11653103  0.55388725 -2.77010897
  3.06858498  2.18960145  1.18552032 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354647  0.72965047  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:50:11 2024]  Iteration number: 0 with current cost as 0.6176602182414705 and parameters 
[12.35305617  2.23743274 -2.12428027 -0.11653229  0.55388581 -2.77011024
  3.06858308  2.18959892  1.18551998 -1.06648498  0.6027132   1.14432318
  1.31029835 -1.8735468   0.72964827  2.88578356 -0.54534462 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 473.43177795410156 seconds. 
Discarding model... 

Training complete taking 11622.506368637085 total seconds. 
Now scoring model... 
Scoring complete taking 2.751715660095215 seconds. 
Saved predicted values as M-M-CNOT_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (0.4071508973283537,), 'R2_train': 0.18926671284188024, 'MAE_train': 0.5538781923664289, 'MSE_test': 0.41711845037859996, 'R2_test': 0.22208870988818175, 'MAE_test': 0.5713555088366133}. 
Saved model results as M-M-CNOT_Modified-Pauli-CRZ_results.json. 
