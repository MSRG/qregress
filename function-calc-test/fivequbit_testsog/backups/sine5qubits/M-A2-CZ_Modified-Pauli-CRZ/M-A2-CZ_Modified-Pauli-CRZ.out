/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:00:33 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:01:28 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:02:38 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:03:50 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:05:00 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:06:20 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 375.0022439956665 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:07:43 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:08:52 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:10:03 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:11:15 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:12:32 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 370.5025556087494 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:13:49 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:14:59 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:16:08 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:17:18 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:18:39 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 367.4861695766449 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:19:59 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:21:14 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:22:23 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:23:37 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:24:58 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 378.4629201889038 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:26:17 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:27:27 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:28:39 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:29:50 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:31:11 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 373.61714720726013 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:32:32 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:33:47 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:35:02 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:36:13 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:37:33 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 381.5563771724701 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:50 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:40:05 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:41:27 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:42:41 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:44:01 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 389.0401499271393 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:45:26 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:46:41 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:47:53 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:49:11 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:50:35 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 395.9033887386322 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:05 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:53:17 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:54:31 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:55:54 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:57:16 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 398.19219160079956 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:58:39 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:59:51 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:01:05 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:02:19 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:03:42 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 386.10590982437134 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:05:05 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:06:20 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:07:32 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:08:47 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:10:20 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 403.82716035842896 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:11:48 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:13:06 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:14:19 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:15:33 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:16:52 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 387.44809317588806 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:18:17 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:19:37 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:20:53 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:22:15 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:23:39 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 407.9693763256073 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:25:05 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:26:28 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:27:42 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:29:03 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:30:33 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 414.1599862575531 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:31:59 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:33:14 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:34:29 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:35:42 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:37:13 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 399.68704414367676 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:38:34 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:39:54 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:41:07 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:42:37 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:44:06 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 413.7337746620178 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:45:29 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:46:47 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:47:59 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:49:13 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:50:40 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 391.22250866889954 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:52:06 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:53:30 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:54:46 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:55:58 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:57:22 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 402.30906796455383 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:58:42 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:59:54 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:01:05 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:02:24 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:03:59 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 401.3528492450714 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:05:27 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:06:40 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:07:56 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:09:11 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:10:37 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 393.2579963207245 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:12:00 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:13:16 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:14:34 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:15:50 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:17:15 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 400.62260222435 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:18:42 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:20:00 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:21:19 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:22:39 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:24:16 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 418.31302881240845 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:25:39 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:26:51 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:28:05 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:29:23 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:30:53 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 405.16123485565186 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:32:24 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:33:43 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:35:04 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:36:29 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:37:57 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 418.4702754020691 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:39:26 2024]  Iteration number: 0 with current cost as 0.09346452408162162 and parameters 
[-4.66993293  2.2374345  -2.12427924 -0.11653089  0.55388721 -2.77010911
  3.06858485  2.18960145  1.18552012 -1.06648322  0.6027151   1.14432458
  1.31029899 -1.87354667  0.72965067  2.88578406 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:40:43 2024]  Iteration number: 0 with current cost as 0.10149399280281746 and parameters 
[-4.64449705  2.23743464 -2.12427939 -0.1165309   0.55388708 -2.7701091
  3.06858486  2.18960157  1.18552011 -1.06648321  0.60271523  1.14432445
  1.31029899 -1.87354656  0.72965068  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:42:01 2024]  Iteration number: 0 with current cost as 0.09775604805001191 and parameters 
[-4.65004244  2.23743464 -2.12427911 -0.11653103  0.55388734 -2.77010897
  3.06858498  2.18960158  1.18552012 -1.06648308  0.6027151   1.14432458
  1.31029899 -1.87354654  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:43:22 2024]  Iteration number: 0 with current cost as 0.09389773804524144 and parameters 
[-4.70877401  2.23743464 -2.1242794  -0.11653091  0.55388708 -2.77010921
  3.06858487  2.18960145  1.18551998 -1.06648332  0.6027151   1.14432445
  1.31029899 -1.87354668  0.72965057  2.88578408 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:44:53 2024]  Iteration number: 0 with current cost as 0.09418781504657975 and parameters 
[-4.69140471  2.23743464 -2.12427939 -0.1165309   0.5538872  -2.77010922
  3.06858486  2.18960157  1.18552011 -1.06648321  0.6027151   1.14432457
  1.31029911 -1.87354668  0.72965056  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 419.469375371933 seconds. 
Discarding model... 

Training complete taking 9892.874816179276 total seconds. 
Now scoring model... 
Scoring complete taking 1.3449597358703613 seconds. 
Saved predicted values as M-A2-CZ_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (0.16198587239935097,), 'R2_train': 0.6774479936916596, 'MAE_train': 0.34360586907385515, 'MSE_test': 0.1776540382583482, 'R2_test': 0.6686814453551773, 'MAE_test': 0.3788960990035136}. 
Saved model results as M-A2-CZ_Modified-Pauli-CRZ_results.json. 
