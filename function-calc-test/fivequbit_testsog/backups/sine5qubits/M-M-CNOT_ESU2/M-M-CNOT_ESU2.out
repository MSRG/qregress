/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 22:08:35 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:09:34 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Thu Apr  4 22:12:17 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 22:15:08 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 22:17:20 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Thu Apr  4 22:19:46 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 772.6880078315735 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:22:26 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Thu Apr  4 22:25:12 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 22:28:16 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 22:30:32 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Thu Apr  4 22:33:03 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 796.4008138179779 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:35:44 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Thu Apr  4 22:38:41 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 22:41:54 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 22:44:07 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Thu Apr  4 22:46:31 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 808.7750899791718 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:49:11 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Thu Apr  4 22:51:54 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 22:54:52 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 22:57:13 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Thu Apr  4 22:59:40 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 789.7709908485413 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:02:24 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Thu Apr  4 23:05:05 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 23:08:03 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 23:10:17 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Thu Apr  4 23:12:46 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 787.3099570274353 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:15:29 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Thu Apr  4 23:18:10 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 23:21:08 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 23:23:28 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Thu Apr  4 23:26:02 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 792.9248352050781 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:28:39 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Thu Apr  4 23:31:24 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 23:34:24 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 23:36:37 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Thu Apr  4 23:39:08 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 786.6531817913055 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:41:48 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Thu Apr  4 23:44:39 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Thu Apr  4 23:47:42 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 23:49:56 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Thu Apr  4 23:52:25 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 801.6614632606506 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:55:11 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Thu Apr  4 23:57:56 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 00:00:48 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 00:02:59 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 00:05:27 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 778.4293973445892 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:08:08 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 00:10:51 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 00:13:52 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 00:16:05 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 00:18:31 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 780.9266636371613 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:21:08 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 00:23:56 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 00:26:54 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 00:29:03 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 00:31:29 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 785.5290772914886 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:34:17 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 00:37:06 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 00:40:06 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 00:42:18 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 00:44:48 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 795.719215631485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:47:34 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 00:50:24 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 00:53:33 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 00:55:49 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 00:58:16 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 806.4278240203857 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:00:59 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 01:03:40 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 01:06:38 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 01:08:51 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 01:11:18 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 784.8721742630005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:14:01 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 01:16:47 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 01:20:01 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 01:22:24 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 01:24:53 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 822.6038026809692 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:27:47 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 01:30:37 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 01:33:39 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 01:35:59 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 01:38:31 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 807.972097158432 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:41:15 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 01:44:06 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 01:47:04 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 01:49:16 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 01:51:57 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 806.5647859573364 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:54:37 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 01:57:19 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 02:00:20 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 02:02:31 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 02:04:58 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 782.5961046218872 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:07:41 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 02:10:22 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 02:13:22 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 02:15:40 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 02:18:09 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 787.9148499965668 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:20:53 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 02:23:39 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 02:26:38 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 02:28:51 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 02:31:21 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 793.4841890335083 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:34:04 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 02:36:44 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 02:39:42 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 02:41:53 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 02:44:19 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 777.7835466861725 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:46:59 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 02:49:40 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 02:52:46 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 02:54:58 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 02:57:28 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 787.2404022216797 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:00:11 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 03:02:56 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 03:05:57 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 03:08:20 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 03:10:51 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 808.6419198513031 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:13:36 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 03:16:21 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 03:19:27 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 03:21:46 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 03:24:13 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 799.0693869590759 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 03:26:54 2024]  Iteration number: 0 with current cost as 0.6099345258566127 and parameters 
[-0.28881505  2.23743464 -2.12427947 -0.11653111  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18551998 -1.06648325]. 
Working on 0.4 fold... 
[Fri Apr  5 03:29:37 2024]  Iteration number: 0 with current cost as 0.26949898505571257 and parameters 
[ 1.28689816  2.23743479 -2.12427948 -0.11653118  0.55388692 -2.77010913
  3.06858514  2.18960161  1.18552014 -1.06648324]. 
Working on 0.6 fold... 
[Fri Apr  5 03:32:36 2024]  Iteration number: 0 with current cost as 0.2548164862726172 and parameters 
[ 1.29248318  2.23743447 -2.12427947 -0.11653119  0.55388691 -2.77010914
  3.06858498  2.18960129  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 03:34:55 2024]  Iteration number: 0 with current cost as 0.610260204230707 and parameters 
[-0.20824722  2.23743455 -2.12427964 -0.11653112  0.55388699 -2.77010906
  3.06858489  2.18960136  1.18551998 -1.06648326]. 
Working on 1.0 fold... 
[Fri Apr  5 03:37:29 2024]  Iteration number: 0 with current cost as 0.6226194522221654 and parameters 
[-0.18757299  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648317]. 
Training complete taking 794.0629675388336 seconds. 
Discarding model... 

Training complete taking 19836.02358531952 total seconds. 
Now scoring model... 
Scoring complete taking 2.2098541259765625 seconds. 
Saved predicted values as M-M-CNOT_ESU2_predicted_values.csv
Model scores: {'MSE_train': (0.5859626717613674,), 'R2_train': -0.16678962553268817, 'MAE_train': 0.663626422418067, 'MSE_test': 0.5709541530166312, 'R2_test': -0.06480948364842476, 'MAE_test': 0.6991903655073723}. 
Saved model results as M-M-CNOT_ESU2_results.json. 
