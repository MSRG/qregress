/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/gjones/scratch/sine5qubits/sine_train.bin... 
Successfully loaded /home/gjones/scratch/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /home/gjones/scratch/sine5qubits/sine_test.bin... 
Successfully loaded /home/gjones/scratch/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /home/gjones/scratch/sine5qubits/sine_train.bin 
 at time Mon Apr  8 15:02:40 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 15:02:59 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Mon Apr  8 15:11:12 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Mon Apr  8 15:12:52 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 15:23:01 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Mon Apr  8 15:27:54 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 15:37:39 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Mon Apr  8 15:42:16 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Mon Apr  8 15:45:52 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Mon Apr  8 15:54:53 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3421.5615046024323 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  8 16:00:03 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Mon Apr  8 16:09:16 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Mon Apr  8 16:11:06 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 16:20:50 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Mon Apr  8 16:25:29 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 16:34:36 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Mon Apr  8 16:38:52 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Mon Apr  8 16:42:32 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Mon Apr  8 16:52:18 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3367.253581047058 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  8 16:56:10 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Mon Apr  8 17:06:04 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Mon Apr  8 17:07:59 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 17:17:23 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Mon Apr  8 17:22:34 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 17:31:20 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Mon Apr  8 17:36:10 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Mon Apr  8 17:39:48 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Mon Apr  8 17:48:28 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3404.4463295936584 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  8 17:52:47 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Mon Apr  8 18:01:44 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Mon Apr  8 18:03:26 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 18:12:44 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Mon Apr  8 18:17:32 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 18:26:06 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Mon Apr  8 18:30:24 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Mon Apr  8 18:34:06 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Mon Apr  8 18:42:41 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3242.2088577747345 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  8 18:46:49 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Mon Apr  8 18:55:32 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Mon Apr  8 18:58:15 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 19:08:15 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Mon Apr  8 19:13:34 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 19:23:10 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Mon Apr  8 19:28:43 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Mon Apr  8 19:33:33 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Mon Apr  8 19:42:45 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3545.716383934021 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 19:45:56 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Mon Apr  8 19:54:24 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Mon Apr  8 19:56:47 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 20:08:07 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Mon Apr  8 20:14:36 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 20:24:52 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Mon Apr  8 20:29:21 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Mon Apr  8 20:33:39 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Mon Apr  8 20:43:25 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3672.4781324863434 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  8 20:47:15 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Mon Apr  8 20:55:10 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Mon Apr  8 20:56:57 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 21:07:41 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Mon Apr  8 21:13:09 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 21:22:54 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Mon Apr  8 21:27:38 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Mon Apr  8 21:32:02 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Mon Apr  8 21:41:52 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3538.3336687088013 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  8 21:46:08 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Mon Apr  8 21:53:46 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Mon Apr  8 21:55:27 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 22:04:35 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Mon Apr  8 22:09:41 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 22:18:08 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Mon Apr  8 22:22:07 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Mon Apr  8 22:25:38 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Mon Apr  8 22:34:14 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3100.1650557518005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  8 22:37:46 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Mon Apr  8 22:45:57 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Mon Apr  8 22:47:44 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 22:56:36 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Mon Apr  8 23:01:21 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 23:10:05 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Mon Apr  8 23:14:31 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Mon Apr  8 23:18:21 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Mon Apr  8 23:26:17 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3128.812861442566 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  8 23:29:59 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Mon Apr  8 23:38:57 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Mon Apr  8 23:40:54 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Mon Apr  8 23:51:26 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Mon Apr  8 23:57:57 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 00:08:22 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 00:13:15 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 00:17:18 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 00:27:26 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3666.272506713867 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 00:31:05 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 00:42:05 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 00:44:24 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 00:54:18 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 00:59:33 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 01:08:49 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 01:13:40 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 01:17:22 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 01:26:39 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3569.498038291931 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 01:30:33 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 01:39:16 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 01:41:20 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 01:51:19 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 01:56:49 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 02:07:11 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 02:11:51 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 02:16:03 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 02:24:19 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3427.9335236549377 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 02:27:45 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 02:36:09 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 02:38:05 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 02:46:20 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 02:51:03 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 02:59:54 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 03:05:16 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 03:09:46 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 03:19:35 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3326.803328037262 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 03:23:07 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 03:31:47 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 03:33:25 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 03:42:24 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 03:47:38 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 03:56:39 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 04:01:33 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 04:05:40 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 04:14:36 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3294.4896433353424 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 04:18:04 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 04:26:12 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 04:28:00 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 04:38:51 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 04:44:32 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 04:53:33 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 04:57:51 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 05:01:18 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 05:10:05 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3325.272147655487 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 05:13:29 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 05:20:52 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 05:22:35 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 05:31:04 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 05:36:20 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 05:45:18 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 05:49:15 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 05:52:58 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 06:00:38 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3029.7622838020325 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 06:03:59 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 06:12:12 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 06:14:11 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 06:23:00 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 06:27:51 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 06:36:51 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 06:41:40 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 06:45:28 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 06:54:45 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3255.952495574951 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 06:58:26 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 07:05:57 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 07:07:50 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 07:16:55 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 07:22:13 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 07:31:17 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 07:37:09 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 07:40:55 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 07:49:52 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3293.6709094047546 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 07:53:05 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 08:03:37 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 08:05:29 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 08:15:43 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 08:20:19 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 08:28:36 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 08:33:20 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 08:37:00 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 08:44:38 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3308.585568189621 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 08:48:14 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 08:56:26 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 08:58:03 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 09:06:37 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 09:11:22 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 09:19:40 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 09:24:20 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 09:27:54 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 09:35:01 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 2999.172872543335 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 09:38:12 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 09:45:53 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 09:47:25 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 09:56:31 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 10:01:21 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 10:09:20 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 10:13:13 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 10:17:08 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 10:25:08 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3032.862202644348 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 10:28:45 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 10:36:57 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 10:38:45 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 10:48:44 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 10:53:42 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 11:03:00 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 11:07:57 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 11:12:15 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 11:20:43 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3309.166836977005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 11:23:56 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 11:32:15 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 11:34:04 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 11:44:41 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 11:50:59 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 12:01:17 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 12:06:13 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 12:09:48 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 12:19:34 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3573.781908273697 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 12:23:28 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 12:33:13 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 12:35:23 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 12:43:49 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 12:48:39 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 12:57:20 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 13:02:17 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 13:05:37 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 13:13:06 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3210.5803027153015 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 13:17:06 2024]  Iteration number: 0 with current cost as 0.11991448431371912 and parameters 
[-2.9860641   3.00105595 -2.13435155 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.73880975  1.14432446
  1.38997193 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.26456709 -0.25136102]. 
[Tue Apr  9 13:26:03 2024]  Iteration number: 50 with current cost as 0.07338808110844086 and parameters 
[-1.12318881  4.76472017 -1.58091004 -0.11653011  0.55388811 -2.77010471
  3.06858889  2.18960442  1.18552298 -1.06648489  2.83708756  1.14432576
  1.67809053 -1.87354771  0.72965347  2.88579124 -0.54534286 -0.47522734
 -2.02653371  0.72897595  1.60512993  2.83077362 -1.2645666  -0.2513624 ]. 
Working on 0.4 fold... 
[Tue Apr  9 13:27:52 2024]  Iteration number: 0 with current cost as 0.157976683579155 and parameters 
[-2.99912605  2.98901344 -2.13622701 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  0.73472298  1.14432447
  1.3943783  -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 13:37:51 2024]  Iteration number: 50 with current cost as 0.09459479664118167 and parameters 
[-1.15532923  4.44207615 -1.63101192 -0.11652567  0.55389022 -2.77009863
  3.06859512  2.189612    1.1855225  -1.066477    2.93932288  1.14432874
  1.91150403 -1.8735403   0.72966667  2.88579101 -0.545335   -0.47522106
 -2.0265353   0.72897799  1.6051311   2.8307672  -1.26456228 -0.251358  ]. 
Working on 0.6 fold... 
[Tue Apr  9 13:43:34 2024]  Iteration number: 0 with current cost as 0.12885070313627184 and parameters 
[-3.00338051  3.025854   -2.13677793 -0.11653103  0.55388709 -2.77010896
  3.06858498  2.18960147  1.18552    -1.06648308  0.74233269  1.14432445
  1.39884198 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456708 -0.25136102]. 
[Tue Apr  9 13:53:04 2024]  Iteration number: 50 with current cost as 0.07578695570760847 and parameters 
[-2.48020281  4.49528106 -1.45277238 -0.11652522  0.55388536 -2.77011166
  3.0685781   2.18959161  1.18552124 -1.06648715  2.71033217  1.14431807
  1.74800303 -1.87354674  0.72965281  2.8857838  -0.54534464 -0.4752216
 -2.02654469  0.72897766  1.60512486  2.83077231 -1.26456575 -0.25135806]. 
Working on 0.8 fold... 
[Tue Apr  9 13:59:15 2024]  Iteration number: 0 with current cost as 0.17841828297371942 and parameters 
[-2.98470614  2.89939238 -2.13527295 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18551999 -1.06648308  0.73813943  1.14432446
  1.38518398 -1.87354679  0.7296508   2.8857842  -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.26456708 -0.25136102]. 
Working on 1.0 fold... 
[Tue Apr  9 14:03:51 2024]  Iteration number: 0 with current cost as 0.13189987972902262 and parameters 
[-2.99116336  3.00908676 -2.13470556 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.73269868  1.14432445
  1.39206622 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654242  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136103]. 
[Tue Apr  9 14:12:16 2024]  Iteration number: 50 with current cost as 0.08379020101662105 and parameters 
[-0.70318688  4.66495067 -1.67909755 -0.11654706  0.55388441 -2.77011844
  3.06857434  2.18959848  1.18551695 -1.06648378  2.83427892  1.14431195
  1.70903825 -1.87354373  0.72964814  2.88578493 -0.54535617 -0.47522887
 -2.02655338  0.72896663  1.60512628  2.83077095 -1.26456749 -0.25135373]. 
Training complete taking 3500.35812997818 seconds. 
Discarding model... 

Training complete taking 83545.14178824425 total seconds. 
Now scoring model... 
Scoring complete taking 1.4338891506195068 seconds. 
Saved predicted values as IQP_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.14239150776091483,), 'R2_train': 0.7164649865494276, 'MAE_train': 0.31762473029943966, 'MSE_test': 0.1539748514599362, 'R2_test': 0.7128422987876546, 'MAE_test': 0.33829242920258984}. 
Saved model results as IQP_Full-Pauli-CRX_results.json. 
