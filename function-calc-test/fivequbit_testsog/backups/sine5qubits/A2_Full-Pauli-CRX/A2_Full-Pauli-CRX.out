/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/gjones/scratch/sine5qubits/sine_train.bin... 
Successfully loaded /home/gjones/scratch/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /home/gjones/scratch/sine5qubits/sine_test.bin... 
Successfully loaded /home/gjones/scratch/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /home/gjones/scratch/sine5qubits/sine_train.bin 
 at time Mon Apr  8 15:02:34 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 15:02:55 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 15:10:25 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Mon Apr  8 15:15:27 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 15:25:39 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Mon Apr  8 15:26:51 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 15:37:24 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Mon Apr  8 15:39:09 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 15:48:29 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Mon Apr  8 15:52:53 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 16:00:51 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3580.3820974826813 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  8 16:02:42 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 16:09:52 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Mon Apr  8 16:14:59 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 16:25:41 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Mon Apr  8 16:26:17 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 16:35:07 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Mon Apr  8 16:36:31 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 16:43:07 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Mon Apr  8 16:46:38 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 16:55:19 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3288.5711789131165 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  8 16:57:36 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 17:06:59 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Mon Apr  8 17:12:17 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 17:20:20 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Mon Apr  8 17:21:28 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 17:30:30 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Mon Apr  8 17:32:06 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 17:40:36 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Mon Apr  8 17:44:21 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 17:53:22 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3464.628950357437 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  8 17:55:25 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 18:04:19 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Mon Apr  8 18:09:45 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 18:21:19 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Mon Apr  8 18:22:25 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 18:32:38 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Mon Apr  8 18:34:20 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 18:41:39 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Mon Apr  8 18:45:31 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 18:54:56 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3691.849739074707 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  8 18:56:43 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 19:05:10 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Mon Apr  8 19:10:04 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 19:19:24 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Mon Apr  8 19:20:09 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 19:29:47 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Mon Apr  8 19:31:39 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 19:39:47 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Mon Apr  8 19:43:59 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 19:53:11 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3494.8114659786224 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 19:54:53 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 20:02:42 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Mon Apr  8 20:08:30 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 20:16:45 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Mon Apr  8 20:17:33 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 20:25:32 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Mon Apr  8 20:26:51 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 20:33:43 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Mon Apr  8 20:37:39 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:44:38 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3081.6397063732147 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  8 20:46:22 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 20:53:34 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Mon Apr  8 20:57:47 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 21:06:24 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Mon Apr  8 21:07:14 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 21:15:48 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Mon Apr  8 21:16:55 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 21:24:28 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Mon Apr  8 21:28:54 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 21:36:33 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3105.590168237686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  8 21:38:11 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 21:45:50 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Mon Apr  8 21:50:00 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 21:58:19 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Mon Apr  8 21:59:07 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 22:07:12 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Mon Apr  8 22:08:26 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 22:14:53 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Mon Apr  8 22:19:23 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 22:26:54 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3029.8795731067657 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  8 22:28:30 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 22:36:51 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Mon Apr  8 22:40:53 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 22:51:05 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Mon Apr  8 22:52:06 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 23:02:56 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Mon Apr  8 23:04:17 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 23:11:58 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Mon Apr  8 23:15:26 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 23:22:53 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3358.106913328171 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  8 23:24:49 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 23:31:40 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Mon Apr  8 23:35:39 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 23:43:14 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Mon Apr  8 23:43:50 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Apr  8 23:54:33 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Mon Apr  8 23:55:45 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 00:03:35 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 00:07:46 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 00:17:49 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3314.1475553512573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 00:19:45 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 00:27:36 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 00:31:18 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 00:39:48 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 00:40:46 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 00:49:38 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 00:51:06 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 00:58:21 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 01:03:10 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 01:12:23 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3277.701164007187 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 01:14:24 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 01:23:00 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 01:28:07 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 01:37:42 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 01:38:24 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 01:46:29 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 01:47:50 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 01:54:17 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 01:58:03 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 02:05:52 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3190.292055130005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 02:07:50 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 02:16:34 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 02:21:38 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 02:29:55 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 02:30:34 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 02:40:06 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 02:41:12 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 02:49:37 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 02:54:13 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:02:58 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3419.5819771289825 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 03:04:30 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 03:12:35 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 03:16:48 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 03:26:24 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 03:27:07 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 03:36:47 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 03:37:51 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 03:45:13 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 03:48:47 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:56:45 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3223.6750195026398 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 03:58:21 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 04:06:14 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 04:10:45 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 04:18:24 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 04:19:10 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 04:27:14 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 04:29:12 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 04:37:27 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 04:42:55 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 04:52:02 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3360.508341550827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 04:54:14 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 05:02:37 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 05:07:36 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 05:17:17 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 05:17:56 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 05:26:52 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 05:28:00 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 05:34:35 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 05:38:05 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:45:13 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3170.083969593048 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 05:47:04 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 05:53:42 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 05:57:59 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 06:06:26 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 06:07:10 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 06:15:08 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 06:16:31 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 06:23:41 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 06:28:44 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 06:36:44 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3090.515324831009 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 06:38:40 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 06:46:36 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 06:50:56 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 06:59:15 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 06:59:59 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 07:07:23 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 07:08:45 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 07:15:12 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 07:19:11 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 07:26:07 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 2953.9644672870636 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 07:27:49 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 07:34:45 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 07:38:24 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 07:45:44 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 07:46:34 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 07:55:08 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 07:56:50 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 08:03:46 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 08:07:42 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 08:16:27 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3021.2263367176056 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 08:18:23 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 08:25:39 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 08:30:33 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 08:40:11 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 08:40:48 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 08:51:29 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 08:52:55 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 09:00:32 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 09:04:21 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 09:12:48 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3359.3676114082336 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 09:14:19 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 09:23:17 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 09:27:49 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 09:36:34 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 09:37:15 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 09:45:57 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 09:47:24 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 09:55:18 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 10:00:03 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:07:00 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3283.28169131279 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 10:09:00 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 10:16:41 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 10:21:22 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 10:30:50 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 10:32:01 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 10:40:59 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 10:43:21 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 10:50:56 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 10:55:49 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 11:04:05 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3420.9534351825714 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 11:05:53 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 11:14:16 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 11:19:29 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 11:27:42 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 11:28:47 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 11:37:11 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 11:38:58 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 11:46:55 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 11:51:07 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 11:58:30 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3285.1820142269135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 12:01:03 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 12:07:49 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 12:12:50 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 12:21:45 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 12:22:54 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 12:32:07 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 12:33:32 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 12:41:22 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 12:45:44 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 12:54:14 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3316.1579587459564 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 12:56:00 2024]  Iteration number: 0 with current cost as 0.12290149625160769 and parameters 
[-2.83055598  2.18386375 -2.10428252 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48372916  1.14432445
  1.17397298 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 13:03:57 2024]  Iteration number: 50 with current cost as 0.07765316077375775 and parameters 
[-3.16954603  1.57226314 -0.00573144 -0.11632442  0.55408478 -2.7699344
  3.0686641   2.18981786  1.18556568 -1.06642739  0.1921086   1.14429931
  1.54775209 -1.87344847  0.7296749   2.88591938 -0.54529006 -0.47519185
 -2.02656956  0.72904492  1.6050283   2.83078916 -1.2645755  -0.25115303]. 
Working on 0.4 fold... 
[Tue Apr  9 13:08:54 2024]  Iteration number: 0 with current cost as 0.13539554227239062 and parameters 
[-2.81727295  2.1744601  -2.10142638 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46183474  1.14432445
  1.14896991 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 13:16:46 2024]  Iteration number: 50 with current cost as 0.09022448303084121 and parameters 
[-3.72790763  1.60019839 -3.03700586 -0.11680593  0.55358866 -2.77020289
  3.06851591  2.18932405  1.18532883 -1.06636829  1.54224659  1.14390771
 -0.00958095 -1.87344722  0.72936289  2.88558327 -0.54533547 -0.4752195
 -2.02655681  0.72908357  1.60501477  2.83087904 -1.26468409 -0.25124703]. 
Working on 0.6 fold... 
[Tue Apr  9 13:17:23 2024]  Iteration number: 0 with current cost as 0.1385641192350621 and parameters 
[-2.81606114  2.17774803 -2.10114892 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46163491  1.14432445
  1.148629   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 13:26:15 2024]  Iteration number: 50 with current cost as 0.07807252654025498 and parameters 
[-1.82259176  1.58691933 -3.16387483 -0.11653105  0.55388684 -2.77012166
  3.06858292  2.18959199  1.18551432 -1.0664896   0.77111374  1.14431164
  0.81214983 -1.87355291  0.72963857  2.88578323 -0.54536308 -0.4752199
 -2.02655354  0.72897279  1.60512198  2.83075832 -1.26456689 -0.25135406]. 
Working on 0.8 fold... 
[Tue Apr  9 13:27:31 2024]  Iteration number: 0 with current cost as 0.12605113209725421 and parameters 
[-2.82238411  2.18844466 -2.1024866  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.47452212  1.14432445
  1.16234623 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Tue Apr  9 13:36:34 2024]  Iteration number: 50 with current cost as 0.08702166534104726 and parameters 
[-3.94379138  1.57505873 -0.76627203 -0.11649295  0.55388164 -2.77010883
  3.06863435  2.18959825  1.18551668 -1.0664652   0.08764108  1.14434819
  1.51181529 -1.87356543  0.72966262  2.88580394 -0.54535871 -0.47522788
 -2.0265386   0.72898065  1.60509515  2.83077007 -1.2645499  -0.25135649]. 
Working on 1.0 fold... 
[Tue Apr  9 13:40:19 2024]  Iteration number: 0 with current cost as 0.12995972637859227 and parameters 
[-2.83094069  2.17571986 -2.10474449 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48077979  1.14432445
  1.17141994 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 13:48:11 2024]  Iteration number: 50 with current cost as 0.08428768801458206 and parameters 
[-3.47140846  1.54003069  0.08883137 -0.11650868  0.55388733 -2.7700861
  3.06859023  2.18961165  1.18555128 -1.06645796  1.32926954  1.14432405
  1.55530066 -1.87354794  0.72966006  2.88578805 -0.54530989 -0.47522686
 -2.02653371  0.72899271  1.60513302  2.83076918 -1.26453853 -0.25136989]. 
Training complete taking 3236.700019836426 seconds. 
Discarding model... 

Training complete taking 82018.80085873604 total seconds. 
Now scoring model... 
Scoring complete taking 0.6774351596832275 seconds. 
Saved predicted values as A2_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.14071473221058928,), 'R2_train': 0.7198038414129733, 'MAE_train': 0.3167694651147235, 'MSE_test': 0.17116689693379303, 'R2_test': 0.6807797365536175, 'MAE_test': 0.36326399787862085}. 
Saved model results as A2_Full-Pauli-CRX_results.json. 
