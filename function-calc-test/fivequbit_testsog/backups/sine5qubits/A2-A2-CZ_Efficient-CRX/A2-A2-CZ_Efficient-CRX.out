/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:29 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:40:04 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Thu Apr  4 21:43:20 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Thu Apr  4 21:47:20 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Thu Apr  4 21:50:54 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Thu Apr  4 21:54:39 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1097.0356175899506 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:58:13 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Thu Apr  4 22:01:23 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Thu Apr  4 22:05:21 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Thu Apr  4 22:09:10 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Thu Apr  4 22:12:54 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1097.6956820487976 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:16:36 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Thu Apr  4 22:19:40 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Thu Apr  4 22:23:34 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Thu Apr  4 22:27:16 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Thu Apr  4 22:31:00 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1085.3324255943298 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:34:49 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Thu Apr  4 22:38:02 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Thu Apr  4 22:41:56 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Thu Apr  4 22:45:35 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Thu Apr  4 22:49:12 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1086.0314218997955 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:52:42 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Thu Apr  4 22:55:53 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Thu Apr  4 22:59:54 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Thu Apr  4 23:03:30 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Thu Apr  4 23:07:03 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1067.7290244102478 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:10:37 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Thu Apr  4 23:13:48 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Thu Apr  4 23:17:57 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Thu Apr  4 23:21:29 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Thu Apr  4 23:24:54 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1080.912995815277 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:28:30 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Thu Apr  4 23:31:38 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Thu Apr  4 23:35:33 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Thu Apr  4 23:38:55 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Thu Apr  4 23:42:18 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1034.4970500469208 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:45:38 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Thu Apr  4 23:48:49 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Thu Apr  4 23:52:32 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Thu Apr  4 23:55:53 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Thu Apr  4 23:59:17 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1020.9098765850067 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:02:38 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 00:05:34 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 00:09:11 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 00:12:32 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 00:16:06 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1006.0050075054169 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:19:26 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 00:22:27 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 00:26:02 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 00:29:26 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 00:32:56 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1011.3018822669983 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:36:16 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 00:39:16 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 00:43:04 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 00:46:28 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 00:49:44 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1010.9120926856995 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:53:03 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 00:56:01 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 00:59:35 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 01:02:57 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 01:06:20 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 994.203106880188 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:09:45 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 01:12:52 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 01:16:34 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 01:19:57 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 01:23:23 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1022.3775033950806 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:26:47 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 01:29:43 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 01:33:32 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 01:37:00 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 01:40:18 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1012.3382275104523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:43:36 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 01:46:46 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 01:50:31 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 01:53:56 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 01:57:20 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1023.8125610351562 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:00:39 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 02:03:37 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 02:07:12 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 02:10:32 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 02:13:54 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 993.2195768356323 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:17:12 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 02:20:14 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 02:23:59 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 02:27:21 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 02:30:43 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1014.1779954433441 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 02:34:09 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 02:37:12 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 02:40:48 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 02:44:06 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 02:47:34 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1006.9239633083344 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:50:57 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 02:53:57 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 02:57:31 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 03:00:51 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 03:04:11 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 994.8977437019348 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 03:07:27 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 03:10:35 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 03:14:19 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 03:17:34 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 03:20:50 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 999.0593664646149 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 03:24:08 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 03:27:10 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 03:30:44 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 03:34:05 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 03:37:24 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 995.7725639343262 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 03:40:47 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 03:44:16 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 03:48:09 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 03:51:25 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 03:54:45 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1044.8947930335999 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:58:03 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 04:01:01 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 04:04:41 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 04:07:56 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 04:11:13 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 984.4597580432892 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 04:14:33 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 04:17:33 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 04:21:08 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 04:24:24 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 04:27:40 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 990.7425558567047 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 04:31:04 2024]  Iteration number: 0 with current cost as 0.30855863940948625 and parameters 
[-4.44578289  2.23743464 -2.12427913 -0.11653052  0.55388758 -2.77010897
  3.06858498  2.18960195  1.18552049 -1.06648308  0.60271561  1.14432495
  1.31029949 -1.87354579]. 
Working on 0.4 fold... 
[Fri Apr  5 04:34:02 2024]  Iteration number: 0 with current cost as 0.320551867467593 and parameters 
[-4.32247438  2.23743446 -2.12427929 -0.11653085  0.55388708 -2.77010915
  3.06858481  2.1896018   1.18552033 -1.06648308  0.6027151   1.1443248
  1.31029916 -1.87354628]. 
Working on 0.6 fold... 
[Fri Apr  5 04:37:44 2024]  Iteration number: 0 with current cost as 0.34250054942553004 and parameters 
[-4.33926416  2.23743436 -2.12427964 -0.11653103  0.5538868  -2.77010925
  3.06858471  2.18960173  1.18552026 -1.06648363  0.60271538  1.14432445
  1.31029871 -1.87354625]. 
Working on 0.8 fold... 
[Fri Apr  5 04:41:00 2024]  Iteration number: 0 with current cost as 0.27645594559332853 and parameters 
[-4.45008136  2.23743464 -2.12427952 -0.11653103  0.55388697 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648331  0.6027151   1.14432445
  1.31029899 -1.87354657]. 
Working on 1.0 fold... 
[Fri Apr  5 04:44:27 2024]  Iteration number: 0 with current cost as 0.34884890195202733 and parameters 
[-7.58077538  2.23743401 -2.12427901 -0.11653165  0.55388646 -2.77010897
  3.06858436  2.18960207  1.18552061 -1.06648371  0.6027151   1.14432507
  1.31029899 -1.87354494]. 
Training complete taking 1006.4281463623047 seconds. 
Discarding model... 

Training complete taking 25681.671591997147 total seconds. 
Now scoring model... 
Scoring complete taking 3.3226914405822754 seconds. 
Saved predicted values as A2-A2-CZ_Efficient-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.589780715330444,), 'R2_train': -0.17439224911422002, 'MAE_train': 0.6694770441048274, 'MSE_test': 0.6324817538818521, 'R2_test': -0.17955630274287082, 'MAE_test': 0.6679460580412562}. 
Saved model results as A2-A2-CZ_Efficient-CRX_results.json. 
