/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:35 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:05 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:45:36 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:52:07 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:58:26 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:04:27 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2038.4010140895844 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:12:03 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:19:30 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:25:59 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:32:23 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:38:24 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2039.8712258338928 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:46:02 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:53:29 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:00:00 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:06:21 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:12:22 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2040.8040232658386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:20:17 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:27:44 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:34:12 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:40:42 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:46:44 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2057.386724472046 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:54:21 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:01:48 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:08:15 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:14:32 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:20:32 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2032.2972950935364 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:28:15 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:36:02 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:42:35 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:48:55 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:55:12 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2089.791299343109 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:03:03 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:10:30 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:17:05 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:23:21 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:29:19 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2043.693943977356 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:37:06 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:44:40 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:51:08 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:57:27 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:03:29 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2041.2216908931732 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:11:08 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:18:44 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:25:14 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:31:31 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:37:54 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2079.2052240371704 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:45:47 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:53:16 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:59:46 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:06:14 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:12:15 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2043.2396085262299 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 03:19:50 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:27:19 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:33:49 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:41:01 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:47:04 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2088.585833787918 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 03:54:38 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:02:05 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:08:35 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:14:54 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:20:54 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2033.0541496276855 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 04:28:31 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:35:59 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:42:28 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:48:48 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:54:50 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2039.2627334594727 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:02:32 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:10:20 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:16:52 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:23:18 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:29:15 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2071.412415266037 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 05:37:02 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:44:30 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:50:58 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:57:23 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:03:22 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2033.90553689003 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 06:10:56 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 06:18:39 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:25:10 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:32:06 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:38:10 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2091.1965968608856 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 06:45:47 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 06:53:15 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 07:00:30 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:06:48 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 07:12:51 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2091.7761812210083 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 07:20:39 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:28:06 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 07:34:42 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:41:03 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 07:47:08 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2051.0954842567444 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 07:54:50 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 08:02:41 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:09:11 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:15:32 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:21:44 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2083.908938884735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 08:29:34 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 08:37:11 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:43:40 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:50:00 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:56:07 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2053.0575244426727 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 09:03:48 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:11:22 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 09:17:55 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:24:25 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 09:30:25 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2056.7673938274384 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 09:38:04 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:45:29 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 09:51:56 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:58:15 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 10:04:15 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2028.9587330818176 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 10:11:54 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 10:19:22 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 10:25:51 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 10:32:10 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 10:38:10 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2034.5145089626312 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 10:45:47 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 10:53:15 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 10:59:41 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 11:05:59 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 11:12:00 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2069.9950907230377 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 11:20:39 2024]  Iteration number: 0 with current cost as 0.32928527192749646 and parameters 
[-3.59595497  2.09335002 -2.25283106 -0.11653103  0.553887   -2.77010897
  3.06858498  2.18960138  1.18552002 -1.06648308  1.82490164  1.14432445
  1.31029902 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 11:28:04 2024]  Iteration number: 0 with current cost as 0.3408065452557587 and parameters 
[-3.59885265  2.15520645 -2.24305642 -0.1165311   0.553887   -2.77010901
  3.06858495  2.18960138  1.18551998 -1.06648308  1.6214119   1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578412 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 11:34:32 2024]  Iteration number: 0 with current cost as 0.3439118972017814 and parameters 
[-3.5962122   2.13438465 -2.2521066  -0.11653099  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18552002 -1.06648305  1.67104324  1.14432449
  1.31029899 -1.87354673  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 11:40:51 2024]  Iteration number: 0 with current cost as 0.32508349542466347 and parameters 
[-3.56584949  2.1507513  -2.25510613 -0.11653106  0.55388697 -2.77010901
  3.06858491  2.18960138  1.18551998 -1.06648308  1.68814482  1.14432445
  1.31029895 -1.87354684  0.72965073  2.88578412 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 11:46:53 2024]  Iteration number: 0 with current cost as 0.3312334433096551 and parameters 
[-3.57924179  2.09811563 -2.22393301 -0.11653103  0.553887   -2.77010897
  3.06858495  2.18960138  1.18551998 -1.06648305  1.73497879  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2072.824641942978 seconds. 
Discarding model... 

Training complete taking 51406.22984623909 total seconds. 
Now scoring model... 
Scoring complete taking 1.0872552394866943 seconds. 
Saved predicted values as M-A1-CNOT_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.3385339116069138,), 'R2_train': 0.32589928507457966, 'MAE_train': 0.49986287426122367, 'MSE_test': 0.37672538210638196, 'R2_test': 0.2974203664540692, 'MAE_test': 0.5570662757317972}. 
Saved model results as M-A1-CNOT_Modified-Pauli-CRX_results.json. 
