/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:30:19 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:31:55 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 17:33:45 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:36:09 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:37 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:46 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 677.5821402072906 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:10 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:02 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:29 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 17:49:56 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:03 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 673.5230240821838 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:32 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:26 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:55 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:01:25 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:03:33 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 688.2460346221924 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:51 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:07:41 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:10:09 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:12:37 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:14:48 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 678.9038443565369 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:17:16 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:19:09 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:21:38 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:24:02 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:26:18 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 687.0246636867523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:28:45 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:30:38 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:33:04 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:35:29 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:37:47 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 689.0912976264954 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:40:08 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:42:01 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:44:42 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:47:08 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:49:18 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 692.264119386673 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:51:43 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:53:40 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:56:08 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:58:38 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:00:50 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 695.1971645355225 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 19:03:18 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:05:22 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:07:50 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:10:28 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:12:44 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 715.205729007721 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 19:15:16 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:17:10 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:19:31 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:21:52 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:24:11 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 683.4609580039978 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 19:26:41 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:28:35 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:31:05 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:33:38 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:35:54 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 701.6537563800812 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 19:38:21 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:40:10 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:42:42 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:45:16 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:47:30 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 694.3011753559113 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 19:50:06 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:52:08 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:54:39 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:57:10 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:59:10 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 706.2400455474854 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 20:01:39 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 20:03:36 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 20:05:55 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 20:08:14 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 20:10:26 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 674.2877480983734 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 20:12:57 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 20:14:48 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 20:17:13 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 20:19:34 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 20:21:40 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 671.8363270759583 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 20:24:04 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 20:26:03 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 20:28:26 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 20:30:55 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 20:33:09 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 690.8247153759003 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 20:35:44 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 20:37:38 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 20:40:05 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 20:42:30 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 20:44:38 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 684.645437002182 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 20:46:56 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 20:48:49 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 20:51:10 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 20:53:29 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 20:55:42 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 674.5377044677734 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 20:58:16 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 21:00:06 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 21:02:37 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 21:05:15 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 21:07:36 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 707.7028126716614 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 21:09:56 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 21:11:55 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 21:14:27 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 21:16:50 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 21:18:59 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 682.3384857177734 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 21:21:28 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 21:23:27 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 21:25:55 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 21:28:32 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 21:30:45 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 705.687228679657 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 21:33:15 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 21:35:07 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 21:37:41 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 21:40:24 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 21:42:31 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 704.8637323379517 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 21:44:54 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 21:46:52 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 21:49:22 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 21:51:44 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 21:53:55 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 682.4166736602783 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 21:56:21 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 21:58:16 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 22:00:43 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 22:03:13 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 22:05:27 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 701.4355487823486 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 22:08:00 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 22:09:49 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 22:12:18 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 22:14:40 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 22:16:55 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 677.8113808631897 seconds. 
Discarding model... 

Training complete taking 17241.082372188568 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 2.5464670658111572 seconds. 
Saved predicted values as M-A2-CZ_ESU2_predicted_values.csv
Model scores: {'MSE_train': (191.95743083459215,), 'R2_train': 0.07003067157585341, 'MAE_train': 11.197196492244611, 'MSE_test': 197.88038239785186, 'R2_test': -0.19278612154185493, 'MAE_test': 10.220631560325149}. 
Saved model results as M-A2-CZ_ESU2_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 11:42:52 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:44:36 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 11:46:38 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 11:49:06 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 11:51:39 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 11:53:54 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 710.178121805191 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:56:27 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 11:58:29 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:00:59 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 12:03:38 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 12:05:52 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 719.3932025432587 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:08:26 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 12:10:23 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:12:50 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 12:15:25 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 12:17:40 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 710.5608677864075 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:20:12 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 12:22:06 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:24:30 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 12:26:56 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 12:29:09 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 686.5098731517792 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:31:41 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 12:33:31 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:35:58 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 12:38:22 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 12:40:32 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 681.3711631298065 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:42:59 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 12:44:51 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:47:14 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 12:49:40 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 12:51:49 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 676.9551956653595 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:54:14 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 12:56:06 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:58:27 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:00:50 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:03:00 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 674.3452458381653 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:05:27 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:07:20 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:09:43 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:12:10 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:14:22 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 676.6214191913605 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 13:16:46 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:18:37 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:21:06 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:23:30 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:25:38 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 679.6503665447235 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 13:28:06 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:30:02 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:32:34 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:35:00 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:37:14 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 695.0960423946381 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 13:39:38 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:41:33 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:43:57 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:46:27 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:48:34 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 680.8675391674042 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 13:51:04 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:52:57 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:55:24 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:57:47 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:59:57 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 681.7045493125916 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 14:02:19 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:04:12 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:06:35 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:09:02 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:11:11 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 673.3485848903656 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 14:13:37 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:15:30 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:17:58 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:20:24 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:22:32 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 680.7558958530426 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 14:24:56 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:26:51 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:29:21 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:31:47 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:33:57 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 685.5255765914917 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 14:36:23 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:38:22 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:40:47 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:43:17 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:45:25 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 687.1031455993652 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 14:47:48 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:49:41 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:52:08 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:54:32 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:56:40 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 676.5716977119446 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 14:59:02 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 15:00:53 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 15:03:20 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 15:05:53 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 15:08:08 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 687.6951489448547 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 15:10:33 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 15:12:27 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 15:14:51 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 15:17:19 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 15:19:28 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 681.0492880344391 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 15:21:55 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 15:23:48 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 15:26:10 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 15:28:37 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 15:30:42 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 672.5467607975006 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 15:33:11 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 15:35:06 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 15:37:31 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 15:39:51 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 15:42:01 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 678.2196390628815 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 15:44:24 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 15:46:16 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 15:48:44 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 15:51:09 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 15:53:17 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 677.12646317482 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 15:55:43 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 15:57:37 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 16:00:02 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 16:02:33 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 16:04:48 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 691.0500364303589 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 16:07:16 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 16:09:14 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 16:11:45 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 16:14:20 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 16:16:31 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 703.8839673995972 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 16:19:01 2024]  Iteration number: 0 with current cost as 0.3229016170994012 and parameters 
[-1.45034102  2.23743464 -2.12427937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552025 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 16:20:59 2024]  Iteration number: 0 with current cost as 0.3065379173479664 and parameters 
[-1.40256759  2.23743482 -2.12427926 -0.11653084  0.55388727 -2.77010879
  3.06858498  2.18960164  1.18552008 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 16:23:33 2024]  Iteration number: 0 with current cost as 0.2902141455082642 and parameters 
[-1.46071846  2.23743464 -2.12427948 -0.11653095  0.55388708 -2.77010889
  3.06858498  2.18960161  1.18552014 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 16:26:01 2024]  Iteration number: 0 with current cost as 0.29853384426024115 and parameters 
[-1.42614214  2.23743464 -2.12427947 -0.11653103  0.55388716 -2.77010897
  3.0685849   2.18960145  1.18552007 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 16:28:19 2024]  Iteration number: 0 with current cost as 0.31432267411186554 and parameters 
[-1.44104315  2.23743464 -2.12427945 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 710.8084540367126 seconds. 
Discarding model... 

Training complete taking 17178.93895149231 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 2.703216552734375 seconds. 
Saved predicted values as M-A2-CZ_ESU2_predicted_values.csv
Model scores: {'MSE_train': (191.95743083459215,), 'R2_train': 0.07003067157585341, 'MAE_train': 11.197196492244611, 'MSE_test': 197.88038239785186, 'R2_test': -0.19278612154185493, 'MAE_test': 10.220631560325149}. 
Saved model results as M-A2-CZ_ESU2_results.json. 
