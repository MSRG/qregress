/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:30:07 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:23 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 17:33:48 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 17:37:19 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:57 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:52 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1098.0476126670837 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:42 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:04 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:37 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:15 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:03:10 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1096.3221797943115 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:06:57 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:10:19 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:13:57 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:17:35 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:21:27 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1093.3433277606964 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:25:12 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:28:30 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:31:57 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:35:33 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:39:25 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1079.804185628891 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:43:11 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:46:30 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:49:59 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:53:34 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:57:27 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1081.1529612541199 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 19:01:13 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 19:04:34 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 19:08:02 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:11:42 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 19:15:34 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1084.8738300800323 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 19:19:17 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 19:22:42 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 19:26:09 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:29:46 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 19:33:47 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1092.1913132667542 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 19:37:28 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 19:40:53 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 19:44:21 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:48:02 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 19:51:56 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1094.6182539463043 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 19:55:44 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 19:59:03 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 20:02:32 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 20:06:08 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 20:10:01 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1081.6087675094604 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 20:13:46 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 20:17:29 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 20:20:56 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 20:24:34 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 20:28:27 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1106.9702534675598 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 20:32:12 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 20:35:52 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 20:39:22 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 20:43:03 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 20:46:58 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1133.896187543869 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 20:51:06 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 20:54:37 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 20:58:04 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 21:01:39 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 21:05:35 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1103.9486045837402 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 21:09:31 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 21:12:55 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 21:16:24 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 21:19:59 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 21:23:54 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1089.0173559188843 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 21:27:38 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 21:30:57 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 21:34:26 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 21:38:11 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 21:42:03 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1088.19921875 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 21:45:46 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 21:49:06 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 21:52:34 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 21:56:12 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 22:00:04 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1096.96284532547 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 22:04:18 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 22:07:40 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 22:11:10 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 22:14:47 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 22:18:38 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1097.810477733612 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 22:22:23 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 22:25:45 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 22:29:13 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 22:33:04 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 22:37:17 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1133.8781199455261 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 22:41:15 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 22:44:36 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 22:48:05 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 22:51:40 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 22:55:33 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1080.045527458191 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 22:59:15 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 23:03:18 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 23:06:48 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 23:10:24 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 23:14:15 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1123.2057378292084 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 23:18:00 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 23:21:29 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 23:24:57 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 23:28:33 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 23:32:30 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1099.0340249538422 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 23:36:18 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 23:39:52 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 23:43:21 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 23:46:59 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 23:50:57 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1105.235392332077 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 23:54:43 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 23:58:06 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 00:01:36 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 00:05:16 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 00:09:07 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1102.5393741130829 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 00:13:07 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 00:16:29 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 00:19:54 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 00:23:31 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 00:27:21 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1093.5573227405548 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 00:31:19 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 00:34:40 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 00:38:07 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 00:42:48 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 00:46:54 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1158.330582857132 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 00:50:39 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 00:54:24 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 00:57:52 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 01:01:28 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 01:05:21 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1106.9876070022583 seconds. 
Discarding model... 

Training complete taking 27521.58246564865 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.9522345066070557 seconds. 
Saved predicted values as M_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (8.311472195105532,), 'R2_train': 0.9597337066770881, 'MAE_train': 1.5956604003700405, 'MSE_test': 52.33575971211256, 'R2_test': 0.6845297796148038, 'MAE_test': 2.9166788971700752}. 
Saved model results as M_Modified-Pauli-CRX_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 11:36:37 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:36:53 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 11:40:20 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 11:43:54 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 11:47:36 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 11:51:34 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1109.4145545959473 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:55:22 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 11:58:55 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:02:36 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:06:19 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:10:16 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1136.9078769683838 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:14:19 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:17:44 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:21:17 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:25:00 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:28:56 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1106.5475869178772 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:32:46 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:36:14 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:39:47 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:43:28 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 12:47:25 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1118.8819806575775 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:51:25 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:54:50 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:58:23 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:02:09 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:06:14 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1124.2124235630035 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 13:10:10 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 13:13:38 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 13:17:11 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:20:55 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:24:52 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1110.2751297950745 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 13:28:40 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 13:32:04 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 13:35:44 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:39:24 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:43:20 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1106.819658756256 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:47:07 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 13:50:30 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 13:54:07 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:57:54 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 14:01:50 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1117.8768467903137 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 14:05:45 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 14:09:10 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 14:12:47 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 14:16:36 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 14:20:48 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1133.589454650879 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 14:24:39 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 14:28:01 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 14:31:32 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 14:35:20 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 14:39:22 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1112.1049225330353 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 14:43:11 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 14:46:47 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 14:50:19 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 14:54:00 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 14:57:58 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1133.0114014148712 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 15:02:02 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 15:05:34 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 15:09:05 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 15:13:19 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 15:17:14 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1139.154729127884 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 15:21:02 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 15:24:30 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 15:28:03 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 15:31:46 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 15:35:53 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1121.0336134433746 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 15:39:47 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 15:43:21 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 15:46:54 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 15:50:35 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 15:54:32 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1115.8678231239319 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 15:58:20 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 16:01:41 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 16:05:15 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 16:08:54 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 16:12:51 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1100.4485447406769 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 16:16:39 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 16:20:06 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 16:23:40 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 16:27:21 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 16:31:18 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1115.835522890091 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 16:35:20 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 16:39:11 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 16:42:51 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 16:46:29 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 16:50:25 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1141.3372838497162 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 16:54:17 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 16:57:40 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 17:01:11 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 17:04:52 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 17:08:57 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1108.2982547283173 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 17:12:45 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 17:16:11 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 17:19:56 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 17:23:37 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 17:27:36 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1117.6795995235443 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 17:31:24 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 17:34:51 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 17:38:27 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 17:42:09 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 17:46:09 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1113.998573064804 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 17:49:57 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 17:53:22 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 17:56:58 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 18:00:45 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 18:04:42 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1117.2694845199585 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 18:08:35 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 18:12:03 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 18:15:55 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 18:19:34 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 18:23:31 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1125.50492477417 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 18:27:19 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 18:30:53 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 18:34:39 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 18:38:20 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 18:42:30 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1138.669902086258 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 18:46:17 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 18:49:41 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 18:53:13 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 18:56:54 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 19:00:49 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1128.530381679535 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 19:05:07 2024]  Iteration number: 0 with current cost as 0.0890845172239251 and parameters 
[-3.27166643  2.2034977  -2.18350784 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551999 -1.06648309  1.28094401  1.14432446
  1.31029898 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 19:08:40 2024]  Iteration number: 0 with current cost as 0.04293922144146098 and parameters 
[-3.35497906  2.20942542 -2.1961153  -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  1.41878239  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 19:12:34 2024]  Iteration number: 0 with current cost as 0.059160805723320234 and parameters 
[-3.3205076   2.21080446 -2.19334375 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.3436998   1.14432444
  1.31029897 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 19:16:13 2024]  Iteration number: 0 with current cost as 0.050381900185761004 and parameters 
[-3.34301508  2.21378778 -2.19489578 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960146  1.18551998 -1.06648309  1.37595283  1.14432444
  1.31029898 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 19:20:12 2024]  Iteration number: 0 with current cost as 0.06081035188773493 and parameters 
[-3.31694205  2.20379465 -2.19036787 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.0664831   1.36550443  1.14432444
  1.31029897 -1.87354679  0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1134.7398200035095 seconds. 
Discarding model... 

Training complete taking 28028.012037038803 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 1.0673375129699707 seconds. 
Saved predicted values as M_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (8.311472195105532,), 'R2_train': 0.9597337066770881, 'MAE_train': 1.5956604003700405, 'MSE_test': 52.33575971211256, 'R2_test': 0.6845297796148038, 'MAE_test': 2.9166788971700752}. 
Saved model results as M_Modified-Pauli-CRX_results.json. 
