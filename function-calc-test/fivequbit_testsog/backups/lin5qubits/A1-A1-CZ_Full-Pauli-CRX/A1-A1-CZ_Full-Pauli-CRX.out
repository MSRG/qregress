/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/opt/miniconda/bin/python: can't open file '/home/gjones/scratch/lin5qubits/main.py': [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/home/gjones/scratch/lin5qubits/main.py", line 19, in <module>
    from quantum.Quantum import QuantumRegressor
ModuleNotFoundError: No module named 'quantum'
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Wed Mar 27 09:38:01 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 09:38:26 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 09:49:55 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 09:50:42 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 10:00:56 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 10:08:14 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 10:19:26 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 10:20:45 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 10:32:44 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 10:35:01 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 10:44:43 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4332.028753757477 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 10:50:36 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 11:01:47 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 11:02:32 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 11:12:35 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 11:19:48 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 11:30:58 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 11:32:22 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 11:44:22 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 11:46:41 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 11:56:28 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4306.278448343277 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 12:02:22 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 12:13:35 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 12:14:20 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 12:24:24 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 12:31:37 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 12:42:52 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 12:44:12 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 12:56:05 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 12:58:21 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 13:08:04 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4294.804719924927 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 13:13:57 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 13:25:12 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 13:25:58 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 13:36:07 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 13:43:24 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 13:54:45 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 13:56:05 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 14:08:07 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 14:10:24 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 14:20:03 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4318.259566545486 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 14:25:55 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 14:37:12 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 14:37:58 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 14:48:07 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 14:55:24 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 15:06:44 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 15:08:05 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 15:20:10 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 15:22:28 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 15:32:12 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4331.042183876038 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 15:38:06 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 15:49:25 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 15:50:11 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 16:00:18 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 16:07:37 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 16:18:56 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 16:20:17 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 16:32:27 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 16:34:46 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 16:44:37 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4349.805080413818 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 16:50:36 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 17:02:00 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 17:02:46 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 17:12:54 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 17:20:11 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 17:31:31 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 17:32:52 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 17:45:01 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 17:47:27 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 17:57:20 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4362.1234674453735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 18:03:18 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 18:14:39 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 18:15:25 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 18:25:39 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 18:32:59 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 18:44:11 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 18:45:32 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 18:57:37 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 18:59:56 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 19:09:53 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4352.8599989414215 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 19:15:51 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 19:27:19 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 19:28:05 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 19:38:16 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 19:45:36 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 19:57:02 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 19:58:23 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 20:10:24 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 20:12:41 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 20:22:28 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4357.541697740555 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 20:28:29 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 20:39:53 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 20:40:39 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 20:50:53 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 20:58:11 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 21:09:36 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 21:10:57 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 21:23:05 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 21:25:26 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 21:35:13 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4360.522853136063 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 21:41:09 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 21:52:38 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 21:53:25 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 22:03:41 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 22:11:07 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 22:22:30 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 22:23:52 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 22:36:04 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 22:38:22 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 22:48:15 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4384.266046762466 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 22:54:14 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 23:05:27 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Wed Mar 27 23:06:13 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 23:16:28 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Wed Mar 27 23:23:45 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 23:35:16 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Wed Mar 27 23:36:38 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 23:48:54 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Wed Mar 27 23:51:12 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 00:01:06 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4369.089044094086 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 00:07:03 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 00:18:26 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 00:19:11 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 00:29:20 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 00:36:39 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 00:47:59 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 00:49:20 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 01:01:29 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 01:03:49 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 01:13:41 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4358.451462268829 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 01:19:42 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 01:31:04 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 01:31:51 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 01:42:04 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 01:49:27 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 02:00:44 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 02:02:04 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 02:14:15 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 02:16:34 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 02:26:25 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4363.549932718277 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 02:32:25 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 02:43:46 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 02:44:33 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 02:54:48 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 03:02:05 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 03:13:27 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 03:14:47 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 03:26:52 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 03:29:09 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 03:39:01 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4356.048223018646 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 03:45:01 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 03:56:27 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 03:57:13 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 04:07:24 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 04:14:40 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 04:26:01 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 04:27:21 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 04:39:27 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 04:41:45 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 04:51:29 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4343.73308634758 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 04:57:24 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 05:08:41 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 05:09:27 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 05:19:37 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 05:26:54 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 05:38:13 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 05:39:33 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 05:51:54 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 05:54:13 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 06:04:00 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4351.479630231857 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 06:09:56 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 06:21:08 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 06:21:54 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 06:32:01 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 06:39:18 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 06:50:41 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 06:52:01 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 07:04:08 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 07:06:26 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 07:16:14 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4333.495784282684 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 07:22:10 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 07:33:27 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 07:34:13 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 07:44:18 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 07:51:37 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 08:02:53 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 08:04:14 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 08:16:18 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 08:18:36 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 08:28:25 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4334.480452775955 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 08:34:24 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 08:45:43 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 08:46:29 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 08:56:39 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 09:03:55 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 09:15:09 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 09:16:31 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 09:28:34 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 09:30:51 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 09:40:41 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4334.104993581772 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 09:46:40 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 09:58:02 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 09:58:48 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 10:09:04 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 10:16:20 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 10:27:37 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 10:28:57 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 10:40:59 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 10:43:16 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 10:53:04 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4341.878593444824 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 10:59:00 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 11:10:19 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 11:11:05 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 11:21:18 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 11:28:37 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 11:40:01 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 11:41:23 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 11:53:33 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 11:55:52 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 12:05:39 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4353.880984783173 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 12:11:34 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 12:22:52 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 12:23:38 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 12:33:51 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 12:41:09 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 12:52:27 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 12:53:48 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 13:05:54 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 13:08:12 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 13:17:57 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4339.007148981094 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 13:23:53 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 13:35:07 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 13:35:53 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 13:46:04 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 13:53:28 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 14:04:49 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 14:06:11 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 14:18:17 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 14:20:36 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 14:30:23 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4347.920365571976 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 14:36:21 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 14:47:38 2024]  Iteration number: 50 with current cost as 0.1911904305690747 and parameters 
[-4.25816165  1.63861897 -3.14989246 -0.11650137  0.5538967  -2.77009533
  3.06858206  2.18960717  1.18552653 -1.0664706   1.52726868  1.14433298
  0.07654554 -1.87353947  0.72965951  2.88578721 -0.54533472 -0.47522853
 -2.02652895  0.72897588  1.60512561  2.83077103 -1.26457256 -0.25136617]. 
Working on 0.4 fold... 
[Thu Mar 28 14:48:23 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 14:58:30 2024]  Iteration number: 50 with current cost as 0.16174260724148254 and parameters 
[-3.45594801  1.56416815 -3.20191328 -0.11655899  0.55386    -2.77014225
  3.06855065  2.18955909  1.18551302 -1.06651289 -0.15167812  1.14430739
  1.71146428 -1.87357599  0.72962144  2.8857701  -0.54537081 -0.47524851
 -2.02657086  0.72895146  1.60511169  2.83074426 -1.26458475 -0.25138801]. 
Working on 0.6 fold... 
[Thu Mar 28 15:05:46 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 15:17:02 2024]  Iteration number: 50 with current cost as 0.16077521443884119 and parameters 
[-1.87262986  1.56921127 -3.03569939 -0.11653298  0.55388756 -2.77011237
  3.06858624  2.18959982  1.18552535 -1.06648196  2.13471238  1.14432409
 -0.56074672 -1.87354853  0.72965496  2.88578104 -0.54534246 -0.47522606
 -2.02654092  0.72897217  1.60512537  2.83077192 -1.26456788 -0.25136089]. 
Working on 0.8 fold... 
[Thu Mar 28 15:18:23 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 15:30:30 2024]  Iteration number: 50 with current cost as 0.16367358370007712 and parameters 
[-4.41628695  1.56512823 -3.07429452 -0.11650545  0.55387974 -2.77012742
  3.06861739  2.18963806  1.18556573 -1.06649112  1.54395724  1.14429186
  0.19289027 -1.87354461  0.72965709  2.88578034 -0.54532854 -0.47521226
 -2.02654596  0.72896322  1.60513255  2.83078611 -1.26457816 -0.25134379]. 
Working on 1.0 fold... 
[Thu Mar 28 15:32:48 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 15:42:38 2024]  Iteration number: 50 with current cost as 0.17407274741857107 and parameters 
[-4.13912557  1.58000377 -2.48105893 -0.11654035  0.55390796 -2.77011996
  3.06857647  2.18960925  1.18552589 -1.06648512  0.07360159  1.14433263
  1.48121401 -1.87351916  0.72967462  2.88580805 -0.54534481 -0.47522241
 -2.02654237  0.72900365  1.60513419  2.83078304 -1.26455625 -0.25133314]. 
Training complete taking 4338.334228038788 seconds. 
Discarding model... 

Training complete taking 108614.98787021637 total seconds. 
Now scoring model... 
Scoring complete taking 1.1751351356506348 seconds. 
Saved predicted values as A1-A1-CZ_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (107.50640888065394,), 'R2_train': 0.47916752983538724, 'MAE_train': 7.544477978866766, 'MSE_test': 123.74108118116132, 'R2_test': 0.25411178961277614, 'MAE_test': 8.443909410658167}. 
Saved model results as A1-A1-CZ_Full-Pauli-CRX_results.json. 
