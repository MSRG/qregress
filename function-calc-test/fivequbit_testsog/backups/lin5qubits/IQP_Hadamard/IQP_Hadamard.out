/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:53:26 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:33 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:53:50 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:02 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:18 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:31 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.00283122062683 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:46 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:02 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:15 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 17:55:28 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:42 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.20201253890991 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:57 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:12 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:25 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:39 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:54 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.14895677566528 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:07 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:23 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:35 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 17:57:50 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:04 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.12905645370483 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:58:18 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:58:34 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:47 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:00 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:15 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.83062028884888 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:29 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:59:46 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:59:58 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:00:11 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:00:27 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.49282121658325 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:00:40 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:01:00 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:01:12 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:01:26 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:40 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 74.9306960105896 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:01:55 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:02:11 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:02:24 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:02:38 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:02:54 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.1610963344574 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:03:08 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:03:24 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:03:36 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:03:51 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:04:04 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.41318893432617 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:04:19 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:04:35 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:04:48 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:05:02 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:05:17 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.40336656570435 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:30 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:05:47 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:05:59 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:12 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:06:27 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.3725094795227 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:06:41 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:06:57 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:07:09 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:07:24 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:38 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.8398187160492 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:07:53 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:08:08 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:08:21 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:08:35 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:08:50 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.59420037269592 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:09:03 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:09:20 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:09:32 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:09:47 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:10:01 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.26279282569885 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:10:16 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:10:31 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:10:43 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:10:58 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:11:13 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 73.36611151695251 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:11:28 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:11:45 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:11:57 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:12:11 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:12:29 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 75.24810290336609 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:12:44 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:13:00 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:13:12 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:13:27 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:13:41 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.53848576545715 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:13:56 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:14:11 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:14:24 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:14:38 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:14:52 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.30798387527466 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:15:06 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:15:23 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:15:34 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:15:49 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:16:03 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.59326362609863 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:16:18 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:16:33 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:16:46 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:17:00 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:17:13 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.8408727645874 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:17:28 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:17:43 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:17:57 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:18:10 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:18:26 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.85126447677612 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:18:39 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:18:56 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:19:08 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:19:23 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:19:37 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.93770146369934 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:19:52 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:20:07 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:20:20 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:20:34 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:20:49 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.97792935371399 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:21:02 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:21:19 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:21:31 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:21:46 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:22:00 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.20865631103516 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:22:13 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:22:30 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:22:42 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:22:57 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:23:11 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.71057868003845 seconds. 
Discarding model... 

Training complete taking 1793.3660838603973 total seconds. 
Now scoring model... 
Scoring complete taking 0.8457624912261963 seconds. 
Saved predicted values as IQP_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (27.70890346749304,), 'R2_train': 0.8657596622490826, 'MAE_train': 3.7149688782716828, 'MSE_test': 29.353778759086744, 'R2_test': 0.8230608840837329, 'MAE_test': 3.5003653003944164}. 
Saved model results as IQP_Hadamard_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 12:29:07 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:29:14 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:29:29 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:29:41 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:29:54 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:30:09 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.24723291397095 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:30:23 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:30:38 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:30:50 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:31:05 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:31:18 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.18693614006042 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:31:32 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:31:47 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:31:59 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:32:14 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:32:28 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.18629431724548 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:32:41 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:32:56 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:33:09 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:33:25 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:33:38 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.68203353881836 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:33:52 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:34:08 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:34:20 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:34:33 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:34:47 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 68.54776096343994 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:35:00 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:35:17 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:35:29 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:35:42 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:35:56 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.26479649543762 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:36:11 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:36:26 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:36:38 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:36:51 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:37:06 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 68.74052715301514 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:37:19 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:37:35 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:37:46 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:38:00 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:38:15 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 68.99404430389404 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:38:28 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:38:43 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:38:55 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:39:10 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:39:24 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 68.80696272850037 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:39:37 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:39:52 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:40:06 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:40:19 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:40:33 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.15388369560242 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:40:46 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:41:02 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:41:15 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:41:28 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:41:42 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.34201622009277 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:41:56 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:42:12 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:42:24 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:42:38 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:42:53 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.50945711135864 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:43:07 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:43:23 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:43:34 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:43:48 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:44:01 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.18967485427856 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:44:16 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:44:31 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:44:43 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:44:57 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:45:12 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 68.85104870796204 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:45:25 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:45:40 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:45:52 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:46:07 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:46:21 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.35967588424683 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:46:35 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:46:50 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:47:02 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:47:17 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:47:30 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.14312863349915 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:47:44 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:47:59 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:48:12 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:48:26 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:48:39 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.21257472038269 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:48:53 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:49:09 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:49:21 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:49:35 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:49:48 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 68.98377919197083 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:50:02 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:50:18 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:50:30 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:50:44 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:50:57 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.43500661849976 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:51:12 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:51:27 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:51:39 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:51:53 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:52:08 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.58848547935486 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:52:22 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:52:37 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:52:49 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:53:03 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:53:17 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.13101363182068 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:53:31 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:53:46 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:53:58 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:54:13 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:54:26 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.08753085136414 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:54:40 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:54:55 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:55:09 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:55:22 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:55:36 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.21228051185608 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:55:49 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:56:06 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:56:18 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:56:31 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:56:45 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 68.9311089515686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:56:58 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:57:15 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:57:27 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Thu Apr  4 12:57:41 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Thu Apr  4 12:57:54 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 69.46018862724304 seconds. 
Discarding model... 

Training complete taking 1734.248407125473 total seconds. 
Now scoring model... 
Scoring complete taking 0.8549206256866455 seconds. 
Saved predicted values as IQP_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (27.70890346749304,), 'R2_train': 0.8657596622490826, 'MAE_train': 3.7149688782716828, 'MSE_test': 29.353778759086744, 'R2_test': 0.8230608840837329, 'MAE_test': 3.5003653003944164}. 
Saved model results as IQP_Hadamard_results.json. 
