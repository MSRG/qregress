/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:30:00 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:08 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:30:27 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:30:44 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:31:04 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:31:21 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.81267762184143 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:31:36 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:31:55 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:32:11 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:32:32 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:32:49 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.51254963874817 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:33:05 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:33:24 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:33:39 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:34:06 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:34:23 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 93.94357705116272 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:34:39 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:34:58 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:15 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:35:34 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:35:51 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 87.86811637878418 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:07 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:36:26 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:36:41 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:37:02 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:37:19 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 87.96244430541992 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:35 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:37:54 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:09 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:30 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:47 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 87.7059874534607 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:03 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:25 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:41 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:02 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:19 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 91.55788731575012 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:34 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:53 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:09 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:30 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:47 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.15780830383301 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:02 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:21 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:37 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:58 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:15 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.15314316749573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:30 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:49 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:05 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:26 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:41 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.02986478805542 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:59 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:18 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:33 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:45:54 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:10 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.8658995628357 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:27 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:47 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:03 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:27 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:42 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 91.81624937057495 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:59 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:18 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:34 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:55 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:10 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.30121636390686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:27 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:46 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:02 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:23 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:38 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.50713872909546 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:56 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:15 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:31 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:52 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:07 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.25983786582947 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:24 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:42 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:59 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:21 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:37 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.88137745857239 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:54 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:12 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:29 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:49 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:05 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 86.58185362815857 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:23 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:40 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:57 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:18 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:34 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.92692422866821 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:56:51 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:09 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:26 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:57:47 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:02 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.19034886360168 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:58:20 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:58:38 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:56 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:17 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:32 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.9649453163147 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:00:04 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:00:27 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:00:42 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 18:01:03 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:20 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 108.05206537246704 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:01:36 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:01:55 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:02:10 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 18:02:32 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:02:49 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.23678517341614 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:03:05 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:03:24 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:03:40 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 18:04:03 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:04:20 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 90.76487684249878 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:04:36 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:04:56 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:05:11 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 18:05:32 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:05:49 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.3534677028656 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:06:05 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:06:24 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:06:40 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 18:07:01 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:19 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.04473543167114 seconds. 
Discarding model... 

Training complete taking 2246.4529423713684 total seconds. 
Now scoring model... 
Scoring complete taking 0.921142578125 seconds. 
Saved predicted values as A1-A1-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (108.85860265806873,), 'R2_train': 0.4726166048015691, 'MAE_train': 7.646677513523848, 'MSE_test': 114.6270450613636, 'R2_test': 0.3090495033123021, 'MAE_test': 8.13478407161976}. 
Saved model results as A1-A1-CZ_Hadamard_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 11:29:55 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:30:05 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:30:22 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:30:39 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:31:00 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:31:16 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.63998341560364 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:31:34 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:31:51 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:32:08 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:32:30 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:32:45 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.23943495750427 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:33:03 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:33:21 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:33:38 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:33:59 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:34:14 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.02535247802734 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:34:31 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:34:49 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:35:06 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:35:25 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:35:43 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.32479119300842 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:36:00 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:36:17 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:36:35 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:36:54 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:37:12 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.02922940254211 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:37:29 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:37:46 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:38:03 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:38:23 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:38:40 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.41973185539246 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:38:56 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:39:15 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:39:32 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:39:51 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:40:09 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.39503908157349 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:40:24 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:40:43 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:41:00 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:41:20 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:41:37 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.95748901367188 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:41:53 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:42:18 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:42:35 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:42:54 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:43:12 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 94.32124257087708 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:43:29 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:43:47 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:44:04 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:44:23 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:44:40 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.7637894153595 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:44:56 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:45:15 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:45:32 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:45:52 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:46:09 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.86379718780518 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:46:25 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:46:44 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:47:04 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:47:24 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:47:45 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 95.66727828979492 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:48:02 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:48:20 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:48:37 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:48:56 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:49:13 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.36169767379761 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:49:30 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:49:48 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:50:05 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:50:25 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:50:42 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.44724130630493 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:50:59 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:51:17 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:51:34 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:51:54 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:52:11 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.05434727668762 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:52:27 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:52:46 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:53:03 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:53:22 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:53:40 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.06435012817383 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:53:56 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:54:15 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:54:33 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:54:52 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:55:09 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.3589859008789 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:55:25 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:55:44 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:56:01 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:56:21 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:56:38 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.70952367782593 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:56:54 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:57:12 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:57:30 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:57:50 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:58:10 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 91.73862147331238 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:58:25 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:58:45 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:59:02 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 11:59:21 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:59:39 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.81438875198364 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:59:54 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:00:13 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:00:30 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 12:00:50 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:01:07 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.57115197181702 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:01:23 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:01:42 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:01:59 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 12:02:19 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:02:36 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.10081505775452 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:02:52 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:03:11 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:03:27 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 12:03:48 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:04:05 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.36351490020752 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:04:20 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:04:39 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:04:55 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 12:05:16 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:05:33 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.90511465072632 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:05:49 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:06:08 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:06:24 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Thu Apr  4 12:06:45 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:07:02 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.65670156478882 seconds. 
Discarding model... 

Training complete taking 2234.7945556640625 total seconds. 
Now scoring model... 
Scoring complete taking 0.9112048149108887 seconds. 
Saved predicted values as A1-A1-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (108.85860265806873,), 'R2_train': 0.4726166048015691, 'MAE_train': 7.646677513523848, 'MSE_test': 114.6270450613636, 'R2_test': 0.3090495033123021, 'MAE_test': 8.13478407161976}. 
Saved model results as A1-A1-CZ_Hadamard_results.json. 
