/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:37:33 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:36 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:37:47 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:37:57 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:05 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:15 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.1454131603241 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:38:21 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:38:31 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:41 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:50 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:58 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 43.743770360946655 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:05 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:16 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:26 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:39:34 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:42 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.666879415512085 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:50 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:00 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:09 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:19 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:27 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.097252368927 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:34 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:45 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:55 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:04 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:13 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 46.10783886909485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:41:20 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:30 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:40 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:49 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:57 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.07689046859741 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:04 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:15 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:26 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:34 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:42:43 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 46.22558236122131 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:50 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:00 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:10 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:20 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:28 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.44673681259155 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:35 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:45 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:55 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:04 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:12 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.99818682670593 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:20 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:30 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:40 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:49 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:57 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.33018755912781 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:04 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:15 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:25 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:45:33 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:45:41 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.30850672721863 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:49 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:59 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:09 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:18 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:27 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.078049182891846 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:33 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:44 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:54 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:02 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:11 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.15742802619934 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:18 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:28 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:38 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:48 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:56 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.6168737411499 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:03 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:14 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:24 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:32 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:48:41 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.1448974609375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:48 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:58 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:08 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:49:17 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:26 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 43.94034719467163 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:32 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:42 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:53 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:02 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:10 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.58795475959778 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:18 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:28 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:38 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:47 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:55 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.16153120994568 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:02 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:12 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:23 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:31 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:51:40 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.46319842338562 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:47 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:57 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:07 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:17 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:25 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.15935015678406 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:32 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:42 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:53 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:01 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:10 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.95928382873535 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:17 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:53:27 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:37 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:46 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:55 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.71382188796997 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:01 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:11 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:22 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:31 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:39 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.42978048324585 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:47 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:57 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:07 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:55:16 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:24 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.399715423583984 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:31 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:41 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:52 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:00 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:09 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.60968995094299 seconds. 
Discarding model... 

Training complete taking 1119.5699911117554 total seconds. 
Now scoring model... 
Scoring complete taking 0.7938284873962402 seconds. 
Saved predicted values as A2-A2-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (149.3261673368832,), 'R2_train': 0.27656483549160005, 'MAE_train': 10.659776152134427, 'MSE_test': 152.9774006211684, 'R2_test': 0.07788069661392127, 'MAE_test': 10.807596130858311}. 
Saved model results as A2-A2-CNOT_Hadamard_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 12:22:05 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:22:10 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:22:22 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:22:33 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:22:44 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:22:54 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 53.73257231712341 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:23:02 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:23:15 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:23:27 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:23:36 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:23:47 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 52.71998643875122 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:23:55 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:24:06 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:24:20 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:24:29 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:24:40 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 53.206228494644165 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:24:48 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:25:00 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:25:13 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:25:22 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:25:32 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 51.317339181900024 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:25:41 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:25:53 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:26:04 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:26:15 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:26:25 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 56.89996910095215 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:26:36 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:26:49 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:27:01 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:27:12 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:27:22 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 53.04835367202759 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:27:30 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:27:54 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:28:05 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:28:16 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:28:26 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 64.27764654159546 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:28:34 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:28:47 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:28:58 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:29:09 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:29:19 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 53.137685775756836 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:29:27 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:29:40 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:29:51 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:30:01 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:30:13 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 53.815858364105225 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:30:21 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:30:32 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:30:48 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:30:58 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:31:07 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 55.8556170463562 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:31:17 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:31:28 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:31:41 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:31:51 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:32:04 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 55.1540150642395 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:32:13 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:32:25 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:32:36 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:32:47 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:32:57 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 53.02997136116028 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:33:05 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:33:18 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:33:29 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:33:42 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:33:53 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 55.88087606430054 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:34:01 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:34:15 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:34:27 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:34:37 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:34:48 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 54.81525421142578 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:34:55 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:35:07 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:35:20 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:35:30 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:35:41 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 53.12483525276184 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:35:49 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:36:00 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:36:13 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:36:23 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:36:32 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 51.74476957321167 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:36:42 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:36:53 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:37:05 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:37:16 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:37:26 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 53.15715980529785 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:37:33 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:37:46 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:37:58 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:38:07 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:38:19 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 53.593509912490845 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:38:27 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:38:40 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:38:52 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:39:01 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:39:13 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 54.18988919258118 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:39:21 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:39:33 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:39:46 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:39:56 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:40:05 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 53.162185192108154 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:40:14 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:40:26 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:40:38 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:40:49 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:40:59 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 51.89431381225586 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:41:06 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:41:19 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:41:31 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:41:42 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:41:51 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 52.92046332359314 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:41:59 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:42:13 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:42:25 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:42:34 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:42:46 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 54.0724937915802 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:42:53 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:43:05 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:43:18 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:43:27 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:43:37 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 53.20841932296753 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:43:47 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:43:58 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:44:11 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:44:21 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:44:30 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 51.680405378341675 seconds. 
Discarding model... 

Training complete taking 1349.6409120559692 total seconds. 
Now scoring model... 
Scoring complete taking 0.8921098709106445 seconds. 
Saved predicted values as A2-A2-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (149.3261673368832,), 'R2_train': 0.27656483549160005, 'MAE_train': 10.659776152134427, 'MSE_test': 152.9774006211684, 'R2_test': 0.07788069661392127, 'MAE_test': 10.807596130858311}. 
Saved model results as A2-A2-CNOT_Hadamard_results.json. 
