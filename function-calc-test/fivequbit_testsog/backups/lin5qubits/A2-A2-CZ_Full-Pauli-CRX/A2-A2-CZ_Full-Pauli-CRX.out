/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/opt/miniconda/bin/python: can't open file '/home/gjones/scratch/lin5qubits/main.py': [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/home/gjones/scratch/lin5qubits/main.py", line 19, in <module>
    from quantum.Quantum import QuantumRegressor
ModuleNotFoundError: No module named 'quantum'
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Wed Mar 27 09:34:31 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 09:34:58 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 09:46:53 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Wed Mar 27 09:56:28 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 27 10:07:57 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 10:20:58 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Wed Mar 27 10:22:56 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 27 10:35:31 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 10:52:35 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5151.983335494995 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 11:00:50 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 11:12:32 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Wed Mar 27 11:22:05 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 27 11:33:39 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 11:46:44 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Wed Mar 27 11:48:41 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 27 12:01:15 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 12:18:19 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5141.544081926346 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 12:26:31 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 12:38:15 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Wed Mar 27 12:47:48 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 27 12:59:16 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 13:12:22 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Wed Mar 27 13:14:18 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 27 13:26:53 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 13:44:09 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5152.9336631298065 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 13:52:23 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 14:04:04 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Wed Mar 27 14:13:37 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 27 14:25:08 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 14:38:06 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Wed Mar 27 14:40:04 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 27 14:52:41 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 15:09:56 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5148.483069658279 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 15:18:12 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 15:29:54 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Wed Mar 27 15:39:28 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 27 15:51:02 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 16:04:07 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Wed Mar 27 16:06:06 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 27 16:18:44 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 16:35:57 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5162.634937286377 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 16:44:14 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 16:55:54 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Wed Mar 27 17:05:25 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 27 17:16:56 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 17:30:00 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Wed Mar 27 17:31:57 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 27 17:44:37 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 18:01:43 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5142.159608364105 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 18:09:57 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 18:21:42 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Wed Mar 27 18:31:19 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 27 18:42:51 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 18:55:54 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Wed Mar 27 18:57:52 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 27 19:10:26 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 19:27:38 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5158.6690056324005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 19:35:56 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 19:47:47 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Wed Mar 27 19:57:20 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 27 20:08:53 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 20:21:53 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Wed Mar 27 20:23:50 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 27 20:36:28 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 20:53:44 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5167.252584934235 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 21:02:03 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 21:13:50 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Wed Mar 27 21:23:24 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 27 21:34:55 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 21:48:02 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Wed Mar 27 21:50:00 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 27 22:02:41 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 22:20:03 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5177.476426124573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 22:28:20 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 22:40:05 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Wed Mar 27 22:49:38 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 27 23:01:14 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 23:14:22 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Wed Mar 27 23:16:23 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 27 23:29:04 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 27 23:46:16 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5169.183157444 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 23:54:30 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 00:06:18 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 00:15:56 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 00:27:29 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 00:40:33 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 00:42:31 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 00:55:05 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 01:12:19 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5166.801331043243 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 01:20:36 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 01:32:21 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 01:41:56 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 01:53:34 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 02:06:37 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 02:08:37 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 02:21:19 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 02:38:36 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5177.348503828049 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 02:46:54 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 02:58:38 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 03:08:10 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 03:19:42 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 03:32:45 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 03:34:43 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 03:47:31 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 04:04:43 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5168.084819078445 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 04:13:01 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 04:24:44 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 04:34:15 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 04:45:53 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 04:58:58 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 05:00:55 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 05:13:33 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 05:30:45 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5160.717107772827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 05:39:02 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 05:50:54 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 06:00:30 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 06:12:03 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 06:25:05 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 06:27:02 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 06:39:35 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 06:56:49 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5161.530448436737 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 07:05:04 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 07:16:48 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 07:26:22 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 07:37:54 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 07:51:03 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 07:53:02 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 08:05:38 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 08:22:51 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5165.669149398804 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 08:31:10 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 08:42:55 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 08:52:29 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 09:03:57 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 09:17:02 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 09:18:59 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 09:31:39 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 09:48:54 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5160.862882614136 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 09:57:10 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 10:08:57 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 10:18:29 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 10:30:04 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 10:43:10 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 10:45:08 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 10:57:45 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 11:14:52 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5157.721781253815 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 11:23:08 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 11:34:56 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 11:44:37 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 11:56:09 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 12:09:12 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 12:11:10 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 12:23:44 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 12:40:54 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5163.191910743713 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 12:49:11 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 13:00:59 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 13:10:33 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 13:22:08 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 13:35:13 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 13:37:11 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 13:49:48 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 14:06:54 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5153.840187549591 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 14:15:05 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 14:26:48 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 14:36:20 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 14:47:49 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 15:00:49 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 15:02:45 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 15:15:20 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 15:32:25 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5134.348176002502 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 15:40:39 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 15:52:28 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 16:02:00 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 16:13:28 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 16:26:28 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 16:28:26 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 16:41:00 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 16:58:08 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5143.244555234909 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 17:06:22 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 17:18:05 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 17:27:38 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 17:39:10 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 17:52:21 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 17:54:18 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 18:06:54 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 18:24:00 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5148.968882799149 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 18:32:12 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 18:44:02 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 18:53:40 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 19:05:12 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 19:18:12 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 19:20:09 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 19:32:42 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 19:49:57 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5159.685793638229 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 19:58:12 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 20:09:56 2024]  Iteration number: 50 with current cost as 0.2922078045336542 and parameters 
[-3.09415701  4.73164509 -1.47568659 -0.11652884  0.55388734 -2.7701066
  3.06858554  2.18960401  1.18552103 -1.06648301 -3.18563086  1.14432365
  4.59152848 -1.87354751  0.729651    2.88578558 -0.54534443 -0.47522404
 -2.02654215  0.72897209  1.60512665  2.83076993 -1.2645669  -0.25135975]. 
Working on 0.4 fold... 
[Thu Mar 28 20:19:27 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 28 20:30:58 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 20:43:56 2024]  Iteration number: 50 with current cost as 0.25028356184581535 and parameters 
[-1.49271938  4.91928793 -4.19215574 -0.11653319  0.55387895 -2.77012111
  3.06857374  2.1895971   1.1855089  -1.06648747 -2.01483792  1.14431819
  1.7001518  -1.87358851  0.72964705  2.88578345 -0.54535297 -0.47526692
 -2.02655461  0.72897633  1.60511958  2.8307697  -1.26460023 -0.25136756]. 
Working on 0.8 fold... 
[Thu Mar 28 20:45:53 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 28 20:58:32 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 28 21:15:44 2024]  Iteration number: 50 with current cost as 0.26212644313578976 and parameters 
[-2.44446153  4.71579911 -4.53099547 -0.11664982  0.55369834 -2.77009017
  3.06856943  2.18947255  1.18546026 -1.06655645 -3.11445612  1.14423283
  1.54824009 -1.87365868  0.72956414  2.88556941 -0.54552053 -0.47531374
 -2.0266516   0.72888143  1.604928    2.83069652 -1.26464302 -0.25137911]. 
Training complete taking 5147.890767812729 seconds. 
Discarding model... 

Training complete taking 128942.22749042511 total seconds. 
Now scoring model... 
Scoring complete taking 1.2164232730865479 seconds. 
Saved predicted values as A2-A2-CZ_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (163.36687467342648,), 'R2_train': 0.20854232073093615, 'MAE_train': 11.019064817228127, 'MSE_test': 161.7547134967146, 'R2_test': 0.024972687969928464, 'MAE_test': 10.776711769519038}. 
Saved model results as A2-A2-CZ_Full-Pauli-CRX_results.json. 
