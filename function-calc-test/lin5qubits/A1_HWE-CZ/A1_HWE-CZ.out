test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Sun Mar 17 23:21:17 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 23:21:20 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:21:41 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:21:59 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:22:16 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:22:36 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.48661375045776 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 23:22:55 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:23:15 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:23:35 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:23:52 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:24:12 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.82084703445435 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 23:24:31 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:24:51 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:25:10 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:25:27 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:25:47 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.55962800979614 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 23:26:06 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:26:26 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:26:45 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:27:03 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:27:23 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.51636075973511 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 23:27:42 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:28:01 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

[Sun Mar 17 23:28:20 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:28:38 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:28:58 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.85102272033691 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 23:29:17 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:29:37 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:29:56 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:30:13 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:30:33 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.01459884643555 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 23:30:52 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:31:12 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:31:31 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:31:48 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:32:09 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.49955582618713 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 23:32:27 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:32:48 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:33:06 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:33:24 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:33:44 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.68376016616821 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 23:34:03 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:34:23 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:34:42 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:35:00 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:35:21 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 97.13428997993469 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 23:35:40 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Sun Mar 17 23:36:00 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:36:19 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:36:36 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:36:57 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 96.07362151145935 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 23:37:16 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:37:36 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:37:55 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:38:13 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:38:34 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 96.79882574081421 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 23:38:53 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:39:13 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:39:32 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:39:50 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:40:10 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.95519256591797 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 23:40:29 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:40:49 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:41:09 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:41:26 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:41:47 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 97.48775172233582 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 23:42:06 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:42:26 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:42:46 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:43:03 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:43:23 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.90736842155457 seconds. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 23:43:42 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:44:02 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:44:21 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:44:38 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:44:59 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.95211172103882 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 23:45:18 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:45:39 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:45:58 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:46:17 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:46:37 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 97.60501790046692 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 23:46:56 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:47:15 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:47:34 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:47:51 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:48:11 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.02187490463257 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 23:48:30 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:48:50 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:49:09 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:49:26 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:49:46 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.88966608047485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 23:50:06 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:50:26 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:50:44 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:51:02 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sun Mar 17 23:51:22 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.03442001342773 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 23:51:41 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:52:01 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:52:20 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:52:37 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:52:57 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.00495386123657 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 23:53:16 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:53:36 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:53:55 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:54:12 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:54:32 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.77569651603699 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 23:54:51 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:55:12 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:55:31 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:55:48 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:56:08 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.83979105949402 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 23:56:26 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:56:46 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:57:05 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Sun Mar 17 23:57:22 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:57:42 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.10650062561035 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 23:58:00 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:58:21 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Sun Mar 17 23:58:40 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Sun Mar 17 23:58:57 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Sun Mar 17 23:59:18 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 96.22909569740295 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 23:59:37 2024]  Iteration number: 0 with current cost as 0.2235799633317808 and parameters 
[-5.05559911  4.4394357  -0.37269761 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648323  0.60271503  1.14432438
  1.31029899 -1.8735468   0.72965073]. 
Working on 0.4 fold... 
[Sun Mar 17 23:59:57 2024]  Iteration number: 0 with current cost as 0.1098345139573697 and parameters 
[-4.85174159  4.25871758 -0.56045239 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552007 -1.06648317  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Mar 18 00:00:15 2024]  Iteration number: 0 with current cost as 0.16031899287447832 and parameters 
[-4.79306926  4.06841705 -0.50588627 -0.11653103  0.55388715 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029891 -1.8735468   0.72965073]. 
Working on 0.8 fold... 
[Mon Mar 18 00:00:33 2024]  Iteration number: 0 with current cost as 0.15314707397066454 and parameters 
[-4.7732601   4.11256144 -0.57259058 -0.11653103  0.55388708 -2.77010912
  3.06858491  2.18960145  1.18551998 -1.06648323  0.6027151   1.14432445
  1.31029899 -1.87354687  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Mar 18 00:00:53 2024]  Iteration number: 0 with current cost as 0.17611878263026182 and parameters 
[-4.75327109  4.06117591 -0.56456153 -0.11653103  0.55388708 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648316  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.65062427520752 seconds. 
Discarding model... 

Training complete taking 2391.899528503418 total seconds. 
Now scoring model... 
Scoring complete taking 0.296555757522583 seconds. 
Saved predicted values as A1_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (2.3552402522004963,), 'R2_train': 0.988589651434209, 'MAE_train': 1.143022736923252, 'MSE_test': 1.7886810598741238, 'R2_test': 0.9892181634266652, 'MAE_test': 1.1600962879415873}. 
Saved model results as A1_HWE-CZ_results.json. 
