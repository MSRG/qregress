/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/opt/miniconda/bin/python: can't open file '/home/gjones/scratch/lin5qubits/main.py': [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/home/gjones/scratch/lin5qubits/main.py", line 19, in <module>
    from quantum.Quantum import QuantumRegressor
ModuleNotFoundError: No module named 'quantum'
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Wed Mar 27 09:34:58 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 09:40:13 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 09:45:29 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 09:58:13 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 10:07:10 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 10:16:09 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2606.7331895828247 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 10:23:39 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 10:28:53 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 10:41:31 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 10:50:24 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 10:59:20 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2590.301954269409 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 11:06:46 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 11:11:57 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 11:24:32 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 11:33:27 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 11:42:24 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2583.53178524971 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 11:49:52 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 11:55:03 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 12:07:41 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 12:16:39 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 12:25:34 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2588.115234851837 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 12:32:59 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 12:38:11 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 12:50:46 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 12:59:40 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 13:08:34 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2580.4286391735077 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 13:15:58 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 13:21:12 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 13:33:47 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 13:42:45 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 13:51:39 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2586.01717543602 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 13:59:08 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 14:04:18 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 14:16:51 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 14:25:46 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 14:34:39 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2579.9365935325623 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 14:42:05 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 14:47:15 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 14:59:55 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 15:08:49 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 15:17:45 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2584.6483447551727 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 15:25:08 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 15:30:19 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 15:43:01 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 15:51:55 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 16:00:47 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2583.2584455013275 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 16:08:15 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 16:13:26 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 16:26:03 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 16:34:57 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 16:43:52 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2583.713121175766 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 16:51:16 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 16:56:27 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 17:09:04 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 17:18:00 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 17:26:54 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2582.423187017441 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 17:34:18 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 17:39:30 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 17:52:16 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 18:01:10 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 18:10:05 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2591.795947790146 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 18:17:29 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 18:22:41 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 18:35:22 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 18:44:14 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 18:53:12 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2585.5745284557343 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 19:00:38 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 19:05:51 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 19:18:26 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 19:27:22 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 19:36:20 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2588.007478237152 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 19:43:49 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 19:49:01 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 20:01:44 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 20:10:39 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 20:19:34 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2594.851373910904 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 20:26:58 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 20:32:08 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 20:44:43 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 20:53:38 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 21:02:33 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2579.6588745117188 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 21:09:58 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 21:15:09 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 21:27:49 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 21:36:43 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 21:45:41 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2587.359879016876 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 21:53:08 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 21:58:20 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 22:10:56 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 22:19:52 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 22:28:49 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2587.235755443573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 22:36:13 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 22:41:26 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 22:54:08 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 23:03:05 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 23:11:57 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2589.3688616752625 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 23:19:22 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 27 23:24:36 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 27 23:37:13 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Wed Mar 27 23:46:10 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 27 23:55:06 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2588.199428319931 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 00:02:30 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Thu Mar 28 00:07:41 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 28 00:20:17 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Thu Mar 28 00:29:10 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Thu Mar 28 00:38:02 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2575.8668456077576 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 00:45:25 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Thu Mar 28 00:50:35 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 28 01:03:11 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Thu Mar 28 01:12:06 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Thu Mar 28 01:20:58 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2576.0278103351593 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 01:28:22 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Thu Mar 28 01:33:34 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 28 01:46:15 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Thu Mar 28 01:55:12 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Thu Mar 28 02:04:03 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2586.1811094284058 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 02:11:28 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Thu Mar 28 02:16:39 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 28 02:29:20 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Thu Mar 28 02:38:15 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Thu Mar 28 02:47:09 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2584.938846349716 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 02:54:33 2024]  Iteration number: 0 with current cost as 0.5502979015750127 and parameters 
[-1.74536136  2.23743486 -2.12427941 -0.1165308   0.55388708 -2.7701092
  3.06858476  2.18960145  1.18552021 -1.06648308  0.60271533  1.14432445
  1.31029921 -1.87354657  0.7296508   2.88578419 -0.54534335 -0.47522463
 -2.02654263  0.72897347  1.60512664  2.83077107 -1.2645671  -0.25136082
 -2.39279195 -2.27309752  3.13337177  2.54856981 -0.67550765 -2.69002202]. 
Working on 0.4 fold... 
[Thu Mar 28 02:59:46 2024]  Iteration number: 0 with current cost as 0.4933882541109627 and parameters 
[-1.50129222  2.23743432 -2.12427964 -0.11653103  0.55388677 -2.77010929
  3.06858467  2.1896013   1.18551998 -1.06648324  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965049  2.88578404 -0.54534366 -0.47522501
 -2.02654256  0.72897354  1.60512648  2.83077076 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 28 03:12:24 2024]  Iteration number: 0 with current cost as 0.19763134127909535 and parameters 
[64.41734328  2.23743464 -2.12426945 -0.11652084  0.55388708 -2.77013954
  3.06858498  2.18959126  1.18553018 -1.06649328  0.60272529  1.14432445
  1.31029899 -1.87353661  0.7296508   2.88578419 -0.54534335 -0.47521466
 -2.0265526   0.7289737   1.60512664  2.83076088 -1.2645671  -0.25135086
 -2.39278199 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.8 fold... 
[Thu Mar 28 03:21:16 2024]  Iteration number: 0 with current cost as 0.2013448034758812 and parameters 
[ 1.53284567  2.23743464 -2.12427964 -0.11653103  0.55388633 -2.77011047
  3.06858423  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432295
  1.31029899 -1.8735468   0.72965005  2.88578419 -0.54534335 -0.4752241
 -2.02654315  0.7289737   1.60512664  2.83077032 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Thu Mar 28 03:30:12 2024]  Iteration number: 0 with current cost as 0.5086763801419845 and parameters 
[-1.61121048  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010931
  3.06858481  2.18960145  1.18551998 -1.06648325  0.6027151   1.14432428
  1.31029899 -1.8735468   0.72965064  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077073 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Training complete taking 2585.406864643097 seconds. 
Discarding model... 

Training complete taking 64649.58185219765 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 2.4698262214660645 seconds. 
Saved predicted values as M-M-CZ_Full-CRX_predicted_values.csv
Model scores: {'MSE_train': (322.73150772525196,), 'R2_train': -0.5635258410974684, 'MAE_train': 16.553766459728568, 'MSE_test': 301.15155920189375, 'R2_test': -0.8152855575874847, 'MAE_test': 16.304477346428968}. 
Saved model results as M-M-CZ_Full-CRX_results.json. 
