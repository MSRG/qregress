test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Sun Mar 17 02:59:03 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 02:59:16 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 02:59:42 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:00:00 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:00:23 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:00:46 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 113.09166145324707 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 03:01:09 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:01:34 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:01:52 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:02:15 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:02:38 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 113.1563925743103 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 03:03:02 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:03:27 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:03:45 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:04:08 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:04:31 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 112.32204246520996 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 03:04:54 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:05:20 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:05:38 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:06:01 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sun Mar 17 03:06:24 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 113.30173134803772 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 03:06:47 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:07:13 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:07:31 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:07:54 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:08:16 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 112.0967845916748 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 03:08:39 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:09:04 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:09:22 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:09:45 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:10:08 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 111.1593804359436 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 03:10:30 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:10:55 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:11:13 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:11:36 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:11:58 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 110.64392566680908 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 03:12:21 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:12:46 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:13:04 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:13:26 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:13:48 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 109.78254652023315 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 03:14:11 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:14:36 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:14:54 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:15:16 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:15:39 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 110.7568633556366 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 03:16:01 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:16:26 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:16:44 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:17:07 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:17:30 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 110.93981218338013 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 03:17:53 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:18:19 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:18:37 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:19:00 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:19:23 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 112.92859387397766 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 03:19:46 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:20:11 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:20:29 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:20:52 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:21:15 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 112.29042053222656 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.2 fold... 
[Sun Mar 17 03:21:38 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:22:03 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:22:21 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:22:43 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:23:05 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 110.24635076522827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 03:23:28 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:23:53 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:24:11 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:24:34 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:24:57 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 111.45852160453796 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 03:25:19 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:25:44 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:26:02 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:26:25 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:26:48 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 111.27926278114319 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 03:27:11 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:27:36 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:27:54 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:28:17 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:28:40 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 111.95375370979309 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 03:29:03 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Sun Mar 17 03:29:28 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:29:46 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:30:09 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:30:32 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 111.6039879322052 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 03:30:55 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:31:20 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:31:37 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:32:00 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:32:23 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 111.18545913696289 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 03:32:46 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:33:11 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:33:28 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:33:51 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:34:14 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 110.60337209701538 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 03:34:36 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:35:01 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:35:18 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:35:41 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:36:04 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 110.26894354820251 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 03:36:27 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:36:52 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Sun Mar 17 03:37:10 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:37:32 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:37:54 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 110.58445715904236 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 03:38:17 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:38:42 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:39:00 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:39:22 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:39:45 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 110.93742060661316 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 03:40:08 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:40:33 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:40:51 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:41:14 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:41:37 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 111.43706226348877 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 03:42:00 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:42:25 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:42:43 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 17 03:43:05 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:43:28 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 111.61055564880371 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 03:43:51 2024]  Iteration number: 0 with current cost as 0.3700387255470995 and parameters 
[-1.82176683  2.23743458 -2.12427953 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648308  0.6027151   1.14432445
  1.31029904 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 17 03:44:16 2024]  Iteration number: 0 with current cost as 0.3122912106762491 and parameters 
[-1.54439865  2.23743459 -2.12427959 -0.11653103  0.55388713 -2.77010902
  3.06858493  2.18960145  1.18552003 -1.06648313  0.60271515  1.1443244
  1.31029903 -1.87354675  0.72965075  2.88578424 -0.5453433  -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 17 03:44:34 2024]  Iteration number: 0 with current cost as 0.3315072595772406 and parameters 
[-1.43602935  2.23743458 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534341 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Sun Mar 17 03:44:57 2024]  Iteration number: 0 with current cost as 0.33672967186451364 and parameters 
[-1.41170488  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.60271516  1.14432445
  1.31029904 -1.87354674  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 17 03:45:20 2024]  Iteration number: 0 with current cost as 0.33971857161021435 and parameters 
[-1.40907062  2.23743464 -2.12427958 -0.11653103  0.55388702 -2.77010909
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674  0.72965074  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 111.77658653259277 seconds. 
Discarding model... 

Training complete taking 2787.416239261627 total seconds. 
Now scoring model... 
Scoring complete taking 0.36116957664489746 seconds. 
Saved predicted values as A1-A1-CZ_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (206.93879274676516,), 'R2_train': -0.0025489989050868633, 'MAE_train': 12.57727151849314, 'MSE_test': 191.37228842545193, 'R2_test': -0.15355654216717363, 'MAE_test': 12.01322042722634}. 
Saved model results as A1-A1-CZ_Modified-Pauli-CRZ_results.json. 
