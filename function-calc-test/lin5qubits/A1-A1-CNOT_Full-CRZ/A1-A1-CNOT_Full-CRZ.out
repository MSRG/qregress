runall.sh: line 11: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Thu Mar 14 07:15:01 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 14 07:16:00 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 07:17:42 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 07:19:40 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 07:23:03 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 07:25:42 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 698.8180963993073 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 14 07:27:38 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 07:29:20 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 07:31:16 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 07:34:40 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 07:37:18 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 695.3003947734833 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 14 07:39:13 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 07:40:54 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 07:42:49 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 07:46:11 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 07:48:48 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 690.2158570289612 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 14 07:50:43 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 07:52:24 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 07:54:19 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 07:57:38 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 08:00:16 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 687.5382976531982 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 14 08:02:10 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 08:03:51 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 08:05:46 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 08:09:10 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 08:11:48 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 692.5268330574036 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 14 08:13:43 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 08:15:23 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 08:17:17 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 08:20:39 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 08:23:17 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 689.0655417442322 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 14 08:25:13 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Thu Mar 14 08:26:54 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 08:28:51 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 08:32:12 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 08:34:49 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 691.7467589378357 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 14 08:36:44 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 08:38:25 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 08:40:19 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 08:43:37 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 08:46:15 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 686.4629380702972 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 14 08:48:11 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 08:49:51 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 08:51:47 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 08:55:08 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 08:57:49 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 693.6045265197754 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 14 08:59:44 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 09:01:23 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Thu Mar 14 09:03:18 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 09:06:37 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 09:09:15 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 685.8500409126282 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 14 09:11:10 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 09:12:52 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 09:14:50 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 09:18:15 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 09:20:56 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 701.9012780189514 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 14 09:22:53 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 09:24:35 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 09:26:32 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 09:29:56 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 09:32:37 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 701.4193403720856 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 14 09:34:34 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 09:36:16 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 09:38:13 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Thu Mar 14 09:41:37 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 09:44:17 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 699.5649671554565 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 14 09:46:14 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 09:47:55 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 09:49:51 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 09:53:13 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 09:55:52 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 693.5520157814026 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 14 09:57:47 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 09:59:29 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 10:01:25 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 10:04:45 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 10:07:24 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 692.4571299552917 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 14 10:09:19 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 10:10:59 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 10:12:55 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 10:16:15 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Thu Mar 14 10:18:53 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 689.3620436191559 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 14 10:20:49 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 10:22:30 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 10:24:25 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 10:27:45 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 10:30:24 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 690.1795430183411 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 14 10:32:19 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 10:33:59 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 10:35:52 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 10:39:15 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 10:41:55 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 693.0215036869049 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 14 10:43:51 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 10:45:32 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 10:47:27 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 10:50:47 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 10:53:25 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 689.1727559566498 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 14 10:55:21 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 10:57:01 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 10:58:57 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 11:02:19 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 11:04:57 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 691.7274475097656 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 14 11:06:53 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 11:08:34 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 11:10:28 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 11:13:51 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 11:16:30 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 693.0014185905457 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 14 11:18:25 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 11:20:05 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 11:21:58 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 11:25:20 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 11:27:59 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 689.3355877399445 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 14 11:29:55 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Thu Mar 14 11:31:36 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 11:33:29 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 11:36:48 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 11:39:25 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 684.8147976398468 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 14 11:41:20 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 11:42:59 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 11:44:55 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 11:48:18 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 11:50:57 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 693.7726073265076 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 14 11:52:54 2024]  Iteration number: 0 with current cost as 0.3460325808451482 and parameters 
[ 1.33999893  2.23743448 -2.12427979 -0.11653103  0.55388692 -2.77010897
  3.06858483  2.18960145  1.18551998 -1.06648324  0.60271526  1.14432445
  1.31029899 -1.8735468   0.72965065  2.88578419 -0.54534335 -0.4752247
 -2.02654256  0.72897385  1.60512648  2.83077091 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337139  2.54856958 -0.67550772 -2.69002217]. 
Working on 0.4 fold... 
[Thu Mar 14 11:54:35 2024]  Iteration number: 0 with current cost as 0.28853377548809134 and parameters 
[-1.29406972  2.23743459 -2.12427954 -0.11653103  0.55388708 -2.77010897
  3.06858493  2.18960145  1.18552003 -1.06648308  0.6027152   1.14432445
  1.31029899 -1.87354675  0.7296508   2.88578419 -0.54534335 -0.47522475
 -2.0265424   0.72897374  1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Thu Mar 14 11:56:32 2024]  Iteration number: 0 with current cost as 0.540885481949374 and parameters 
[ 0.02415267  2.23743464 -2.12427954 -0.11653093  0.55388718 -2.77010897
  3.06858489  2.18960155  1.18552008 -1.06648318  0.6027152   1.14432445
  1.31029908 -1.8735467   0.72965071  2.88578419 -0.54534335 -0.47522466
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105
 -2.39279228 -2.27309765  3.13337155  2.54856958 -0.67550778 -2.69002211]. 
Working on 0.8 fold... 
[Thu Mar 14 11:59:55 2024]  Iteration number: 0 with current cost as 0.5183899726646668 and parameters 
[ 0.00866845  2.23743444 -2.12427964 -0.11653103  0.55388698 -2.77010897
  3.06858479  2.18960136  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265425   0.7289736   1.60512644  2.83077097 -1.2645671  -0.25136124
 -2.39279228 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002211]. 
Working on 1.0 fold... 
[Thu Mar 14 12:02:34 2024]  Iteration number: 0 with current cost as 0.3275025144923933 and parameters 
[ 1.57604839  2.23743464 -2.12427935 -0.11653074  0.55388708 -2.77010868
  3.06858527  2.1896016   1.18552027 -1.06648308  0.60271539  1.14432474
  1.31029913 -1.87354651  0.72965066  2.88578419 -0.54534349 -0.47522456
 -2.02654255  0.7289737   1.60512664  2.83077121 -1.2645671  -0.25136105
 -2.39279218 -2.2730976   3.13337169  2.54856973 -0.67550773 -2.69002202]. 
Training complete taking 696.3546662330627 seconds. 
Discarding model... 

Training complete taking 17310.766709327698 total seconds. 
Now scoring model... 
Scoring complete taking 0.9151935577392578 seconds. 
Saved predicted values as A1-A1-CNOT_Full-CRZ_predicted_values.csv
Model scores: {'MSE_train': (193.24510237542225,), 'R2_train': 0.0637923351235985, 'MAE_train': 12.576626094729802, 'MSE_test': 169.18972262632695, 'R2_test': -0.019844163482825028, 'MAE_test': 11.370996008300859}. 
Saved model results as A1-A1-CNOT_Full-CRZ_results.json. 
