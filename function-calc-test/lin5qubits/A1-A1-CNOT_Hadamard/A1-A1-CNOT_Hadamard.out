test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Fri Mar 15 01:11:24 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 01:11:27 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:11:32 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:11:37 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:11:42 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:11:48 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.7628014087677 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 01:11:54 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:11:59 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:12:04 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:12:09 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:12:15 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.827836990356445 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 01:12:20 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:12:26 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:12:31 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:12:36 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:12:42 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.940192222595215 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 01:12:47 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:12:53 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:12:57 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:13:03 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:13:09 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.85534405708313 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 01:13:14 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:13:20 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:13:24 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:13:30 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:13:35 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.708104610443115 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 01:13:41 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:13:46 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:13:51 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:13:57 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:14:02 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.793691873550415 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 01:14:08 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:14:13 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:14:18 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:14:23 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:14:29 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 26.50096344947815 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 01:14:34 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:14:40 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:14:44 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:14:50 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:14:55 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.658145427703857 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 01:15:01 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:15:06 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:15:11 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:15:16 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:15:22 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.79384160041809 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 01:15:28 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:15:33 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:15:38 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:15:44 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:15:49 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 27.275835037231445 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 01:15:55 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:16:01 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:16:05 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:16:11 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:16:17 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 27.367766618728638 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 01:16:22 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:16:28 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:16:33 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:16:38 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:16:44 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.902127742767334 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 01:16:49 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:16:55 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:16:59 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:17:05 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:17:10 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.69975256919861 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 01:17:16 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:17:22 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:17:26 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:17:32 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:17:37 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 27.098660945892334 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 01:17:43 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:17:49 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Fri Mar 15 01:17:53 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:17:59 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:18:05 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 27.30161166191101 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 01:18:10 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:18:16 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:18:20 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:18:26 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:18:32 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 27.131617069244385 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 01:18:37 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:18:43 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:18:48 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:18:53 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:18:59 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 27.345409393310547 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 01:19:05 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:19:10 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:19:15 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:19:21 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:19:26 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 27.11630892753601 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 01:19:32 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:19:38 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:19:42 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:19:48 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:19:53 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.786466598510742 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 01:19:59 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:20:04 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:20:09 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:20:14 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:20:20 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.88727045059204 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 01:20:25 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:20:31 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:20:36 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:20:41 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:20:47 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 26.936314582824707 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 01:20:53 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:20:58 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:21:03 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:21:08 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:21:14 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 27.13408637046814 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 01:21:20 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:21:25 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:21:30 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:21:36 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:21:41 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 27.224002838134766 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 01:21:47 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:21:52 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:21:57 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:22:03 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:22:08 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 27.12127685546875 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 01:22:14 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Fri Mar 15 01:22:20 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Fri Mar 15 01:22:24 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Fri Mar 15 01:22:30 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Fri Mar 15 01:22:36 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 27.44146966934204 seconds. 
Discarding model... 

Training complete taking 674.6112589836121 total seconds. 
Now scoring model... 
Scoring complete taking 0.31180596351623535 seconds. 
Saved predicted values as A1-A1-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (206.51597340240704,), 'R2_train': -0.0005005810865745808, 'MAE_train': 12.558614507414685, 'MSE_test': 195.86551907841735, 'R2_test': -0.18064090039813796, 'MAE_test': 12.133802896986289}. 
Saved model results as A1-A1-CNOT_Hadamard_results.json. 
