/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:30:19 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:29 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:30:47 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:31:03 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:31:20 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:31:39 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.3186252117157 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:31:56 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:32:15 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:32:29 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:32:47 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:33:06 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.413747549057 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:33:23 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:33:43 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:34:00 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:34:21 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:34:41 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 94.77040505409241 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:34:58 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:35:17 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:32 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:35:49 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:36:08 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 86.88826966285706 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:25 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:36:43 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:36:57 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:37:16 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:37:36 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 88.52155876159668 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:53 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:38:12 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:26 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:45 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:04 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.44425916671753 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:21 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:40 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:54 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:13 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:31 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.9980525970459 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:49 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:08 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:22 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:41 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:58 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.57987475395203 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:16 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:35 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:49 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:09 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:26 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 88.1920256614685 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:45 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:03 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:17 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:36 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:53 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.58834552764893 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:12 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:29 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:45 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:04 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:21 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 85.8589813709259 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:40 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:57 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:13 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:31 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:49 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.91234230995178 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:08 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:25 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:41 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:58 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:16 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.6063780784607 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:35 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:52 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:12 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:29 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:48 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 91.66388964653015 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:07 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:24 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:40 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:57 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:16 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.94237303733826 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:35 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:57 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:13 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:30 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:48 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 92.36865592002869 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:07 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:24 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:40 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:57 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:16 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.34590101242065 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:35 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:52 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:07 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:24 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:43 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.55626630783081 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:01 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:19 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:35 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:57:52 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:11 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.81876945495605 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:58:28 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:58:47 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:59:03 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:20 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:39 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.79508423805237 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:56 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 18:00:15 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:00:29 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 18:00:48 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:07 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.94528913497925 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:01:24 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 18:01:43 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:01:57 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 18:02:16 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:02:40 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 92.92091536521912 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:02:58 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 18:03:17 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:03:33 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 18:03:50 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:04:09 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 89.18641352653503 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:04:26 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 18:04:45 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:04:59 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 18:05:20 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:05:38 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 89.17751407623291 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:55 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 18:06:14 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:06:28 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:47 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:06 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.87894606590271 seconds. 
Discarding model... 

Training complete taking 2214.6937158107758 total seconds. 
Now scoring model... 
Scoring complete taking 0.8050537109375 seconds. 
Saved predicted values as A1-A1-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (206.51597340240704,), 'R2_train': -0.0005005810865745808, 'MAE_train': 12.558614507414685, 'MSE_test': 195.86551907841735, 'R2_test': -0.18064090039813796, 'MAE_test': 12.133802896986289}. 
Saved model results as A1-A1-CNOT_Hadamard_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 11:40:56 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:41:05 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:41:24 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:41:38 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:41:57 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:42:16 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 89.37951064109802 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:42:34 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:42:54 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:43:08 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:43:26 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:43:43 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.14469504356384 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:44:02 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:44:20 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:44:35 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:44:53 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:45:13 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 89.92808747291565 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:45:31 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:45:50 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:46:04 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:46:22 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:46:39 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 85.75639295578003 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:46:57 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:47:16 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:47:30 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:47:48 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:48:05 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 84.57529997825623 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:48:23 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:48:40 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:48:56 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:49:13 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:49:31 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 86.00500798225403 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:49:54 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:50:11 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:50:27 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:50:44 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:51:02 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 91.2008728981018 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:51:20 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:51:37 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:51:53 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:52:10 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:52:28 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 85.84476089477539 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:52:49 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:53:06 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:53:21 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:53:38 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:53:57 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 88.60944557189941 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:54:14 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:54:33 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:54:48 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:55:05 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:55:25 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 88.03890562057495 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:55:42 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:56:00 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:56:14 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:56:32 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:56:51 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 85.94248628616333 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:57:08 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:57:26 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:57:40 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:57:58 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:58:17 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 86.06573939323425 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:58:34 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 11:58:52 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:59:06 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 11:59:24 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:59:41 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 86.29466605186462 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:00:00 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:00:18 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:00:32 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:00:51 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:01:08 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.3834273815155 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:01:27 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:01:46 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:02:00 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:02:18 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:02:35 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 84.56871104240417 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:02:54 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:03:11 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:03:26 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:03:44 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:04:02 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.22186541557312 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:04:20 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:04:37 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:04:53 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:05:10 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:05:28 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 85.83986639976501 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:05:46 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:06:03 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:06:18 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:06:35 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:06:54 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 85.69926714897156 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:07:11 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:07:29 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:07:43 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:08:01 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:08:19 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 85.8111469745636 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:08:36 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:08:55 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:09:08 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:09:27 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:09:43 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 86.88846516609192 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:10:03 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:10:21 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:10:35 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:10:53 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:11:10 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 84.87896871566772 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:11:28 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:11:46 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:12:00 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:12:20 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:12:37 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 88.98810982704163 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:12:58 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:13:15 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:13:30 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:13:48 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:14:05 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 84.87852549552917 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:14:23 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:14:40 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:14:56 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:15:12 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:15:31 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 86.29543495178223 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:15:50 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Thu Apr  4 12:16:08 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:16:23 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Thu Apr  4 12:16:40 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 12:16:58 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.00363159179688 seconds. 
Discarding model... 

Training complete taking 2170.2444927692413 total seconds. 
Now scoring model... 
Scoring complete taking 0.7956221103668213 seconds. 
Saved predicted values as A1-A1-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (206.51597340240704,), 'R2_train': -0.0005005810865745808, 'MAE_train': 12.558614507414685, 'MSE_test': 195.86551907841735, 'R2_test': -0.18064090039813796, 'MAE_test': 12.133802896986289}. 
Saved model results as A1-A1-CNOT_Hadamard_results.json. 
