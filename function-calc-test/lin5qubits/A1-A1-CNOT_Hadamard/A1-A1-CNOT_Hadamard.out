/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:30:19 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:29 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:30:47 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:31:03 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:31:20 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:31:39 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.3186252117157 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:31:56 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:32:15 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:32:29 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:32:47 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:33:06 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.413747549057 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:33:23 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:33:43 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:34:00 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:34:21 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:34:41 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 94.77040505409241 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:34:58 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:35:17 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:32 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:35:49 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:36:08 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 86.88826966285706 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:25 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:36:43 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:36:57 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:37:16 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:37:36 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 88.52155876159668 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:53 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:38:12 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:26 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:45 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:04 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.44425916671753 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:21 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:40 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:54 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:13 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:31 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.9980525970459 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:49 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:08 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:22 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:41 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:58 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.57987475395203 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:16 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:35 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:49 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:09 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:26 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 88.1920256614685 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:45 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:03 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:17 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:36 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:53 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.58834552764893 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:12 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:29 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:45 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:04 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:21 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 85.8589813709259 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:40 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:57 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:13 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:31 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:49 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.91234230995178 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:08 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:25 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:41 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:58 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:16 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.6063780784607 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:35 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:52 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:12 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:29 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:48 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 91.66388964653015 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:07 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:24 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:40 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:57 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:16 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.94237303733826 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:35 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:57 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:13 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:30 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:48 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 92.36865592002869 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:07 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:24 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:40 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:57 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:16 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.34590101242065 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:35 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:52 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:07 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:24 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:43 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.55626630783081 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:01 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:19 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:35 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:57:52 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:11 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.81876945495605 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:58:28 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 17:58:47 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:59:03 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:20 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:39 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.79508423805237 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:56 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 18:00:15 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:00:29 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 18:00:48 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:07 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.94528913497925 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:01:24 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 18:01:43 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:01:57 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 18:02:16 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:02:40 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 92.92091536521912 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:02:58 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 18:03:17 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:03:33 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 18:03:50 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:04:09 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 89.18641352653503 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:04:26 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 18:04:45 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:04:59 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 18:05:20 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:05:38 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 89.17751407623291 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:55 2024]  Iteration number: 0 with current cost as 0.35643001517743894 and parameters 
[-2.05576291  2.23743451 -2.12427989 -0.11653103  0.55388682]. 
Working on 0.4 fold... 
[Sun Mar 24 18:06:14 2024]  Iteration number: 0 with current cost as 0.31074188584643325 and parameters 
[-1.46193213  2.2374345  -2.12427977 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:06:28 2024]  Iteration number: 0 with current cost as 0.3228248738270668 and parameters 
[-1.8960221   2.23743464 -2.12427988 -0.11653103  0.55388683]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:47 2024]  Iteration number: 0 with current cost as 0.3277165488626831 and parameters 
[-1.89831405  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:06 2024]  Iteration number: 0 with current cost as 0.3286278649626029 and parameters 
[-1.81591379  2.23743464 -2.12427951 -0.11653078  0.55388708]. 
Training complete taking 87.87894606590271 seconds. 
Discarding model... 

Training complete taking 2214.6937158107758 total seconds. 
Now scoring model... 
Scoring complete taking 0.8050537109375 seconds. 
Saved predicted values as A1-A1-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (206.51597340240704,), 'R2_train': -0.0005005810865745808, 'MAE_train': 12.558614507414685, 'MSE_test': 195.86551907841735, 'R2_test': -0.18064090039813796, 'MAE_test': 12.133802896986289}. 
Saved model results as A1-A1-CNOT_Hadamard_results.json. 
