runall.sh: line 11: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Wed Mar 13 21:17:24 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 13 21:17:52 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 21:18:42 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 21:19:38 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 21:21:17 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 21:22:34 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 337.0818908214569 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 13 21:23:29 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 21:24:17 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 21:25:13 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 21:26:49 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 21:28:05 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 330.7285418510437 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 13 21:29:00 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 21:29:48 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 21:30:43 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 21:32:19 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 21:33:35 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 330.78319096565247 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 13 21:34:31 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 21:35:19 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 21:36:15 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 21:37:52 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 21:39:08 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 332.4768934249878 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 13 21:40:03 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 21:40:52 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 21:41:46 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Wed Mar 13 21:43:23 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 21:44:38 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 330.1098999977112 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 13 21:45:34 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 21:46:23 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 21:47:18 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 21:48:55 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 21:50:11 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 332.83419275283813 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 13 21:51:06 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 21:51:54 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 21:52:50 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 21:54:26 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 21:55:42 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 330.91107988357544 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 13 21:56:37 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 21:57:25 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 21:58:21 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 21:59:57 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:01:13 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 331.34286999702454 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 13 22:02:08 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 22:02:57 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 22:03:52 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 22:05:29 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:06:45 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 331.6153223514557 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 13 22:07:40 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 22:08:28 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 22:09:23 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Wed Mar 13 22:11:00 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:12:16 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 331.744909286499 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 13 22:13:12 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 22:14:00 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 22:14:55 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 22:16:32 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:17:48 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 331.73284888267517 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 13 22:18:43 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 22:19:31 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 22:20:27 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 22:22:04 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:23:19 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 330.76529836654663 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 13 22:24:14 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 22:25:02 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 22:25:53 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 22:27:18 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:28:25 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 302.47196912765503 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 13 22:29:13 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 22:29:55 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 22:30:45 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 22:32:10 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:33:17 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 292.4313657283783 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 13 22:34:06 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 22:34:49 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 22:35:38 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Wed Mar 13 22:37:04 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:38:12 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 295.52653527259827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 13 22:39:01 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 22:39:45 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 22:40:35 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 22:42:01 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:43:08 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 295.2282221317291 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 13 22:43:57 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 22:44:40 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 22:45:30 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 22:46:56 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:48:04 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 295.88885831832886 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 13 22:48:53 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 22:49:36 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 22:50:25 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 22:51:52 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:53:04 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 302.7121045589447 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 13 22:53:56 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 22:54:42 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 22:55:36 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 22:57:09 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 22:58:23 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 318.2534534931183 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 13 22:59:16 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 23:00:02 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 23:00:53 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Wed Mar 13 23:02:20 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 23:03:28 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 303.6256015300751 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 13 23:04:17 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 23:05:00 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 23:05:49 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 23:07:15 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 23:08:23 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 294.3168623447418 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 13 23:09:12 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 23:09:55 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 23:10:43 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 23:12:10 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 23:13:18 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 295.4675750732422 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 13 23:14:07 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 23:14:50 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 23:15:40 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 23:17:06 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 23:18:13 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 295.32066226005554 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 13 23:19:03 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 23:19:46 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 23:20:36 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. 
Working on 0.8 fold... 
[Wed Mar 13 23:22:02 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 23:23:09 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 295.7348532676697 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 13 23:23:58 2024]  Iteration number: 0 with current cost as 0.34603258084514815 and parameters 
[ 1.33999893  2.23743464 -2.12427932 -0.11653071  0.55388708 -2.77010897
  3.06858483  2.1896013   1.18551998 -1.06648308  0.60271526  1.14432461
  1.3102993  -1.87354649]. 
Working on 0.4 fold... 
[Wed Mar 13 23:24:41 2024]  Iteration number: 0 with current cost as 0.2885337746973257 and parameters 
[-1.29406975  2.23743459 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858488  2.18960145  1.18552003 -1.06648318  0.6027151   1.1443245
  1.31029899 -1.8735467 ]. 
Working on 0.6 fold... 
[Wed Mar 13 23:25:29 2024]  Iteration number: 0 with current cost as 0.5408854819461052 and parameters 
[ 0.02415267  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552018 -1.06648308  0.6027151   1.14432464
  1.31029918 -1.87354661]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Wed Mar 13 23:26:55 2024]  Iteration number: 0 with current cost as 0.5183899726530419 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653083  0.55388708 -2.77010897
  3.06858498  2.18960165  1.18552018 -1.06648308  0.6027152   1.14432455
  1.31029908 -1.87354641]. 
Working on 1.0 fold... 
[Wed Mar 13 23:28:02 2024]  Iteration number: 0 with current cost as 0.327502891978733 and parameters 
[ 1.57605038  2.23743449 -2.12427935 -0.11653103  0.55388708 -2.77010912
  3.06858498  2.18960145  1.18551998 -1.06648337  0.6027151   1.14432445
  1.31029913 -1.87354651]. 
Training complete taking 292.6197290420532 seconds. 
Discarding model... 

Training complete taking 7861.72504734993 total seconds. 
Now scoring model... 
Scoring complete taking 0.7871718406677246 seconds. 
Saved predicted values as A1-A1-CNOT_Efficient-CRX_predicted_values.csv
Model scores: {'MSE_train': (193.2451023625074,), 'R2_train': 0.06379233518616656, 'MAE_train': 12.576626101631165, 'MSE_test': 169.18972253811205, 'R2_test': -0.019844162951081934, 'MAE_test': 11.370995999839524}. 
Saved model results as A1-A1-CNOT_Efficient-CRX_results.json. 
