/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:35:02 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:35:17 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:35:41 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:58 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:36:18 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:36:39 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.71313142776489 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:56 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:37:20 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:37:37 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:37:57 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:20 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.25512599945068 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:38:36 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:00 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:17 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:39:36 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:58 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 98.39590787887573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:16 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:40 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:57 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:17 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:39 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 102.9374852180481 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:41:58 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:22 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:41 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:59 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:21 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.28416848182678 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:39 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:02 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:21 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:41 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:45:02 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.49007892608643 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:20 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:44 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:01 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:21 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:43 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.9092710018158 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:00 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:23 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:41 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:01 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:48:23 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 99.98461627960205 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:41 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:03 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:21 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:49:42 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:03 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 99.91234421730042 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:21 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:45 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:02 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:22 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:51:44 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.43500065803528 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:01 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:25 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:43 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:02 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:24 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.11396145820618 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:42 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:06 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:24 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:44 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:05 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.95000529289246 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:23 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:47 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:04 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:24 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:46 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.35528945922852 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:03 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:27 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:45 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:03 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:26 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 99.19686150550842 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:58:43 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 17:59:06 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:59:24 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:44 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:00:05 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 99.225900888443 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:00:24 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:00:47 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:01:05 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:01:25 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:47 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.82001304626465 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:02:04 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:02:29 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:02:47 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:03:06 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:03:28 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.18674802780151 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:03:46 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:04:09 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:04:27 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:04:47 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:05:09 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.65686178207397 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:27 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:05:50 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:06:08 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:28 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:06:50 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.96754455566406 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:07:07 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:07:31 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:07:49 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:08:09 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:08:31 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.48272109031677 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:08:49 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:09:13 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:09:30 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:09:50 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:10:12 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.88741374015808 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:10:29 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:10:53 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:11:12 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:11:31 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:11:53 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.22210597991943 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:12:11 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:12:35 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:12:53 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:13:13 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:13:33 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.1934175491333 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:13:51 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:14:15 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:14:32 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:14:53 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:15:14 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 101.30956554412842 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:15:31 2024]  Iteration number: 0 with current cost as 0.31799771104661995 and parameters 
[ 0.10438183  2.23743511 -2.12427916 -0.11653055  0.55388756]. 
Working on 0.4 fold... 
[Sun Mar 24 18:15:55 2024]  Iteration number: 0 with current cost as 0.2585362243671552 and parameters 
[ 0.25095359  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:16:13 2024]  Iteration number: 0 with current cost as 0.2800061943427081 and parameters 
[-0.05050641  2.23743464 -2.12427964 -0.11653103  0.55388783]. 
Working on 0.8 fold... 
[Sun Mar 24 18:16:32 2024]  Iteration number: 0 with current cost as 0.2781112265801354 and parameters 
[ 0.08833649  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:16:55 2024]  Iteration number: 0 with current cost as 0.2798022669486347 and parameters 
[-0.05921017  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 100.56597185134888 seconds. 
Discarding model... 

Training complete taking 2516.452889442444 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.8546080589294434 seconds. 
Saved predicted values as M-A1-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (177.25816508535758,), 'R2_train': 0.14124368082331995, 'MAE_train': 10.527907281315368, 'MSE_test': 142.45531555627866, 'R2_test': 0.1413058673306904, 'MAE_test': 8.809892052298718}. 
Saved model results as M-A1-CZ_Hadamard_results.json. 
