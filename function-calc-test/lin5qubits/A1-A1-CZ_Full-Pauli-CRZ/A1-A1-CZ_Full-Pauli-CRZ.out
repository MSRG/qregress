/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:30:09 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:30 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:07 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 17:47:54 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:00 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Sun Mar 24 18:04:05 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Sun Mar 24 18:05:59 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 18:15:22 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Sun Mar 24 18:16:02 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 18:25:18 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3410.6441764831543 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:27:19 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Sun Mar 24 18:36:00 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 18:44:40 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Sun Mar 24 18:51:57 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Sun Mar 24 19:01:07 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Sun Mar 24 19:02:58 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 19:12:02 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Sun Mar 24 19:12:42 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 19:22:06 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3405.8561584949493 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 19:24:06 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Sun Mar 24 19:32:36 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 19:41:07 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Sun Mar 24 19:48:17 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Sun Mar 24 19:57:47 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Sun Mar 24 19:59:38 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 20:08:37 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Sun Mar 24 20:09:17 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 20:18:51 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3406.8251135349274 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 20:20:52 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Sun Mar 24 20:29:24 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 20:37:53 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Sun Mar 24 20:44:55 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Sun Mar 24 20:54:02 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Sun Mar 24 20:55:51 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 21:05:36 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Sun Mar 24 21:06:16 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 21:15:28 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3396.9526805877686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 21:17:29 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Sun Mar 24 21:26:05 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 21:34:50 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Sun Mar 24 21:42:11 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Sun Mar 24 21:51:32 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Sun Mar 24 21:53:26 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 22:02:39 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Sun Mar 24 22:03:19 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 22:12:34 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3425.96919965744 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 22:14:35 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Sun Mar 24 22:23:11 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 22:31:46 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Sun Mar 24 22:38:48 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Sun Mar 24 22:47:52 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Sun Mar 24 22:49:56 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 22:59:01 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Sun Mar 24 22:59:42 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 23:09:16 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3413.915475130081 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 23:11:31 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Sun Mar 24 23:20:16 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 23:28:50 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Sun Mar 24 23:36:38 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Sun Mar 24 23:45:39 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Sun Mar 24 23:47:31 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sun Mar 24 23:57:24 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Sun Mar 24 23:58:04 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 00:07:26 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3476.408272743225 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 00:09:32 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 00:18:05 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 00:26:35 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 00:33:35 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 00:42:35 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 00:44:26 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 00:53:29 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 00:54:09 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 01:03:29 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3363.208979845047 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 01:05:29 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 01:14:03 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 01:22:58 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 01:30:02 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 01:39:16 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 01:41:06 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 01:50:06 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 01:50:46 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 02:00:21 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3426.1712350845337 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 02:02:36 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 02:11:22 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 02:19:56 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 02:26:56 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 02:36:02 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 02:37:52 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 02:46:53 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 02:47:33 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 02:56:48 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3373.7864186763763 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 25 02:58:48 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 03:07:30 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 03:16:27 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 03:23:48 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 03:33:06 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 03:34:57 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 03:45:07 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 03:46:09 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 03:55:23 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3514.4918167591095 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 03:57:23 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 04:05:55 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 04:15:02 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 04:22:03 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 04:31:03 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 04:32:53 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 04:41:55 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 04:42:36 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 04:51:46 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3382.192003250122 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 04:53:47 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 05:02:19 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 05:10:51 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 05:17:52 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 05:26:59 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 05:28:54 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 05:37:57 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 05:38:39 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 05:47:51 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3365.207765817642 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 05:49:51 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 05:58:48 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 06:07:26 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 06:14:49 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 06:24:18 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 06:26:09 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 06:35:14 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 06:35:53 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 06:45:11 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3440.0415377616882 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 06:47:11 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 06:56:00 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 07:05:16 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 07:12:18 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 07:21:17 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 07:23:07 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 07:32:53 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 07:33:33 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 07:42:47 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3468.5882833004 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 25 07:45:00 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 07:53:35 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 08:02:22 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 08:09:25 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 08:18:29 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 08:20:20 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 08:29:24 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 08:30:04 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 08:39:19 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3379.3821523189545 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 08:41:19 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 08:49:53 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 08:58:34 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 09:05:37 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 09:15:11 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 09:17:18 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 09:26:27 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 09:27:07 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 09:36:31 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3431.505688905716 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 09:38:31 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 09:47:40 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 09:56:13 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 10:03:15 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 10:12:17 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 10:14:08 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 10:23:13 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 10:23:54 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 10:33:05 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3395.4055256843567 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 10:35:06 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 10:43:36 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 10:52:07 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 10:59:12 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 11:08:33 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 11:10:28 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 11:19:35 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 11:20:15 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 11:29:30 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3383.868402481079 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 11:31:30 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 11:40:01 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 11:48:41 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 11:55:41 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 12:04:43 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 12:06:35 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 12:15:37 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 12:16:17 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 12:25:32 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3362.8626430034637 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 25 12:27:33 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 12:36:08 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 12:44:47 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 12:52:04 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 13:01:37 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 13:03:28 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 13:12:57 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 13:13:38 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 13:22:51 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3440.6547026634216 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 13:24:52 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 13:33:25 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 13:41:59 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 13:49:04 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 13:58:10 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 14:00:00 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 14:09:40 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 14:10:20 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 14:19:31 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3399.5065331459045 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 14:21:32 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 14:30:07 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 14:38:46 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 14:45:56 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 14:55:14 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 14:57:03 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 15:06:08 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 15:06:48 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 15:16:03 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3391.5939157009125 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 15:18:03 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 15:27:00 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 15:36:05 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 15:43:19 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 15:52:26 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 15:54:17 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 16:03:22 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 16:04:01 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 16:13:15 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3431.1300361156464 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 16:15:16 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Mar 25 16:23:48 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 16:32:21 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Mon Mar 25 16:39:23 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Mon Mar 25 16:48:28 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Mon Mar 25 16:50:20 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 17:00:21 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Mon Mar 25 17:01:05 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Mar 25 17:10:25 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3432.6808161735535 seconds. 
Discarding model... 

Training complete taking 85318.85197997093 total seconds. 
Now scoring model... 
Scoring complete taking 0.9948985576629639 seconds. 
Saved predicted values as A1-A1-CZ_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (107.50642420949825,), 'R2_train': 0.479167455572281, 'MAE_train': 7.54448756340427, 'MSE_test': 123.74139797298429, 'R2_test': 0.2541098800506191, 'MAE_test': 8.443893408424675}. 
Saved model results as A1-A1-CZ_Full-Pauli-CRZ_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 11:40:56 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:41:17 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 11:49:51 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 11:58:24 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 12:05:30 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 12:14:30 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 12:16:23 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 12:25:28 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 12:26:08 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 12:35:21 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3364.8539044857025 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:37:21 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 12:46:16 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 12:54:47 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 13:01:49 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 13:11:03 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 13:12:54 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 13:22:00 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 13:22:41 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 13:32:01 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3403.137893676758 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:34:05 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 13:42:41 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 13:52:59 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 14:00:08 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 14:09:40 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 14:11:34 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 14:20:34 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 14:21:14 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 14:30:49 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3525.7724783420563 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 14:32:49 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 14:41:17 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 14:50:00 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 14:57:09 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 15:06:23 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 15:08:13 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 15:17:53 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 15:18:34 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 15:27:41 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3409.8926935195923 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 15:29:40 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 15:38:11 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 15:46:41 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 15:53:42 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 16:02:42 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 16:04:33 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 16:13:32 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 16:14:12 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 16:23:22 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3343.1162943840027 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 16:25:22 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 16:33:53 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 16:42:28 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 16:49:28 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 16:58:29 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 17:00:21 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 17:09:30 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 17:10:11 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 17:19:22 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3359.296492099762 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 17:21:23 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 17:29:55 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 17:38:23 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 17:45:55 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 17:54:59 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 17:56:49 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 18:05:56 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 18:06:36 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 18:16:03 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3402.4660789966583 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 18:18:04 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 18:26:55 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 18:36:05 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 18:43:20 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 18:52:19 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 18:54:08 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 19:03:16 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 19:03:56 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 19:13:08 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3424.5560994148254 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 19:15:08 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 19:23:38 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 19:32:14 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 19:39:17 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 19:48:23 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 19:50:12 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 19:59:58 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 20:00:38 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 20:09:56 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3406.8952689170837 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 20:11:57 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 20:20:33 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 20:29:24 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 20:36:26 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 20:46:32 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 20:48:23 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 20:57:43 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 20:58:24 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:07:31 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3454.834674835205 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:09:31 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 21:18:02 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:26:33 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 21:33:34 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:42:37 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 21:44:28 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:53:58 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 21:54:38 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:03:55 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3393.803516149521 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:06:05 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 22:14:36 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:23:05 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 22:30:06 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:39:08 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 22:40:58 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:50:23 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 22:51:04 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:01:04 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3419.076694726944 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:03:04 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 23:11:38 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:20:07 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Thu Apr  4 23:27:07 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:36:07 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Thu Apr  4 23:37:56 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:47:00 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Thu Apr  4 23:47:40 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:56:49 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3353.3806297779083 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:58:57 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 00:08:08 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:16:40 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 00:24:10 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:33:23 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 00:35:16 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:44:20 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 00:45:00 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:54:12 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3435.4116835594177 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:56:13 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 01:04:45 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:13:17 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 01:20:25 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:30:06 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 01:32:00 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:41:06 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 01:41:46 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:51:03 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3412.3505980968475 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:53:04 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 02:01:39 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:10:18 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 02:17:19 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:26:47 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 02:28:36 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:38:32 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 02:39:14 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:48:40 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3458.9487438201904 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:50:44 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 02:59:26 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:07:58 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 03:15:00 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:24:02 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 03:25:53 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:34:54 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 03:35:34 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:44:45 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3360.5697293281555 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:46:45 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 03:55:15 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:03:45 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 04:10:46 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:19:48 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 04:21:37 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:30:39 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 04:31:20 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:40:31 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3345.909644126892 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 04:42:39 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 04:51:26 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:00:16 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 05:07:21 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:16:21 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 05:18:11 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:27:38 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 05:28:18 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:37:36 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3425.2089784145355 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 05:39:36 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 05:48:10 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:56:42 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 06:03:45 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:12:48 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 06:15:22 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:24:31 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 06:25:11 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:34:33 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3418.1391565799713 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 06:36:34 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 06:45:06 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:53:37 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 07:00:50 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:10:11 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 07:12:02 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:21:06 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 07:21:45 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:31:01 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3387.1786873340607 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 07:33:01 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 07:41:33 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:50:04 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 07:57:40 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:07:05 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 08:08:54 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:18:09 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 08:18:49 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:28:01 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3419.571481704712 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 08:30:01 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 08:38:33 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:47:28 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 08:54:29 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:03:32 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 09:05:23 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:14:25 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 09:15:06 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:24:28 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3390.01971244812 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 09:26:30 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 09:35:01 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:43:31 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 09:50:31 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:59:31 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 10:01:22 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:10:21 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 10:11:01 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:20:13 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3342.039123773575 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 10:22:13 2024]  Iteration number: 0 with current cost as 0.23960938389315584 and parameters 
[-3.09664455  2.06511031 -2.07541002 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.47047071  1.14432445
  1.55401052 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 10:30:43 2024]  Iteration number: 0 with current cost as 0.19638712798290586 and parameters 
[-3.18389614  2.02594783 -2.06621337 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.45815098  1.14432446
  1.66660791 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:39:11 2024]  Iteration number: 50 with current cost as 0.16181008464167884 and parameters 
[-1.52445797  1.43760971 -2.45636476 -0.11654609  0.55388108 -2.77010821
  3.06857524  2.18960825  1.18552346 -1.06650509  0.16093744  1.14431907
  1.56152044 -1.87355407  0.7296326   2.88578959 -0.54535825 -0.47524126
 -2.02655733  0.72895902  1.60510453  2.83075252 -1.26456785 -0.25137946]. 
Working on 0.6 fold... 
[Fri Apr  5 10:46:14 2024]  Iteration number: 0 with current cost as 0.2021232829833744 and parameters 
[-3.15176185  2.03433408 -2.06657715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45483493  1.14432445
  1.62368794 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:55:59 2024]  Iteration number: 50 with current cost as 0.16083621154701847 and parameters 
[-0.25946863  3.57273367 -3.04834372 -0.11650529  0.55390609 -2.77009029
  3.06859308  2.18962068  1.18552829 -1.06645523 -2.05231131  1.14435912
  1.58744647 -1.87353912  0.72965645  2.88579898 -0.54533683 -0.47520957
 -2.02654267  0.72896642  1.60512467  2.83076562 -1.26457377 -0.25135942]. 
Working on 0.8 fold... 
[Fri Apr  5 10:57:49 2024]  Iteration number: 0 with current cost as 0.20434661966555354 and parameters 
[-3.15371285  2.02838133 -2.06543437 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.44754661  1.14432445
  1.62657995 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:07:22 2024]  Iteration number: 50 with current cost as 0.1628496178196296 and parameters 
[-0.37114698  3.33944595 -3.16061192 -0.11653218  0.55388442 -2.77011297
  3.06858318  2.18959885  1.18551854 -1.06648418 -1.78055377  1.14432561
  1.5423501  -1.87354676  0.72964975  2.88577947 -0.54534419 -0.47522487
 -2.02654315  0.72897153  1.60512566  2.83077104 -1.2645664  -0.25136033]. 
Working on 1.0 fold... 
[Fri Apr  5 11:08:02 2024]  Iteration number: 0 with current cost as 0.2096855502331966 and parameters 
[-3.15539441  2.04001104 -2.06957669 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46121289  1.14432445
  1.62922795 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:17:20 2024]  Iteration number: 50 with current cost as 0.17374131833675233 and parameters 
[-2.98399219  2.20348028 -3.24147338 -0.11659563  0.5538923  -2.77011149
  3.06852733  2.18959939  1.18559918 -1.066556   -0.65309422  1.14426425
  1.56357504 -1.87343988  0.72973052  2.88578546 -0.54535081 -0.47514595
 -2.02662799  0.72897142  1.60524525  2.83069821 -1.26463696 -0.25134565]. 
Training complete taking 3427.3849833011627 seconds. 
Discarding model... 

Training complete taking 85083.81725811958 total seconds. 
Now scoring model... 
Scoring complete taking 0.9974944591522217 seconds. 
Saved predicted values as A1-A1-CZ_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (107.50642420949825,), 'R2_train': 0.479167455572281, 'MAE_train': 7.54448756340427, 'MSE_test': 123.74139797298429, 'R2_test': 0.2541098800506191, 'MAE_test': 8.443893408424675}. 
Saved model results as A1-A1-CZ_Full-Pauli-CRZ_results.json. 
