test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Thu Mar 21 14:56:53 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 14:56:56 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 14:57:06 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 14:57:13 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 14:57:22 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 14:57:29 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 40.5945885181427 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 14:57:36 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 14:57:46 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 14:57:53 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 14:58:01 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 14:58:09 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.7736656665802 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 14:58:16 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 14:58:25 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 14:58:32 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 14:58:41 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 14:58:49 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 40.20034575462341 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 14:58:56 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 14:59:06 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 14:59:13 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 14:59:22 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 14:59:30 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 40.78375482559204 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 14:59:37 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 14:59:47 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 14:59:54 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:00:02 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:00:10 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 40.276275873184204 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 15:00:17 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:00:27 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:00:34 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:00:42 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:00:50 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.87248206138611 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 15:00:57 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:01:07 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:01:13 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:01:22 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:01:30 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 39.33812236785889 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 15:01:37 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:01:46 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:01:53 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:02:01 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:02:09 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.312257289886475 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 15:02:16 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:02:25 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:02:32 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:02:41 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:02:49 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.88029718399048 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 15:02:56 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:03:05 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:03:12 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:03:20 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:03:28 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 38.92706537246704 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 15:03:35 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:03:44 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:03:51 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:03:59 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:04:07 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 38.890530824661255 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 15:04:14 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:04:23 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:04:29 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:04:38 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:04:46 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 38.9093656539917 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 15:04:52 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:05:02 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:05:09 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:05:17 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:05:25 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.5941379070282 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 15:05:32 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:05:41 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:05:48 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:05:57 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:06:05 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.46793222427368 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 15:06:12 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:06:21 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Thu Mar 21 15:06:28 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:06:36 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:06:44 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.21541237831116 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 15:06:51 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:07:00 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:07:07 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:07:15 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:07:23 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.286186933517456 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 15:07:30 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:07:39 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:07:46 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:07:55 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:08:03 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.604482889175415 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 15:08:10 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:08:19 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:08:26 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:08:34 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:08:42 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.15391659736633 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 15:08:49 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:08:58 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:09:05 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:09:13 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:09:21 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.25539445877075 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 15:09:28 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:09:37 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:09:44 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:09:53 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:10:00 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.17794156074524 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 15:10:07 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:10:16 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:10:23 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:10:32 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:10:39 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 38.91031837463379 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 15:10:46 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:10:55 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:11:02 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:11:11 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:11:19 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 39.34799790382385 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 15:11:25 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:11:35 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:11:42 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:11:50 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:11:58 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.52438044548035 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 15:12:05 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:12:14 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:12:21 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:12:30 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:12:38 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.507646799087524 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 15:12:45 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 21 15:12:54 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Mar 21 15:13:01 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 21 15:13:09 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Mar 21 15:13:17 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 39.460121631622314 seconds. 
Discarding model... 

Training complete taking 988.2649207115173 total seconds. 
Now scoring model... 
Scoring complete taking 0.4673128128051758 seconds. 
Saved predicted values as A2-A2-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (160.68993206689294,), 'R2_train': 0.22151120923503964, 'MAE_train': 11.717667463039964, 'MSE_test': 160.64806244174207, 'R2_test': 0.03164337459265276, 'MAE_test': 11.904031966870976}. 
Saved model results as A2-A2-CZ_Hadamard_results.json. 
