/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:49:02 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:13 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:41 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:02 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:28 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:51 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.06083250045776 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:13 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:41 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:02 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:29 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:53 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.44992065429688 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:15 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:53:43 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:04 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:31 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:55 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 123.32460069656372 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:17 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:45 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:07 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:33 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:56 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.28164291381836 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:18 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:46 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:09 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:35 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:58 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.98607301712036 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:20 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:59:49 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:00:11 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:00:36 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:00 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.24942636489868 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:01:22 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:01:50 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:02:13 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:02:39 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:03:04 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 123.80724000930786 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:03:26 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:03:54 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:04:17 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:04:43 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:05:08 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.9531569480896 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:29 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:05:57 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:06:20 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:45 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:10 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.94698071479797 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:07:31 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:08:00 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:08:22 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:08:48 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:09:12 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.19174551963806 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:09:33 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:10:02 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:10:24 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:10:50 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:11:15 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.2891047000885 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:11:36 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:12:04 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:12:26 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:12:52 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:13:17 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.61806964874268 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:13:38 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:14:08 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:14:29 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:14:55 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:15:19 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.30983018875122 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:15:41 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:16:10 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:16:31 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:16:57 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:17:22 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.15837121009827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:17:43 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:18:12 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:18:33 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:18:59 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:19:25 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 123.23904657363892 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:19:46 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:20:15 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:20:36 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:21:09 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:21:33 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 127.6410698890686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:21:54 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:22:23 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:22:44 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:23:11 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:23:35 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.38072443008423 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:23:56 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:24:25 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:24:47 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:25:14 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:25:37 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.08430743217468 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:25:58 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:26:27 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:26:48 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:27:15 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:27:39 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.15012431144714 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:28:00 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:28:30 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:28:51 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:29:19 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:29:42 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 123.41317915916443 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:30:04 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:30:33 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:30:54 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:31:21 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:31:45 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.1264579296112 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:32:06 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:32:35 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:32:57 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:33:24 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:33:47 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.51606678962708 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:34:09 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:34:38 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:34:59 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:35:26 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:35:49 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.71420907974243 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:36:11 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:36:39 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:37:01 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:37:28 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:37:51 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.45142483711243 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:38:13 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:38:42 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:39:03 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:39:30 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:39:54 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.4536783695221 seconds. 
Discarding model... 

Training complete taking 3063.7988176345825 total seconds. 
Now scoring model... 
Scoring complete taking 1.0121870040893555 seconds. 
Saved predicted values as A2-A2-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (160.68993206689294,), 'R2_train': 0.22151120923503964, 'MAE_train': 11.717667463039964, 'MSE_test': 160.64806244174207, 'R2_test': 0.03164337459265276, 'MAE_test': 11.904031966870976}. 
Saved model results as A2-A2-CZ_Hadamard_results.json. 
