/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:49:02 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:13 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:41 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:02 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:28 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:51 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.06083250045776 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:13 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:41 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:02 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:29 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:53 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.44992065429688 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:15 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:53:43 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:04 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:31 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:55 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 123.32460069656372 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:17 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:45 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:07 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:33 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:56 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.28164291381836 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:18 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:46 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:09 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:35 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:58 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.98607301712036 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:20 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:59:49 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:00:11 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:00:36 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:00 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.24942636489868 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:01:22 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:01:50 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:02:13 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:02:39 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:03:04 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 123.80724000930786 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:03:26 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:03:54 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:04:17 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:04:43 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:05:08 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.9531569480896 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:29 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:05:57 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:06:20 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:45 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:10 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.94698071479797 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:07:31 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:08:00 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:08:22 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:08:48 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:09:12 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.19174551963806 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:09:33 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:10:02 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:10:24 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:10:50 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:11:15 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.2891047000885 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:11:36 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:12:04 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:12:26 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:12:52 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:13:17 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.61806964874268 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:13:38 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:14:08 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:14:29 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:14:55 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:15:19 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.30983018875122 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:15:41 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:16:10 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:16:31 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:16:57 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:17:22 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.15837121009827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:17:43 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:18:12 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:18:33 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:18:59 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:19:25 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 123.23904657363892 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:19:46 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:20:15 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:20:36 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:21:09 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:21:33 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 127.6410698890686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:21:54 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:22:23 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:22:44 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:23:11 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:23:35 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.38072443008423 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:23:56 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:24:25 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:24:47 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:25:14 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:25:37 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.08430743217468 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:25:58 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:26:27 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:26:48 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:27:15 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:27:39 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.15012431144714 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:28:00 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:28:30 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:28:51 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:29:19 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:29:42 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 123.41317915916443 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:30:04 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:30:33 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:30:54 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:31:21 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:31:45 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.1264579296112 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:32:06 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:32:35 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:32:57 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:33:24 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:33:47 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.51606678962708 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:34:09 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:34:38 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:34:59 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:35:26 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:35:49 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.71420907974243 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:36:11 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:36:39 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:37:01 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:37:28 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:37:51 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.45142483711243 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:38:13 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:38:42 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Sun Mar 24 18:39:03 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:39:30 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Sun Mar 24 18:39:54 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.4536783695221 seconds. 
Discarding model... 

Training complete taking 3063.7988176345825 total seconds. 
Now scoring model... 
Scoring complete taking 1.0121870040893555 seconds. 
Saved predicted values as A2-A2-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (160.68993206689294,), 'R2_train': 0.22151120923503964, 'MAE_train': 11.717667463039964, 'MSE_test': 160.64806244174207, 'R2_test': 0.03164337459265276, 'MAE_test': 11.904031966870976}. 
Saved model results as A2-A2-CZ_Hadamard_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 12:26:24 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:26:33 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:27:03 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:27:24 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:27:49 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:28:13 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 120.84910345077515 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:28:34 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:29:03 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:29:24 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:29:49 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:30:14 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 120.34766745567322 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:30:38 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:31:07 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:31:28 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:31:54 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:32:19 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 125.08952808380127 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:32:39 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:33:08 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:33:29 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:33:54 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:34:18 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 119.265545129776 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:34:38 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:35:07 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:35:28 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:35:53 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:36:19 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.61443734169006 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:36:40 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:37:11 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:37:32 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:37:58 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:38:22 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.60429453849792 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:38:43 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:39:12 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:39:33 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:40:00 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:40:23 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.41024160385132 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:40:44 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:41:14 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:41:35 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:42:02 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:42:25 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.69404745101929 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:42:46 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:43:16 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:43:37 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:44:05 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:44:28 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.66771578788757 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:44:49 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:45:18 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:45:39 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:46:06 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:46:30 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.00552439689636 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:46:51 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:47:20 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:47:41 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:48:08 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:48:31 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.57437562942505 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:48:52 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:49:21 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:49:42 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:50:09 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:50:33 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.4538848400116 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:50:54 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:51:24 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:51:45 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:52:11 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:52:35 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 122.00648021697998 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:52:56 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:53:25 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:53:46 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:54:13 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:54:36 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.35717582702637 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:54:59 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:55:28 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:55:49 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:56:16 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:56:39 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 123.15547299385071 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:57:02 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:57:30 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:57:51 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:58:18 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 12:58:41 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.61822962760925 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:59:03 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:59:31 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 12:59:52 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 13:00:19 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 13:00:42 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.48160290718079 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:01:04 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 13:01:32 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 13:01:53 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 13:02:20 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 13:02:44 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.49036145210266 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 13:03:06 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 13:03:34 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 13:03:55 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 13:04:22 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 13:04:45 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.11698865890503 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 13:05:07 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 13:05:35 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 13:05:56 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 13:06:23 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 13:06:46 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 120.72875452041626 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 13:07:08 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 13:07:36 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 13:07:57 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 13:08:23 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 13:08:46 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 120.33015561103821 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 13:09:08 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 13:09:36 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 13:09:57 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 13:10:24 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 13:10:47 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 121.18288111686707 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:11:21 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 13:11:49 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 13:12:11 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 13:12:36 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 13:12:59 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 132.86908292770386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 13:13:21 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 13:13:48 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 13:14:10 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 13:14:35 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 13:14:58 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 119.37561011314392 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 13:15:20 2024]  Iteration number: 0 with current cost as 0.2800072538285152 and parameters 
[-4.07508996  2.23743479 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 13:15:48 2024]  Iteration number: 0 with current cost as 0.2480541862739316 and parameters 
[-4.43966146  2.23743478 -2.12427949 -0.11653103  0.55388723]. 
Working on 0.6 fold... 
[Thu Apr  4 13:16:10 2024]  Iteration number: 0 with current cost as 0.2509413093034531 and parameters 
[-4.16614267  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 13:16:36 2024]  Iteration number: 0 with current cost as 0.2577925388679121 and parameters 
[-4.18975243  2.23743464 -2.12427953 -0.11653092  0.55388718]. 
Working on 1.0 fold... 
[Thu Apr  4 13:16:59 2024]  Iteration number: 0 with current cost as 0.2589418146145701 and parameters 
[-4.14791726  2.23743453 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 120.30034279823303 seconds. 
Discarding model... 

Training complete taking 3047.5907049179077 total seconds. 
Now scoring model... 
Scoring complete taking 0.9884788990020752 seconds. 
Saved predicted values as A2-A2-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (160.68993206689294,), 'R2_train': 0.22151120923503964, 'MAE_train': 11.717667463039964, 'MSE_test': 160.64806244174207, 'R2_test': 0.03164337459265276, 'MAE_test': 11.904031966870976}. 
Saved model results as A2-A2-CZ_Hadamard_results.json. 
