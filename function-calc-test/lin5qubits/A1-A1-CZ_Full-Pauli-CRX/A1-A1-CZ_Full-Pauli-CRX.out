test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Fri Mar 15 21:16:51 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 21:17:00 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 21:21:19 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Fri Mar 15 21:21:37 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 21:25:25 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Fri Mar 15 21:28:02 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 21:32:15 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Fri Mar 15 21:32:50 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 21:37:24 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Fri Mar 15 21:38:15 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 21:42:11 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1651.3564491271973 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 21:44:31 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 21:48:50 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Fri Mar 15 21:49:08 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 21:52:56 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Fri Mar 15 21:55:34 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 21:59:49 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Fri Mar 15 22:00:24 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 22:05:00 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Fri Mar 15 22:05:52 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 22:09:49 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1655.553985118866 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 22:12:06 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 22:16:18 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Fri Mar 15 22:16:36 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 22:20:22 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Fri Mar 15 22:22:58 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 22:27:11 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Fri Mar 15 22:27:46 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 22:32:20 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Fri Mar 15 22:33:12 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 22:37:07 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1638.9996359348297 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 22:39:25 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 22:43:40 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Fri Mar 15 22:43:57 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 22:47:41 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Fri Mar 15 22:50:15 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 22:54:26 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Fri Mar 15 22:55:00 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 22:59:34 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Fri Mar 15 23:00:26 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 23:04:21 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1634.004897594452 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 23:06:40 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 23:10:55 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Fri Mar 15 23:11:12 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 23:14:57 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Fri Mar 15 23:17:32 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 23:21:41 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Fri Mar 15 23:22:15 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 23:26:49 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Fri Mar 15 23:27:42 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 23:31:37 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1637.6458899974823 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 23:33:57 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 23:38:15 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Fri Mar 15 23:38:32 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 23:42:19 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Fri Mar 15 23:44:56 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 23:49:07 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Fri Mar 15 23:49:42 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 23:54:14 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Fri Mar 15 23:55:06 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Mar 15 23:58:59 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1642.1569237709045 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sat Mar 16 00:01:19 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 00:05:35 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 00:05:52 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 00:09:38 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 00:12:14 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 00:16:25 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 00:17:00 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 00:21:33 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Sat Mar 16 00:22:25 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 00:26:17 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1635.8340468406677 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sat Mar 16 00:28:35 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 00:32:50 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 00:33:08 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 00:36:54 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 00:39:30 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 00:43:41 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 00:44:15 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 00:48:49 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sat Mar 16 00:49:41 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 00:53:36 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1639.5996644496918 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sat Mar 16 00:55:55 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:00:10 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 01:00:27 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:04:12 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 01:06:49 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:10:59 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 01:11:33 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:16:07 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Sat Mar 16 01:16:59 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:20:54 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1639.3907315731049 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sat Mar 16 01:23:14 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:27:32 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 01:27:50 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:31:38 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 01:34:16 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:38:32 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 01:39:07 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:43:45 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sat Mar 16 01:44:37 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:48:32 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1657.103803396225 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sat Mar 16 01:50:52 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:55:12 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 01:55:30 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 01:59:20 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 02:02:00 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 02:06:15 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 02:06:50 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 02:11:29 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Sat Mar 16 02:12:22 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 02:16:22 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1672.8375718593597 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sat Mar 16 02:18:44 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 02:23:06 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 02:23:24 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 02:27:14 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 02:29:55 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 02:34:12 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 02:34:47 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 02:39:22 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sat Mar 16 02:40:14 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 02:44:11 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1667.658040523529 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sat Mar 16 02:46:32 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 02:50:52 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 02:51:09 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 02:54:56 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 02:57:33 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 03:01:45 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 03:02:19 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 03:06:48 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Sat Mar 16 03:07:38 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 03:11:29 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1633.4327552318573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sat Mar 16 03:13:45 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 03:17:58 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 03:18:15 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 03:21:57 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 03:24:33 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 03:28:45 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 03:29:20 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 03:33:54 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sat Mar 16 03:34:47 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 03:38:41 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1633.7542960643768 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sat Mar 16 03:40:59 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 03:45:13 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 03:45:31 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 03:49:16 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 03:51:53 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 03:56:06 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 03:56:41 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 04:01:12 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Sat Mar 16 04:02:04 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 04:05:58 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1637.2295622825623 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sat Mar 16 04:08:16 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 04:12:32 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 04:12:50 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 04:16:36 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 04:19:11 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 04:23:22 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 04:23:57 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 04:28:35 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sat Mar 16 04:29:28 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 04:33:26 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1651.1728382110596 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sat Mar 16 04:35:47 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 04:40:08 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 04:40:25 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 04:44:14 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 04:46:52 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 04:51:06 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 04:51:41 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 04:56:20 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Sat Mar 16 04:57:13 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 05:01:15 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1670.9623749256134 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sat Mar 16 05:03:39 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 05:08:01 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 05:08:19 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 05:12:10 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 05:14:49 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 05:19:05 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 05:19:40 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 05:24:18 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sat Mar 16 05:25:11 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 05:29:06 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1667.2798745632172 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sat Mar 16 05:31:26 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 05:35:43 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 05:36:01 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 05:39:46 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 05:42:19 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 05:46:28 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 05:47:03 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 05:51:34 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Sat Mar 16 05:52:25 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 05:56:15 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1627.5341861248016 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sat Mar 16 05:58:33 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 06:02:45 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 06:03:02 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 06:06:44 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 06:09:20 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 06:13:34 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 06:14:09 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 06:18:43 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sat Mar 16 06:19:35 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 06:23:30 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1637.414290189743 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sat Mar 16 06:25:51 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 06:30:08 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 06:30:25 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 06:34:15 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 06:36:54 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 06:41:10 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 06:41:45 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 06:46:23 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Sat Mar 16 06:47:16 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 06:51:15 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1665.0058529376984 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sat Mar 16 06:53:36 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 06:57:54 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 06:58:11 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 07:01:55 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 07:04:30 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 07:08:42 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 07:09:17 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 07:13:52 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sat Mar 16 07:14:45 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 07:18:38 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1640.0765974521637 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sat Mar 16 07:20:55 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 07:25:07 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 07:25:24 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 07:29:10 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 07:31:46 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 07:35:56 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 07:36:31 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 07:41:03 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Sat Mar 16 07:41:55 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 07:45:49 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1632.4963738918304 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sat Mar 16 07:48:08 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 07:52:19 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 07:52:36 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 07:56:15 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 07:58:48 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 08:02:59 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 08:03:34 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 08:08:07 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sat Mar 16 08:08:58 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 08:12:52 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1622.5124428272247 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sat Mar 16 08:15:11 2024]  Iteration number: 0 with current cost as 0.21201277424847365 and parameters 
[-2.88931081  2.17449119 -2.12505034 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56329213  1.14432445
  1.2631463  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 08:19:28 2024]  Iteration number: 50 with current cost as 0.1911904305693307 and parameters 
[-4.25816981  1.63861826 -3.14990317 -0.11653179  0.55389409 -2.77010657
  3.06857439  2.18960864  1.18552595 -1.06648539  1.52716786  1.14431991
  0.07663114 -1.87354822  0.72965524  2.88576391 -0.5453545  -0.47523164
 -2.02654129  0.72896631  1.60512449  2.83075219 -1.2645709  -0.25136307]. 
Working on 0.4 fold... 
[Sat Mar 16 08:19:46 2024]  Iteration number: 0 with current cost as 0.17949847975852887 and parameters 
[-2.89384769  2.18018939 -2.11263645 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56763763  1.14432445
  1.2833272  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 08:23:33 2024]  Iteration number: 50 with current cost as 0.1617427251705241 and parameters 
[-3.44429901  1.56494872 -3.20364396 -0.11651243  0.55389417 -2.77011018
  3.06860297  2.18960146  1.1855135  -1.06648897 -0.15099882  1.1443318
  1.71036774 -1.87352834  0.72963984  2.88577597 -0.54532662 -0.47523664
 -2.02653655  0.72898995  1.60511855  2.83077103 -1.2645669  -0.25135684]. 
Working on 0.6 fold... 
[Sat Mar 16 08:26:13 2024]  Iteration number: 0 with current cost as 0.18080715669057554 and parameters 
[-2.88101089  2.18155671 -2.11658464 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.55553983  1.14432445
  1.2571905  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 08:30:30 2024]  Iteration number: 50 with current cost as 0.16078258724975297 and parameters 
[-1.88091951  1.56456035 -3.02987375 -0.11653115  0.55388639 -2.77011028
  3.06858575  2.1896039   1.18552121 -1.06648031  2.185689    1.14432683
 -0.62603974 -1.8735461   0.72965446  2.88578366 -0.5453406  -0.47522715
 -2.02654189  0.72897095  1.60512525  2.83076905 -1.26456909 -0.25135948]. 
Working on 0.8 fold... 
[Sat Mar 16 08:31:06 2024]  Iteration number: 0 with current cost as 0.18177760998270015 and parameters 
[-2.89055091  2.17927127 -2.12179402 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.56531565  1.14432445
  1.2690256  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 08:35:44 2024]  Iteration number: 50 with current cost as 0.1636797767171304 and parameters 
[-4.4152057   1.56538764 -3.07499653 -0.11652019  0.55386152 -2.77019705
  3.06853954  2.18958406  1.18550524 -1.06651751  1.5398964   1.14429715
  0.19685482 -1.87357298  0.72961274  2.88579998 -0.54535378 -0.47523609
 -2.0266217   0.72895925  1.60509092  2.83075548 -1.26456609 -0.25137724]. 
Working on 1.0 fold... 
[Sat Mar 16 08:36:37 2024]  Iteration number: 0 with current cost as 0.1902455517092645 and parameters 
[-2.88561533  2.18291712 -2.11430392 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.5580282   1.14432445
  1.2657081  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Sat Mar 16 08:40:35 2024]  Iteration number: 50 with current cost as 0.17407681304904654 and parameters 
[-3.95363332  1.58069647 -2.70245043 -0.11651769  0.55392625 -2.77008914
  3.06859874  2.18959137  1.18554245 -1.06645573  0.07069323  1.14436336
  1.48547103 -1.87352205  0.72964536  2.88579582 -0.54531366 -0.47518903
 -2.02652643  0.72900736  1.60515153  2.8307747  -1.26454627 -0.25134279]. 
Training complete taking 1664.5582983493805 seconds. 
Discarding model... 

Training complete taking 41155.57168650627 total seconds. 
Now scoring model... 
Scoring complete taking 0.5242087841033936 seconds. 
Saved predicted values as A1-A1-CZ_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (107.50648481434959,), 'R2_train': 0.4791671619621163, 'MAE_train': 7.544483719821313, 'MSE_test': 123.74028845422231, 'R2_test': 0.254116568023246, 'MAE_test': 8.443883824461016}. 
Saved model results as A1-A1-CZ_Full-Pauli-CRX_results.json. 
