test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Tue Mar 19 08:33:16 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 08:33:26 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:34:57 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:36:54 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:38:47 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:40:33 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 528.6674120426178 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 08:42:15 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:43:44 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:45:40 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:47:31 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:49:16 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 523.947744846344 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 08:50:59 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:52:29 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:54:26 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:56:19 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:58:05 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 528.6947596073151 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 08:59:48 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 09:01:18 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 09:03:14 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 09:05:04 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Tue Mar 19 09:06:48 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 521.5972061157227 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 09:08:29 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 09:09:57 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 09:11:50 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 09:13:41 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 09:15:25 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 516.7557780742645 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 09:17:06 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 09:18:34 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 09:20:27 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 09:22:20 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 09:24:05 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 520.6497094631195 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 09:25:47 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 09:27:14 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 09:29:09 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 09:31:01 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 09:32:46 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 519.8894109725952 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 09:34:26 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 09:35:55 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 09:37:50 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 09:39:43 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 09:41:28 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 523.7781915664673 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 09:43:10 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 09:44:39 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 09:46:34 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 09:48:26 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 09:50:11 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 522.1982064247131 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 09:51:53 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 09:53:21 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 09:55:15 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 09:57:08 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 09:58:53 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 521.7098019123077 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 10:00:34 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 10:02:03 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 10:03:57 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 10:05:49 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 10:07:35 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 522.7893679141998 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 10:09:17 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 10:10:46 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 10:12:42 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 10:14:33 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 10:16:17 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 522.4747037887573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.2 fold... 
[Tue Mar 19 10:17:59 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 10:19:28 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 10:21:23 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 10:23:14 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 10:25:00 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 531.972097158432 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 10:26:52 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 10:28:26 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 10:30:24 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 10:32:19 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 10:34:06 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 536.675666809082 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 10:35:48 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 10:37:20 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 10:39:17 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 10:41:15 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 10:43:01 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 534.8278958797455 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 10:44:43 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 10:46:13 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 10:48:09 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 10:50:03 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 10:51:49 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 531.1508433818817 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 10:53:34 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Tue Mar 19 10:55:05 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 10:57:01 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 10:58:54 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 11:00:40 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 528.6573572158813 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 11:02:23 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 11:03:53 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 11:05:50 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 11:07:47 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 11:09:35 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 536.5952181816101 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 11:11:20 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 11:12:50 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 11:14:48 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 11:16:42 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 11:18:29 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 533.2256557941437 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 11:20:13 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 11:21:43 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 11:23:39 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 11:25:33 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 11:27:27 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 544.2160801887512 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 11:29:17 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 11:30:56 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Tue Mar 19 11:32:59 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 11:35:02 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 11:36:56 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 569.9486150741577 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 11:38:47 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 11:40:22 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 11:42:30 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 11:44:27 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 11:46:15 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 554.7178905010223 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 11:48:02 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 11:49:36 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 11:51:38 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 11:53:40 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 11:55:34 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 560.427533864975 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 11:57:23 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 12:09:44 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 12:27:09 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Mar 19 12:31:13 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 12:33:17 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2271.230321407318 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 12:35:16 2024]  Iteration number: 0 with current cost as 0.3946272296631361 and parameters 
[-2.82278494  2.0256901  -2.40223636 -0.11653103  0.55388708 -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648312  1.67589967  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Mar 19 12:37:02 2024]  Iteration number: 0 with current cost as 0.3329604614022771 and parameters 
[-2.99138249  1.96502368 -2.3306498  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648316  2.00049886  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Mar 19 12:39:11 2024]  Iteration number: 0 with current cost as 0.3345007694083931 and parameters 
[-2.95591232  1.98219276 -2.37226945 -0.11653103  0.55388712 -2.77010897
  3.06858502  2.18960149  1.18552002 -1.06648312  1.91767049  1.14432449
  1.31029902 -1.87354676  0.72965077  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Tue Mar 19 12:41:16 2024]  Iteration number: 0 with current cost as 0.3321590371089672 and parameters 
[-2.95929422  1.989361   -2.3831704  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648312  1.9106503   1.14432445
  1.31029906 -1.87354673  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Mar 19 12:43:14 2024]  Iteration number: 0 with current cost as 0.34649450653514635 and parameters 
[-2.94362125  1.98017033 -2.35602868 -0.11653095  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648308  1.90922735  1.14432449
  1.31029906 -1.87354673  0.7296508   2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 594.4872853755951 seconds. 
Discarding model... 

Training complete taking 15101.285094976425 total seconds. 
Now scoring model... 
Scoring complete taking 0.4332883358001709 seconds. 
Saved predicted values as A2-A2-CNOT_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (111.4019556213289,), 'R2_train': 0.46029491328431427, 'MAE_train': 9.491056900738949, 'MSE_test': 128.96323955410617, 'R2_test': 0.22263359073190603, 'MAE_test': 9.76920095333099}. 
Saved model results as A2-A2-CNOT_Modified-Pauli-CRX_results.json. 
