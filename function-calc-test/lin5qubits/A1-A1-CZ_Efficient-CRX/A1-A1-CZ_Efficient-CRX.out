test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Fri Mar 15 06:55:29 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 06:56:01 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 06:57:06 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 06:57:51 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 06:58:49 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 06:59:47 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 283.7236077785492 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 07:00:45 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:01:50 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:02:35 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 07:03:33 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:04:31 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 284.0933084487915 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 07:05:29 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:06:33 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:07:18 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 07:08:17 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:09:15 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 283.30651569366455 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 07:10:12 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:11:17 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:12:02 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 07:12:59 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:13:56 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 281.7487349510193 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 07:14:54 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:15:58 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:16:43 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Fri Mar 15 07:17:40 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:18:37 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 280.27302861213684 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 07:19:34 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:20:37 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:21:22 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 07:22:19 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:23:16 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 278.728102684021 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 07:24:13 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:25:17 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:26:02 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 07:27:00 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:27:58 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 282.02425599098206 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 07:28:55 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:30:00 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:30:45 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 07:31:43 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:32:40 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 283.21329259872437 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 07:33:38 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:34:42 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:35:27 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 07:36:24 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:37:21 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 280.80891585350037 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 07:38:19 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:39:22 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:40:07 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Fri Mar 15 07:41:04 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:42:01 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 278.9482436180115 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 07:42:58 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:44:02 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:44:48 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 07:45:45 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:46:42 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 281.6959431171417 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 07:47:39 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:48:44 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:49:28 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 07:50:25 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:51:23 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 280.91104555130005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 07:52:21 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:53:25 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:54:09 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 07:55:06 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 07:56:04 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 281.33257842063904 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 07:57:02 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 07:58:06 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 07:58:50 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 07:59:47 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:00:45 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 280.97813415527344 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 08:01:43 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 08:02:48 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 08:03:32 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Fri Mar 15 08:04:30 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:05:27 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 281.1482274532318 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 08:06:23 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 08:07:26 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 08:08:11 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 08:09:09 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:10:06 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 279.73631525039673 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 08:11:04 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 08:12:08 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 08:12:53 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 08:13:51 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:14:48 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 282.3538920879364 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 08:15:46 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 08:16:50 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 08:17:36 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 08:18:34 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:19:31 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 282.47459840774536 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 08:20:29 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 08:21:33 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 08:22:18 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 08:23:15 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:24:13 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 281.7504541873932 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 08:25:10 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 08:26:14 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 08:26:59 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Fri Mar 15 08:27:56 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:28:54 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 281.0288543701172 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 08:29:51 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 08:30:55 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 08:31:40 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 08:32:37 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:33:33 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 279.2278664112091 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 08:34:30 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 08:35:33 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 08:36:18 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 08:37:14 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:38:11 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 277.70062160491943 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 08:39:08 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 08:40:12 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 08:40:57 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 08:41:55 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:42:53 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 281.9713463783264 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 08:43:50 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 08:44:54 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 08:45:38 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. 
Working on 0.8 fold... 
[Fri Mar 15 08:46:37 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:47:33 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 280.55722308158875 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 08:48:31 2024]  Iteration number: 0 with current cost as 0.3700387253127946 and parameters 
[-1.82176683  2.23743458 -2.12427964 -0.11653103  0.55388697 -2.77010903
  3.06858488  2.18960145  1.18551998 -1.06648319  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.4 fold... 
[Fri Mar 15 08:49:35 2024]  Iteration number: 0 with current cost as 0.3122912106738731 and parameters 
[-1.54439865  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010902
  3.06858488  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354675]. 
Working on 0.6 fold... 
[Fri Mar 15 08:50:20 2024]  Iteration number: 0 with current cost as 0.3315072465391975 and parameters 
[-1.43602946  2.23743458 -2.12427958 -0.11653103  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18551998 -1.06648314  0.6027151   1.14432439
  1.31029899 -1.87354674]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Fri Mar 15 08:51:18 2024]  Iteration number: 0 with current cost as 0.33672965815469186 and parameters 
[-1.41170499  2.23743464 -2.12427958 -0.11653097  0.55388708 -2.77010903
  3.06858492  2.18960151  1.18552004 -1.06648314  0.60271516  1.14432451
  1.31029904 -1.87354668]. 
Working on 1.0 fold... 
[Fri Mar 15 08:52:15 2024]  Iteration number: 0 with current cost as 0.33971858859910875 and parameters 
[-1.4090705   2.23743458 -2.12427964 -0.11653097  0.55388702 -2.77010903
  3.06858492  2.18960145  1.18551993 -1.06648314  0.60271516  1.14432439
  1.31029899 -1.87354674]. 
Training complete taking 281.6552379131317 seconds. 
Discarding model... 

Training complete taking 7031.390629291534 total seconds. 
Now scoring model... 
Scoring complete taking 0.7694263458251953 seconds. 
Saved predicted values as A1-A1-CZ_Efficient-CRX_predicted_values.csv
Model scores: {'MSE_train': (206.9387927548426,), 'R2_train': -0.0025489989442195604, 'MAE_train': 12.577271517852694, 'MSE_test': 191.37228810339, 'R2_test': -0.1535565402258443, 'MAE_test': 12.013220429265761}. 
Saved model results as A1-A1-CZ_Efficient-CRX_results.json. 
