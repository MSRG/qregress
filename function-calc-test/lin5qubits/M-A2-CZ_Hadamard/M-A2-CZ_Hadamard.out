/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:31:46 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:32:01 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:32:25 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:33:03 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:33:24 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:34:12 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.87951374053955 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:34:34 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:34:58 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:37 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:36:01 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:36:47 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 153.14357566833496 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:08 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:37:34 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:14 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:36 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:22 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 155.66203498840332 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:44 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:10 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:48 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:12 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:58 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 155.99509692192078 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:21 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:46 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:23 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:43 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:29 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 151.43864274024963 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:51 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:15 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:52 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:13 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:57 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 148.00932025909424 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:18 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:43 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:21 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:43 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:27 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.96991991996765 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:49 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:13 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:51 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:13 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:00 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.4884283542633 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:22 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:47 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:25 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:47 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:32 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 151.82316613197327 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:53 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:18 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:55 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:16 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:57:01 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.24377536773682 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:23 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:48 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:24 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:47 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:34 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.63005447387695 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:55 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:00:20 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:00:58 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:01:19 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:02:07 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 154.21809005737305 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:02:29 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:02:54 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:03:30 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:03:53 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:04:38 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 151.98182034492493 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:00 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:05:25 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:06:04 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:26 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:13 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.665283203125 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:07:32 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:07:58 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:08:36 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:08:58 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:09:43 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 150.14155840873718 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:10:03 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:10:29 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:11:08 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:11:31 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:12:19 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 157.1207718849182 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:12:41 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:13:07 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:13:45 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:14:07 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:14:53 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 153.3220980167389 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:15:15 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:15:39 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:16:18 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:16:37 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:17:23 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 150.16868591308594 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:17:46 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:18:12 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:18:49 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:19:10 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:19:56 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 154.06516075134277 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:20:19 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:20:44 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:21:21 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:21:42 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:22:27 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.63927698135376 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:22:49 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:23:14 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:23:51 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:24:13 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:25:00 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 152.88154816627502 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:25:21 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:25:44 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:26:20 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:26:41 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:27:28 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 148.32243394851685 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:27:49 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:28:12 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:28:49 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:29:10 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:29:55 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 146.834481716156 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:30:16 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:30:41 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:31:19 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:31:42 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:32:28 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 153.0562388896942 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:32:50 2024]  Iteration number: 0 with current cost as 0.25291769505353734 and parameters 
[-5.2437286   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:33:15 2024]  Iteration number: 0 with current cost as 0.41685395039657097 and parameters 
[-7.81469223  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:33:54 2024]  Iteration number: 0 with current cost as 0.21939999362498738 and parameters 
[-5.18120956  2.23743449 -2.12427964 -0.11653117  0.55388679]. 
Working on 0.8 fold... 
[Sun Mar 24 18:34:14 2024]  Iteration number: 0 with current cost as 0.46034339835342974 and parameters 
[-8.22478998  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:34:57 2024]  Iteration number: 0 with current cost as 0.232740568182248 and parameters 
[-5.04161793  2.23743464 -2.12427949 -0.11653103  0.55388708]. 
Training complete taking 149.87980365753174 seconds. 
Discarding model... 

Training complete taking 3797.5821619033813 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.9467060565948486 seconds. 
Saved predicted values as M-A2-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (144.359133358489,), 'R2_train': 0.3006284481012492, 'MAE_train': 10.101884324137085, 'MSE_test': 145.671770686518, 'R2_test': 0.12191767435561351, 'MAE_test': 9.756547317239868}. 
Saved model results as M-A2-CZ_Hadamard_results.json. 
