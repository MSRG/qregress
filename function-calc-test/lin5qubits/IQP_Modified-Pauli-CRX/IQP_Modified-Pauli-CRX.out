/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:35:02 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:35:20 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 17:43:21 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:53 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 17:53:14 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:45 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 18:02:59 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:05:03 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 18:12:23 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 18:16:08 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 18:24:01 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3027.5511679649353 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:25:48 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 18:33:53 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 18:36:32 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 18:44:40 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 18:47:37 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 18:55:17 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 18:57:33 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 19:05:18 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 19:09:06 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 19:17:16 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3197.4852137565613 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 19:19:04 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 19:27:21 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 19:30:06 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 19:37:48 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 19:40:22 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 19:48:06 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 19:50:19 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 19:57:57 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 20:02:03 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 20:10:27 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3186.4155128002167 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 20:12:12 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 20:20:30 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 20:23:07 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 20:31:51 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 20:34:45 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 20:42:29 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 20:44:58 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 20:52:58 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 20:56:46 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 21:05:06 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3287.6121351718903 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 21:06:57 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 21:15:40 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 21:18:33 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 21:26:55 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 21:29:27 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 21:36:42 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 21:38:48 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 21:46:10 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 21:49:39 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 21:57:03 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3105.4578630924225 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 21:58:44 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 22:06:17 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 22:08:46 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 22:16:08 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 22:18:41 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 22:25:44 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 22:27:47 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 22:35:31 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 22:39:30 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 22:48:05 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3075.0500276088715 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 22:49:58 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 22:58:55 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 23:01:46 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 23:10:06 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Sun Mar 24 23:12:59 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 23:20:00 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Sun Mar 24 23:22:06 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 23:29:18 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Sun Mar 24 23:32:51 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 23:40:14 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3114.898005247116 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 23:41:54 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 23:49:32 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Sun Mar 24 23:52:03 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Sun Mar 24 23:59:24 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 00:01:56 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 00:09:04 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 00:11:15 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 00:18:34 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 00:22:02 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 00:29:23 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2948.730294942856 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 00:31:03 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 00:38:49 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 00:41:34 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 00:49:30 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 00:52:16 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 00:59:52 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 01:02:03 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 01:09:34 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 01:13:12 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 01:20:32 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3068.0783393383026 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 01:22:09 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 01:29:41 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 01:32:15 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 01:40:14 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 01:43:00 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 01:50:49 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 01:53:02 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 02:01:09 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 02:05:00 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 02:13:08 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3162.486136198044 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 25 02:14:53 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 02:23:21 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 02:26:24 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 02:35:04 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 02:37:41 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 02:44:48 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 02:46:56 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 02:55:04 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 02:59:07 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 03:07:35 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3269.0218493938446 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 03:09:24 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 03:17:58 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 03:20:39 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 03:29:40 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 03:32:37 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 03:40:32 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 03:42:53 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 03:51:07 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 03:55:07 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 04:03:51 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3373.262760400772 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 04:05:37 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 04:14:06 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 04:17:03 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 04:25:16 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 04:28:06 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 04:36:05 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 04:38:27 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 04:46:26 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 04:50:30 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 04:58:52 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3313.719706058502 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 05:00:50 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 05:09:30 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 05:12:34 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 05:20:21 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 05:23:26 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 05:31:51 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 05:34:17 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 05:43:03 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 05:46:44 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 05:55:23 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3391.0673744678497 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 05:57:24 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 06:04:59 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 06:07:26 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 06:14:49 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 06:17:22 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 06:24:34 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 06:26:36 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 06:33:58 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 06:37:28 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 06:44:45 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2943.7900941371918 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 25 06:46:24 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 06:54:07 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 06:56:37 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 07:04:13 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 07:06:47 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 07:13:56 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 07:16:01 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 07:23:21 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 07:26:49 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 07:34:20 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2981.3851613998413 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 07:36:06 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 07:43:47 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 07:46:17 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 07:53:51 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 07:56:20 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 08:03:30 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 08:05:40 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 08:13:01 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 08:16:31 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 08:23:59 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2977.5194141864777 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 08:25:43 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 08:33:22 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 08:36:00 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 08:43:37 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 08:46:19 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 08:53:34 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 08:55:40 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 09:02:58 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 09:06:26 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 09:14:01 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3006.1911997795105 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 09:15:49 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 09:23:29 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 09:25:59 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 09:33:25 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 09:35:56 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 09:43:13 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 09:45:17 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 09:52:34 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 09:56:07 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 10:03:34 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2964.5434758663177 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 10:05:13 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 10:12:59 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 10:15:28 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 10:22:59 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 10:25:29 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 10:32:39 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 10:34:49 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 10:42:11 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 10:45:43 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 10:53:17 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3008.721667289734 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 25 10:55:24 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 11:03:40 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 11:06:13 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 11:13:36 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 11:16:15 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 11:23:30 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 11:25:36 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 11:32:54 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 11:36:28 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 11:44:01 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3020.0790510177612 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 11:45:42 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 11:53:26 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 11:56:00 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 12:03:29 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 12:06:04 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 12:13:20 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 12:15:25 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 12:22:48 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 12:26:22 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 12:33:54 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2991.701901435852 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 12:35:34 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 12:43:18 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 12:45:54 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 12:53:22 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 12:55:54 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 13:03:04 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 13:05:09 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 13:12:23 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 13:15:57 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 13:24:00 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3017.453793287277 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 13:25:55 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 13:34:33 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 13:37:25 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 13:45:53 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 13:48:30 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 13:55:55 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 13:58:03 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 14:06:20 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 14:10:01 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 14:18:15 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3264.3785133361816 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 14:20:18 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 14:29:02 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 25 14:31:43 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 14:39:50 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 25 14:42:39 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 14:50:46 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 25 14:53:00 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 15:00:23 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 25 15:03:55 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Mon Mar 25 15:11:18 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3162.7511007785797 seconds. 
Discarding model... 

Training complete taking 77859.35432910919 total seconds. 
Now scoring model... 
Scoring complete taking 0.9608676433563232 seconds. 
Saved predicted values as IQP_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (2.3010084365608274,), 'R2_train': 0.9888523863799226, 'MAE_train': 1.1002919371700344, 'MSE_test': 1.6933439173258258, 'R2_test': 0.9897928379806613, 'MAE_test': 1.1849113263979083}. 
Saved model results as IQP_Modified-Pauli-CRX_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 12:21:36 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:21:55 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 12:30:16 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 12:32:58 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 12:40:51 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 12:43:30 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 12:51:02 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 12:53:17 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 13:00:57 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:04:37 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 13:12:23 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3137.768650531769 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 13:14:11 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 13:22:11 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 13:24:54 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 13:32:39 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 13:35:17 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 13:42:45 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 13:44:57 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 13:52:32 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 13:56:11 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 14:03:56 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3100.7212612628937 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 14:05:53 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 14:13:47 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 14:16:24 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 14:24:13 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 14:26:51 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 14:34:25 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 14:36:36 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 14:44:31 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 14:48:10 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 14:55:58 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3110.6629600524902 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 14:57:42 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 15:05:40 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 15:08:22 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 15:16:12 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 15:18:57 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 15:26:34 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 15:28:45 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 15:36:23 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 15:40:03 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 15:48:10 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3131.695262670517 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 15:49:55 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 15:58:04 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 16:00:40 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 16:08:28 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 16:11:07 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 16:19:15 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 16:21:28 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 16:29:12 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 16:32:52 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 16:40:38 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3150.241716146469 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 16:42:24 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 16:50:19 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 16:53:00 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 17:00:45 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 17:03:24 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 17:10:57 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 17:13:26 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 17:21:05 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 17:24:45 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 17:32:38 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3119.514442205429 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 17:34:24 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 17:42:17 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 17:44:54 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 17:52:38 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 17:55:19 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 18:02:53 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 18:05:05 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 18:13:10 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 18:16:48 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 18:24:39 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3120.745208501816 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 18:26:24 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 18:34:19 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 18:36:55 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 18:44:40 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 18:47:18 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 18:54:56 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 18:57:30 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 19:05:07 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 19:08:45 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 19:16:30 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3110.0762088298798 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 19:18:16 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 19:26:11 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 19:28:48 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 19:36:37 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 19:39:15 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 19:46:43 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 19:48:54 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 19:56:35 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 20:00:14 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 20:08:08 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3097.889260292053 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 20:09:53 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 20:17:49 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 20:20:27 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 20:28:13 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 20:30:50 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 20:38:19 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 20:40:30 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 20:48:18 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 20:51:56 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 20:59:42 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3095.2316796779633 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:01:28 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 21:09:38 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:12:17 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 21:20:01 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:22:40 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 21:30:07 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:32:19 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 21:39:55 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:43:38 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 21:51:32 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3109.243936777115 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:53:18 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 22:01:16 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:03:54 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 22:11:39 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:14:17 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 22:21:44 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:23:55 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 22:31:32 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:35:11 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 22:42:58 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3086.337821483612 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:44:43 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 22:52:37 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:55:14 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 23:03:02 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:05:41 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 23:13:11 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:15:23 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 23:23:28 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:27:06 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 23:35:04 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3126.2353625297546 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:36:49 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 23:44:46 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:47:25 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 23:55:08 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:57:46 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 00:05:13 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:07:25 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 00:14:57 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:18:35 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 00:26:19 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3074.264279127121 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:28:04 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 00:35:57 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:38:36 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 00:46:20 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:48:58 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 00:56:31 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:58:42 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 01:06:32 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:10:11 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 01:18:22 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3123.490154027939 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:20:07 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 01:28:17 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:31:20 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 01:39:24 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:42:02 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 01:49:31 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:51:43 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 01:59:21 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:03:01 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 02:10:46 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3143.5777595043182 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:12:32 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 02:20:22 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:23:00 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 02:30:44 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:33:22 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 02:41:22 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:43:57 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 02:51:35 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:55:31 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 03:03:37 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3172.3679287433624 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:05:23 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 03:13:20 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:15:58 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 03:24:11 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:26:50 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 03:34:15 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:36:27 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 03:44:04 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:47:43 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 03:55:28 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3110.5176074504852 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:57:14 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 04:05:09 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:07:48 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 04:15:32 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:18:10 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 04:25:37 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:27:48 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 04:35:23 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:39:03 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 04:46:50 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3081.046754360199 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 04:48:35 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 04:56:30 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:59:08 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 05:06:52 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:09:29 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 05:16:55 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:19:06 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 05:26:44 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:30:22 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 05:38:06 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3075.551993370056 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 05:39:52 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 05:47:45 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:50:22 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 05:58:07 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:00:45 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 06:08:13 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:10:24 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 06:18:00 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:21:40 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 06:29:29 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3083.8072028160095 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 06:31:14 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 06:39:07 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 06:41:45 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 06:49:31 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:52:09 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 06:59:36 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:01:49 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 07:09:28 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 07:13:08 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 07:20:51 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3081.811985731125 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 07:22:36 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 07:30:29 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:33:08 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 07:40:51 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 07:43:28 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 07:50:59 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:53:11 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 08:00:46 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:04:27 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 08:12:12 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3080.462568998337 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 08:13:57 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 08:21:48 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 08:24:26 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 08:32:09 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:34:46 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 08:42:13 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:44:26 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 08:52:03 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:55:41 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 09:03:35 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3084.4705033302307 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 09:05:21 2024]  Iteration number: 0 with current cost as 0.12397467730277721 and parameters 
[-3.52158465  2.3579937  -2.09229509 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.7119746   1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 09:13:34 2024]  Iteration number: 50 with current cost as 0.004267534655693076 and parameters 
[-4.73273365  0.55037216 -1.68348211 -0.1165311   0.55388716 -2.77011089
  3.06858517  2.18960067  1.18551842 -1.066484    0.06197206  1.1443223
  1.31029671 -1.87354717  0.72965023  2.88578349 -0.54534365 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:16:11 2024]  Iteration number: 0 with current cost as 0.12332615730188941 and parameters 
[-3.38451544  2.33464167 -2.09232756 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.72288053  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 09:23:56 2024]  Iteration number: 50 with current cost as 0.003396155472121645 and parameters 
[-4.69702411  5.65600368 -1.67795158 -0.11653224  0.55388696 -2.77011021
  3.0685838   2.18960144  1.18552047 -1.06648411 -0.04455106  1.14432116
  1.31029905 -1.87354794  0.72964934  2.88578267 -0.54534498 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 09:26:33 2024]  Iteration number: 0 with current cost as 0.12700311563379268 and parameters 
[-3.42537056  2.34377434 -2.0933422  -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.70725714  1.14432445
  1.31029898 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 09:34:02 2024]  Iteration number: 50 with current cost as 0.0032875469680661556 and parameters 
[-4.70867921  5.49508534 -1.64974843 -0.1165314   0.55388483 -2.77011071
  3.06858338  2.18960004  1.18551791 -1.06648714 -0.02105731  1.14432228
  1.31029878 -1.87354512  0.72964546  2.88578271 -0.54534936 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:36:13 2024]  Iteration number: 0 with current cost as 0.12664828410077345 and parameters 
[-3.43720518  2.33946575 -2.0954369  -0.11653103  0.55388707 -2.77010898
  3.06858498  2.18960144  1.18551998 -1.06648309  0.7070499   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 09:43:49 2024]  Iteration number: 50 with current cost as 0.0034614196541789405 and parameters 
[-4.72560348  0.47627924 -1.74866612 -0.11653021  0.55388672 -2.77010874
  3.06858507  2.18960121  1.18552026 -1.06648237  0.05434759  1.14432509
  1.3102984  -1.87354614  0.72965125  2.88578325 -0.54534259 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 09:47:28 2024]  Iteration number: 0 with current cost as 0.1285872946904963 and parameters 
[-3.42277432  2.34341978 -2.09274905 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.71258782  1.14432446
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 09:55:14 2024]  Iteration number: 50 with current cost as 0.003974816349964446 and parameters 
[-4.70215435  5.46682699 -1.58041637 -0.11652678  0.55388908 -2.77010422
  3.06858686  2.18960104  1.18552352 -1.06648378 -0.02770989  1.14432712
  1.31029819 -1.87354184  0.72965259  2.8857825  -0.54534507 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 3097.829975128174 seconds. 
Discarding model... 

Training complete taking 77705.56460142136 total seconds. 
Now scoring model... 
Scoring complete taking 1.026853322982788 seconds. 
Saved predicted values as IQP_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (2.3010084365608274,), 'R2_train': 0.9888523863799226, 'MAE_train': 1.1002919371700344, 'MSE_test': 1.6933439173258258, 'R2_test': 0.9897928379806613, 'MAE_test': 1.1849113263979083}. 
Saved model results as IQP_Modified-Pauli-CRX_results.json. 
