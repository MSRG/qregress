test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Fri Mar 15 03:38:13 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 03:38:21 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 03:39:38 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 03:41:03 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 03:42:14 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 03:43:27 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 381.4401080608368 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 03:44:43 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 03:45:57 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 03:47:22 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 03:48:32 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 03:49:46 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 379.74149084091187 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 03:51:02 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 03:52:18 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 03:53:43 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 03:54:52 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 03:56:05 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 378.2580623626709 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 03:57:20 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 03:58:36 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 04:00:00 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 04:01:11 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Fri Mar 15 04:02:23 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 378.6994471549988 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 04:03:39 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 04:04:55 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 04:06:20 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 04:07:30 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 04:08:43 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 379.55158591270447 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 04:09:59 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 04:11:15 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 04:12:39 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 04:13:48 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 04:15:01 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 378.5955045223236 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 04:16:18 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 04:17:33 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 04:18:58 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 04:20:07 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 04:21:20 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 378.02138471603394 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 04:22:35 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 04:23:51 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 04:25:15 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 04:26:25 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 04:27:37 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 376.6295156478882 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 04:28:52 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 04:30:07 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 04:31:32 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 04:32:42 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 04:33:55 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 378.0966203212738 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 04:35:10 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 04:36:25 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 04:37:50 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 04:38:59 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 04:40:11 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 375.38822984695435 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 04:41:26 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 04:42:40 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 04:44:03 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 04:45:12 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 04:46:24 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 373.4958505630493 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 04:47:39 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 04:48:54 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 04:50:19 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 04:51:28 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 04:52:40 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 375.8808083534241 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.2 fold... 
[Fri Mar 15 04:53:55 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 04:55:09 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 04:56:32 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 04:57:40 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 04:58:52 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 372.5199410915375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 05:00:07 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 05:01:22 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 05:02:45 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 05:03:54 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 05:05:06 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 372.85208654403687 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 05:06:20 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 05:07:35 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 05:08:58 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 05:10:07 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 05:11:18 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 372.300500869751 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 05:12:32 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 05:13:46 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 05:15:08 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 05:16:18 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 05:17:30 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 372.1555371284485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 05:18:45 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Fri Mar 15 05:20:00 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 05:21:23 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 05:22:33 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 05:23:45 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 374.5839116573334 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 05:24:59 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 05:26:14 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 05:27:36 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 05:28:45 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 05:29:56 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 372.1782965660095 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 05:31:11 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 05:32:26 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 05:33:50 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 05:34:59 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 05:36:12 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 375.60422348976135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 05:37:27 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 05:38:42 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 05:40:06 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 05:41:16 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 05:42:29 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 375.8965530395508 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 05:43:43 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 05:44:59 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Fri Mar 15 05:46:22 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 05:47:32 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 05:48:45 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 377.58278799057007 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 05:50:00 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 05:51:16 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 05:52:40 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 05:53:49 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 05:55:01 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 376.195068359375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 05:56:17 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 05:57:32 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 05:58:56 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:00:06 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:01:18 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 377.0181586742401 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 06:02:34 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:03:49 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:05:12 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:06:22 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:07:35 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 376.2757058143616 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 06:08:50 2024]  Iteration number: 0 with current cost as 0.42077059383619764 and parameters 
[-3.13068052  1.76497685 -2.33071265 -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.77426429  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:10:05 2024]  Iteration number: 0 with current cost as 0.32273442527540636 and parameters 
[-3.17181257  1.62372212 -2.35276816 -0.11653106  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551995 -1.06648316  2.22034504  1.14432445
  1.31029899 -1.8735468   0.72965073  2.88578416 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:11:29 2024]  Iteration number: 0 with current cost as 0.34567405544082425 and parameters 
[-3.15941599  1.69751475 -2.34528949 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960141  1.18551998 -1.06648312  2.01990166  1.14432445
  1.31029902 -1.87354676  0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Fri Mar 15 06:12:38 2024]  Iteration number: 0 with current cost as 0.34791311164269956 and parameters 
[-3.15624354  1.7006583  -2.3438564  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  2.00393328  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:13:49 2024]  Iteration number: 0 with current cost as 0.34607399009197204 and parameters 
[-3.16151192  1.67429289 -2.34662262 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552002 -1.06648308  2.08248564  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 373.26129174232483 seconds. 
Discarding model... 

Training complete taking 9402.22302031517 total seconds. 
Now scoring model... 
Scoring complete taking 0.36622023582458496 seconds. 
Saved predicted values as A1-A1-CNOT_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (141.15084375548832,), 'R2_train': 0.3161715344747258, 'MAE_train': 10.84265530812114, 'MSE_test': 135.63034275672027, 'R2_test': 0.18244553330751478, 'MAE_test': 10.275606046240148}. 
Saved model results as A1-A1-CNOT_Modified-Pauli-CRX_results.json. 
