/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:35:49 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:25 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 17:37:28 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:32 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 17:39:54 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:17 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 378.73201537132263 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:38 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:46 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:48 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:08 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:33 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 374.9517698287964 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:56 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:04 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:09 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:33 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:51 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 379.85998153686523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:16 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:22 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:27 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:50 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:00:17 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 380.9870615005493 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:01:38 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:02:44 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:03:51 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:05:12 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:06:38 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 380.26891040802 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:07:57 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:09:03 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:10:04 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:11:24 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:12:50 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 378.13519072532654 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:14:14 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:15:16 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:16:23 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:17:43 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:19:02 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 369.11367082595825 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:20:23 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:21:28 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:22:33 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:23:56 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:25:24 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 381.91409969329834 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:26:46 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:27:53 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:29:02 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:30:30 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:31:53 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 390.2329730987549 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:33:16 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:34:23 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:35:29 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:36:53 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:38:16 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 381.30797719955444 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:39:37 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:40:42 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:41:50 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:43:13 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:44:33 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 381.26074838638306 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:45:59 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:47:08 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:48:18 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:49:37 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:51:00 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 388.7971751689911 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:52:25 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:53:28 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 18:54:32 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 18:55:53 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 18:57:13 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 365.31288409233093 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:58:33 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 18:59:39 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:00:47 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:02:08 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:03:34 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 382.44465827941895 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 19:04:54 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:06:00 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:07:06 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:08:29 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:09:53 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 382.98943758010864 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 19:11:17 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:12:21 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:13:28 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:14:51 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:16:12 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 380.2109520435333 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 19:17:37 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:18:43 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:19:47 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:21:13 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:22:37 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 384.59401655197144 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 19:24:01 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:25:10 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:26:21 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:27:43 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:29:13 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 391.6856174468994 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 19:30:34 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:31:39 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:32:49 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:34:15 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:35:39 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 388.7049162387848 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 19:37:05 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:38:09 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:39:16 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:40:41 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:42:06 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 385.33548617362976 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 19:43:30 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:44:37 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:45:45 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:47:10 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:48:38 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 388.8168776035309 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 19:49:56 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:51:05 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:52:15 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:53:37 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 19:54:58 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 380.0039310455322 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 19:56:19 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 19:57:25 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 19:58:30 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 19:59:52 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 20:01:19 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 386.16001081466675 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 20:02:45 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 20:03:51 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 20:05:02 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 20:06:31 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 20:07:57 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 396.46592473983765 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 20:09:20 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Sun Mar 24 20:10:26 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Sun Mar 24 20:11:33 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Sun Mar 24 20:12:59 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Sun Mar 24 20:14:24 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 385.134957075119 seconds. 
Discarding model... 

Training complete taking 9563.42207789421 total seconds. 
Now scoring model... 
Scoring complete taking 2.8811182975769043 seconds. 
Saved predicted values as IQP_ESU2_predicted_values.csv
Model scores: {'MSE_train': (206.6985994957776,), 'R2_train': -0.0013853432167307833, 'MAE_train': 12.570108849473945, 'MSE_test': 193.76124339760548, 'R2_test': -0.16795671817878066, 'MAE_test': 12.065264221858929}. 
Saved model results as IQP_ESU2_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 12:21:36 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:22:10 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 12:23:14 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:24:19 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 12:25:39 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 12:27:02 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 373.44654393196106 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:28:21 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 12:29:27 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:30:33 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 12:31:52 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 12:33:13 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 372.3797426223755 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 12:34:34 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 12:35:40 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:36:46 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 12:38:10 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 12:39:30 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 378.3549749851227 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:40:50 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 12:41:54 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:42:55 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 12:44:14 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 12:45:34 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 360.9399325847626 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:46:53 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 12:47:56 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:48:59 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 12:50:20 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 12:51:40 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 365.5590822696686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 12:52:58 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 12:54:00 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 12:55:03 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 12:56:23 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 12:57:42 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 363.44851326942444 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 12:59:01 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:00:02 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:01:06 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:02:26 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:03:45 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 362.33824944496155 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:05:04 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:06:08 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:07:13 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:08:32 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:09:51 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 365.7746772766113 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 13:11:10 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:12:14 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:13:17 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:14:37 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:15:55 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 363.70528078079224 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 13:17:15 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:18:20 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:19:23 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:20:43 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:22:02 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 367.1485393047333 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 13:23:19 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:24:21 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:25:27 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:26:46 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:28:04 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 362.8214750289917 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 13:29:24 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:30:28 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:31:31 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:32:52 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:34:11 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 368.24494767189026 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 13:35:32 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:36:39 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:37:45 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:39:04 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:40:25 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 371.42077112197876 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 13:41:43 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:42:48 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:43:52 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:45:10 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:46:30 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 365.1338412761688 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 13:47:49 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:48:54 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:49:58 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:51:15 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:52:34 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 365.78850412368774 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 13:53:55 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 13:54:58 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 13:56:01 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 13:57:22 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 13:58:47 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 373.78185772895813 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 14:00:07 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:01:12 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:02:19 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:03:43 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:05:05 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 378.75584053993225 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 14:06:29 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:07:31 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:08:41 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:10:02 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:11:23 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 378.305988073349 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 14:12:46 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:13:49 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:14:57 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:16:19 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:17:42 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 379.9148213863373 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 14:19:08 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:20:13 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:21:23 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:22:45 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:24:05 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 382.26600337028503 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 14:25:31 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:26:36 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:27:47 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:29:10 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:30:42 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 399.0139579772949 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 14:32:10 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:33:15 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:34:23 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:35:48 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:37:11 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 386.38827991485596 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 14:38:33 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:39:37 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:40:43 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:42:04 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:43:23 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 371.02525806427 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 14:44:45 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:45:49 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:46:53 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:48:14 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:49:31 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 370.19951725006104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 14:50:53 2024]  Iteration number: 0 with current cost as 0.36639483223115216 and parameters 
[-3.36128069  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 14:51:56 2024]  Iteration number: 0 with current cost as 0.31707474691360493 and parameters 
[-3.19505212  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 14:53:01 2024]  Iteration number: 0 with current cost as 0.329250608850924 and parameters 
[-3.27472175  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 14:54:18 2024]  Iteration number: 0 with current cost as 0.3337226037561096 and parameters 
[-3.26687976  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 14:55:40 2024]  Iteration number: 0 with current cost as 0.3335886832996057 and parameters 
[-3.26163071  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 364.8346757888794 seconds. 
Discarding model... 

Training complete taking 9290.992817401886 total seconds. 
Now scoring model... 
Scoring complete taking 2.623116970062256 seconds. 
Saved predicted values as IQP_ESU2_predicted_values.csv
Model scores: {'MSE_train': (206.6985994957776,), 'R2_train': -0.0013853432167307833, 'MAE_train': 12.570108849473945, 'MSE_test': 193.76124339760548, 'R2_test': -0.16795671817878066, 'MAE_test': 12.065264221858929}. 
Saved model results as IQP_ESU2_results.json. 
