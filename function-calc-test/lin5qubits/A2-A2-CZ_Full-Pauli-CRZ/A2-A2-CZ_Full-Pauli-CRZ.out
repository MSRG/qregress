test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Thu Mar 21 11:20:54 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 11:21:05 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 11:22:40 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 11:24:26 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 11:26:12 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 11:27:54 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 514.0021464824677 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 11:29:39 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 11:31:15 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 11:33:01 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 11:34:48 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 11:36:31 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 517.4652726650238 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 11:38:17 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 11:39:52 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 11:41:36 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 11:43:22 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 11:45:03 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 512.888750076294 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 11:46:50 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 11:48:25 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Thu Mar 21 11:50:11 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 11:51:57 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 11:53:40 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 517.9914937019348 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 11:55:28 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 11:57:03 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 11:58:50 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 12:00:37 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 12:02:19 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 518.0006232261658 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 12:04:06 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 12:05:41 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 12:07:27 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 12:09:14 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 12:10:56 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 516.2738845348358 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 12:12:42 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 12:14:16 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 12:16:02 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 12:17:48 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 12:19:30 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 514.9057323932648 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.2 fold... 
[Thu Mar 21 12:21:17 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 12:22:51 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 12:24:37 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 12:26:22 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 12:28:05 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 515.2926552295685 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 12:29:52 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 12:31:28 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 12:33:16 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 12:35:04 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 12:36:48 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 523.2735459804535 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 12:38:36 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 12:40:12 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 12:42:00 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 12:43:48 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 12:45:31 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 523.2930040359497 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 12:47:19 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 12:48:55 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 12:50:43 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 12:52:30 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Thu Mar 21 12:54:14 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 523.0853490829468 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 12:56:02 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 12:57:37 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 12:59:23 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 13:01:09 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 13:02:54 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 519.4071543216705 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 13:04:41 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 13:06:16 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 13:08:03 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 13:09:51 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 13:11:35 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 520.1726026535034 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 13:13:21 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 13:14:57 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 13:16:45 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 13:18:34 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 13:20:18 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 524.2839517593384 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 13:22:06 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 13:23:43 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Thu Mar 21 13:25:31 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 13:27:19 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 13:29:04 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 526.1197810173035 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 13:30:52 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 13:32:28 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 13:34:15 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 13:36:03 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 13:37:47 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 523.5721607208252 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 13:39:35 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 13:41:11 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 13:42:59 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 13:44:47 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 13:46:29 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 520.4723064899445 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 13:48:16 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 13:49:52 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 13:51:38 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 13:53:25 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 13:55:09 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 518.7149798870087 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.2 fold... 
[Thu Mar 21 13:56:54 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 13:58:29 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 14:00:15 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 14:02:02 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 14:03:44 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 515.3642041683197 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 14:05:30 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 14:07:05 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 14:08:51 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 14:10:37 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 14:12:20 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 516.540281534195 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 14:14:07 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 14:15:42 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 14:17:29 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 14:19:15 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 14:20:58 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 518.0475904941559 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 14:22:45 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 14:24:20 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 14:26:06 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 14:27:53 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Thu Mar 21 14:29:35 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 515.7477920055389 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 14:31:20 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 14:32:55 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 14:34:41 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 14:36:26 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 14:38:09 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 513.7279486656189 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 14:39:54 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 14:41:28 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 14:43:16 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 14:45:01 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 14:46:44 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 514.0841763019562 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 14:48:28 2024]  Iteration number: 0 with current cost as 0.3471024290414729 and parameters 
[-3.00403741  2.86782109 -2.04522357 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551997 -1.06648308  1.1074843   1.14432445
  1.37447883 -1.87354682  0.72965078  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077105 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Mar 21 14:50:02 2024]  Iteration number: 0 with current cost as 0.35585717525065735 and parameters 
[-3.08149693  2.31286072 -2.11109594 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67002268  1.14432445
  1.50140815 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 21 14:51:48 2024]  Iteration number: 0 with current cost as 0.39705388119620844 and parameters 
[-3.00687863  2.32206722 -2.10356805 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.67494418  1.14432445
  1.42159469 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 21 14:53:34 2024]  Iteration number: 0 with current cost as 0.3921962655959692 and parameters 
[-3.00822304  2.31808224 -2.10360891 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.66973108  1.14432445
  1.4219854  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Mar 21 14:55:16 2024]  Iteration number: 0 with current cost as 0.39079955875103156 and parameters 
[-3.02288927  2.32221059 -2.10749849 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.67478926  1.14432445
  1.43783666 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Training complete taking 513.7763352394104 seconds. 
Discarding model... 

Training complete taking 12956.504099845886 total seconds. 
Now scoring model... 
Scoring complete taking 0.45064854621887207 seconds. 
Saved predicted values as A2-A2-CZ_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (163.36687287738428,), 'R2_train': 0.2085423294321579, 'MAE_train': 11.019071698721973, 'MSE_test': 161.75386702339, 'R2_test': 0.02497779035360903, 'MAE_test': 10.776672692864768}. 
Saved model results as A2-A2-CZ_Full-Pauli-CRZ_results.json. 
