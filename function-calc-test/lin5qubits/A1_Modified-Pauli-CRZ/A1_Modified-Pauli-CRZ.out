test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Mon Mar 18 03:19:25 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 18 03:19:31 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:19:46 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:20:02 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:20:11 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:20:27 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 69.20884156227112 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 18 03:20:41 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:20:56 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:21:11 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:21:20 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:21:36 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 68.660813331604 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 18 03:21:49 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:22:04 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:22:20 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:22:29 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:22:44 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 68.45972895622253 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 18 03:22:58 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:23:12 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:23:27 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:23:37 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Mon Mar 18 03:23:52 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 67.61373949050903 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 18 03:24:05 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:24:21 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:24:36 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:24:45 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:25:00 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 68.77033710479736 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 18 03:25:14 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:25:30 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:25:45 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:25:54 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:26:09 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 68.65461730957031 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 18 03:26:23 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:26:38 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:26:54 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:27:03 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:27:19 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 69.65435576438904 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 18 03:27:32 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:27:48 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:28:03 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:28:13 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:28:28 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 69.0777657032013 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 18 03:28:41 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:28:57 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:29:12 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:29:21 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:29:37 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 68.94718623161316 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 18 03:29:50 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:30:05 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:30:21 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:30:30 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:30:46 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 69.26530981063843 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 18 03:31:00 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:31:15 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:31:30 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:31:40 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:31:55 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 69.33126664161682 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 18 03:32:09 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:32:24 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:32:39 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:32:48 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:33:04 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 68.21587610244751 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.2 fold... 
[Mon Mar 18 03:33:17 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:33:33 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:33:48 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:33:57 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:34:13 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 69.45475840568542 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 18 03:34:27 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:34:43 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:34:58 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:35:08 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:35:23 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 69.80770611763 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 18 03:35:37 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:35:52 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:36:07 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:36:17 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:36:32 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 69.51347184181213 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 18 03:36:46 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:37:01 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:37:16 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:37:26 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:37:41 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 68.68407821655273 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 18 03:37:55 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Mon Mar 18 03:38:10 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:38:24 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:38:34 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:38:49 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 67.78564214706421 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 18 03:39:02 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:39:18 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:39:32 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:39:42 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:39:57 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 67.80439901351929 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 18 03:40:10 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:40:25 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:40:40 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:40:50 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:41:05 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 67.99257159233093 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 18 03:41:19 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:41:34 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:41:49 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:41:58 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:42:13 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 68.08782958984375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 18 03:42:27 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:42:42 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Mon Mar 18 03:42:57 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:43:06 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:43:21 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 68.64461302757263 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 18 03:43:35 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:43:50 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:44:06 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:44:15 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:44:30 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 68.9907808303833 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 18 03:44:44 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:44:59 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:45:14 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:45:23 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:45:38 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 67.59256744384766 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 18 03:45:52 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:46:06 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:46:21 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Mar 18 03:46:30 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:46:45 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 67.3231749534607 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 18 03:46:59 2024]  Iteration number: 0 with current cost as 0.38011340407366556 and parameters 
[-1.86063587  2.23743464 -2.12427958 -0.11653103  0.55388705 -2.77010897
  3.06858495  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Mar 18 03:47:15 2024]  Iteration number: 0 with current cost as 0.3402131780397023 and parameters 
[-1.73750486  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Mar 18 03:47:29 2024]  Iteration number: 0 with current cost as 0.3214981746198782 and parameters 
[-1.59867868  2.23743464 -2.12427958 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960148  1.18552002 -1.06648312  0.60271513  1.14432448
  1.31029899 -1.8735468   0.72965074  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Mon Mar 18 03:47:38 2024]  Iteration number: 0 with current cost as 0.3568027324609079 and parameters 
[-1.80309345  2.23743461 -2.12427961 -0.116531    0.55388705 -2.770109
  3.06858496  2.18960148  1.18552004 -1.06648311  0.60271513  1.14432445
  1.31029896 -1.8735468   0.72965078  2.88578419 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Mar 18 03:47:53 2024]  Iteration number: 0 with current cost as 0.35714830453772717 and parameters 
[-1.79851555  2.23743466 -2.12427959 -0.11653098  0.5538871  -2.77010897
  3.06858496  2.1896015   1.18552006 -1.06648306  0.60271515  1.1443245
  1.31029901 -1.87354675  0.72965078  2.88578424 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 68.06522631645203 seconds. 
Discarding model... 

Training complete taking 1715.6069905757904 total seconds. 
Now scoring model... 
Scoring complete taking 0.28776979446411133 seconds. 
Saved predicted values as A1_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (206.69854451800143,), 'R2_train': -0.001385076867856716, 'MAE_train': 12.570106825680046, 'MSE_test': 193.76226346793214, 'R2_test': -0.16796286697288498, 'MAE_test': 12.06528046815796}. 
Saved model results as A1_Modified-Pauli-CRZ_results.json. 
