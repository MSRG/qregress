/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:53:26 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:33 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:53:50 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:02 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:18 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:31 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.00283122062683 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:46 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:02 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:15 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 17:55:28 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:42 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.20201253890991 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:57 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:12 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:25 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:39 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:54 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.14895677566528 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:07 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:23 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:35 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 17:57:50 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:04 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.12905645370483 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:58:18 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:58:34 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:47 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:00 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:15 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.83062028884888 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:29 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:59:46 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:59:58 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:00:11 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:00:27 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.49282121658325 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:00:40 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:01:00 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:01:12 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:01:26 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:40 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 74.9306960105896 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:01:55 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:02:11 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:02:24 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:02:38 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:02:54 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.1610963344574 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:03:08 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:03:24 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:03:36 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:03:51 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:04:04 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.41318893432617 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:04:19 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:04:35 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:04:48 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:05:02 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:05:17 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.40336656570435 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:30 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:05:47 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:05:59 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:12 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:06:27 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.3725094795227 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:06:41 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:06:57 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:07:09 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:07:24 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:38 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.8398187160492 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:07:53 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:08:08 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:08:21 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:08:35 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:08:50 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.59420037269592 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:09:03 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:09:20 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:09:32 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:09:47 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:10:01 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.26279282569885 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:10:16 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:10:31 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:10:43 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:10:58 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:11:13 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 73.36611151695251 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:11:28 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:11:45 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:11:57 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:12:11 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:12:29 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 75.24810290336609 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:12:44 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:13:00 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:13:12 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:13:27 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:13:41 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.53848576545715 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:13:56 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:14:11 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:14:24 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:14:38 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:14:52 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.30798387527466 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:15:06 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:15:23 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:15:34 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:15:49 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:16:03 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.59326362609863 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:16:18 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:16:33 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:16:46 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:17:00 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:17:13 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.8408727645874 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:17:28 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:17:43 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:17:57 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:18:10 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:18:26 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.85126447677612 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:18:39 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:18:56 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:19:08 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:19:23 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:19:37 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 70.93770146369934 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:19:52 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:20:07 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:20:20 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:20:34 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:20:49 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.97792935371399 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:21:02 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:21:19 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:21:31 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:21:46 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:22:00 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 71.20865631103516 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:22:13 2024]  Iteration number: 0 with current cost as 0.08254125841968474 and parameters 
[-1.80615689  2.23743464 -2.12427961 -0.11653101  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:22:30 2024]  Iteration number: 0 with current cost as 0.0456594841914219 and parameters 
[-1.63842079  2.23743464 -2.12427961 -0.11653104  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:22:42 2024]  Iteration number: 0 with current cost as 0.06367369203119275 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388707]. 
Working on 0.8 fold... 
[Sun Mar 24 18:22:57 2024]  Iteration number: 0 with current cost as 0.06242059859736621 and parameters 
[-1.74666116  2.23743466 -2.12427961 -0.11653103  0.55388709]. 
Working on 1.0 fold... 
[Sun Mar 24 18:23:11 2024]  Iteration number: 0 with current cost as 0.06501695879569036 and parameters 
[-1.74143586  2.23743462 -2.12427961 -0.11653104  0.55388707]. 
Training complete taking 72.71057868003845 seconds. 
Discarding model... 

Training complete taking 1793.3660838603973 total seconds. 
Now scoring model... 
Scoring complete taking 0.8457624912261963 seconds. 
Saved predicted values as IQP_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (27.70890346749304,), 'R2_train': 0.8657596622490826, 'MAE_train': 3.7149688782716828, 'MSE_test': 29.353778759086744, 'R2_test': 0.8230608840837329, 'MAE_test': 3.5003653003944164}. 
Saved model results as IQP_Hadamard_results.json. 
