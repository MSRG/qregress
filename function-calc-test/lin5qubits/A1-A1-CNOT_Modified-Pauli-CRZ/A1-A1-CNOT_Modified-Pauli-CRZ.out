test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Fri Mar 15 06:14:57 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 06:15:05 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:15:19 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:15:36 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:16:05 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:16:28 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 98.86196970939636 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 06:16:44 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:16:59 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:17:15 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:17:44 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:18:06 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 98.67050385475159 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 06:18:23 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:18:37 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:18:53 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:19:21 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:19:44 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.06835651397705 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 06:20:00 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:20:14 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:20:30 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:20:58 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Fri Mar 15 06:21:21 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.3309428691864 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 06:21:37 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:21:51 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:22:07 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:22:36 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:22:58 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.13948893547058 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 06:23:14 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:23:28 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:23:44 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:24:12 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:24:34 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 95.88310408592224 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 06:24:50 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:25:04 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:25:20 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:25:49 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:26:11 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.53918051719666 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 06:26:28 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:26:42 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:26:58 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:27:26 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:27:48 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 96.63012290000916 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 06:28:04 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:28:18 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:28:34 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:29:02 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:29:24 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 96.18251442909241 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 06:29:40 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:29:55 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:30:11 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:30:39 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:31:02 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.50059175491333 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 06:31:18 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:31:32 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:31:48 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:32:16 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:32:39 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 96.88312721252441 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 06:32:55 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:33:09 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:33:26 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:33:54 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:34:16 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.6865131855011 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.2 fold... 
[Fri Mar 15 06:34:32 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:34:47 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:35:03 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:35:31 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:35:53 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 96.47122478485107 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 06:36:09 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:36:23 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:36:40 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:37:08 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:37:31 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 98.01730179786682 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 06:37:47 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:38:01 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:38:18 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:38:46 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:39:08 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.76509714126587 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 06:39:25 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:39:39 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:39:55 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:40:24 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:40:46 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.9595136642456 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 06:41:03 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Fri Mar 15 06:41:17 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:41:34 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:42:02 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:42:24 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.78249144554138 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 06:42:40 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:42:54 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:43:10 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:43:39 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:44:01 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.18918514251709 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 06:44:18 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:44:32 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:44:48 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:45:17 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:45:38 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 96.90400457382202 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 06:45:54 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:46:08 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:46:25 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:46:52 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:47:14 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 95.67559480667114 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 15 06:47:30 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:47:44 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Fri Mar 15 06:48:00 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:48:29 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:48:51 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.07092237472534 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 15 06:49:07 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:49:21 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:49:37 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:50:06 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:50:28 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 96.79038143157959 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 15 06:50:44 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:50:58 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:51:14 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:51:43 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:52:05 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.51050686836243 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 15 06:52:22 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:52:36 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:52:52 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Mar 15 06:53:21 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:53:43 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 97.60230374336243 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 15 06:53:59 2024]  Iteration number: 0 with current cost as 0.3460325798915368 and parameters 
[ 1.33999862  2.23743464 -2.12427948 -0.11653103  0.55388692 -2.77010913
  3.06858483  2.18960145  1.18551998 -1.0664834   0.60271495  1.14432429
  1.31029883 -1.8735468   0.72965033  2.88578404 -0.54534351 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Mar 15 06:54:13 2024]  Iteration number: 0 with current cost as 0.28853377252097057 and parameters 
[-1.29406983  2.23743473 -2.12427954 -0.11653093  0.55388713 -2.77010897
  3.06858498  2.18960155  1.18552008 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735467   0.7296507   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Mar 15 06:54:29 2024]  Iteration number: 0 with current cost as 0.540885482477226 and parameters 
[ 0.02415263  2.23743473 -2.12427944 -0.11653093  0.55388708 -2.77010897
  3.06858489  2.18960155  1.18552018 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.8735467   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Fri Mar 15 06:54:57 2024]  Iteration number: 0 with current cost as 0.5183899726642975 and parameters 
[ 0.00866845  2.23743464 -2.12427944 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648328  0.6027151   1.14432445
  1.31029899 -1.87354661  0.72965061  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Mar 15 06:55:19 2024]  Iteration number: 0 with current cost as 0.32750283975187355 and parameters 
[ 1.5760501   2.23743478 -2.12427935 -0.11653088  0.55388722 -2.77010897
  3.06858498  2.1896016   1.18552013 -1.06648337  0.60271496  1.14432445
  1.31029884 -1.87354666  0.72965066  2.88578405 -0.54534321 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 95.95475721359253 seconds. 
Discarding model... 

Training complete taking 2430.070069551468 total seconds. 
Now scoring model... 
Scoring complete taking 0.31946396827697754 seconds. 
Saved predicted values as A1-A1-CNOT_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (193.24510235504033,), 'R2_train': 0.06379233522234207, 'MAE_train': 12.576626105621372, 'MSE_test': 169.18972248710836, 'R2_test': -0.019844162643641194, 'MAE_test': 11.37099599494738}. 
Saved model results as A1-A1-CNOT_Modified-Pauli-CRZ_results.json. 
