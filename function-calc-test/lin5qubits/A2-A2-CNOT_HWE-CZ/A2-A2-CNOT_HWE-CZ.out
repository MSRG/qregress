test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Tue Mar 19 07:53:41 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 07:53:45 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 07:54:05 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 07:54:25 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 07:54:43 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 07:55:02 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.69927954673767 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 07:55:20 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 07:55:39 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 07:55:59 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 07:56:17 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 07:56:35 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 93.25608777999878 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 07:56:53 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 07:57:13 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 07:57:33 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 07:57:52 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 07:58:10 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.09259915351868 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 07:58:28 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 07:58:48 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 07:59:08 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 07:59:26 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 07:59:44 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.31172251701355 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 08:00:02 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:00:22 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

[Tue Mar 19 08:00:42 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:01:00 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:01:18 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.16579055786133 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 08:01:36 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:01:57 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:02:17 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:02:34 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:02:52 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.42519497871399 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 08:03:11 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:03:31 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:03:52 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:04:10 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:04:28 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.42019748687744 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 08:04:46 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:05:07 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:05:27 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:05:45 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:06:03 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.15191888809204 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 08:06:21 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:06:41 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:07:02 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:07:20 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:07:39 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.36303949356079 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 08:07:57 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Tue Mar 19 08:08:17 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:08:37 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:08:55 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:09:14 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.19945883750916 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 08:09:32 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:09:52 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:10:12 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:10:30 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:10:49 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.8470196723938 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 08:11:07 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:11:27 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:11:47 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:12:05 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:12:23 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.43126797676086 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 08:12:41 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:13:01 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:13:22 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:13:40 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:13:58 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.32649946212769 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 08:14:16 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:14:36 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:14:56 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:15:14 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:15:32 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.40734481811523 seconds. 
Discarding model... 
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 08:15:50 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:16:10 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:16:31 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:16:49 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:17:07 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.49838185310364 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 08:17:25 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:17:46 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:18:06 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:18:25 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:18:43 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.4818344116211 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 08:19:01 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:19:21 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:19:41 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:19:59 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:20:18 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.02863621711731 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 08:20:36 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:20:57 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:21:17 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:21:35 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:21:53 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 96.00639820098877 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 08:22:12 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:22:33 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:22:54 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:23:13 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Working on 1.0 fold... 
[Tue Mar 19 08:23:30 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 96.30595874786377 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 08:23:48 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:24:08 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:24:29 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:24:47 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:25:05 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.92528533935547 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 08:25:23 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:25:43 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:26:03 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:26:21 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:26:39 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.1094913482666 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 08:26:57 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:27:17 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:27:37 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:27:56 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:28:14 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 94.67741417884827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 08:28:32 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:28:52 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:29:13 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:29:31 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:29:49 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.53407049179077 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 08:30:08 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:30:28 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:30:48 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Tue Mar 19 08:31:06 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:31:24 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.19565486907959 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 08:31:43 2024]  Iteration number: 0 with current cost as 0.247090918263202 and parameters 
[-3.01512808  2.13238182 -1.86073841 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Tue Mar 19 08:32:03 2024]  Iteration number: 0 with current cost as 0.2250103144286847 and parameters 
[-3.02131248  2.13594182 -1.85353274 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Tue Mar 19 08:32:24 2024]  Iteration number: 0 with current cost as 0.22223841808564548 and parameters 
[-3.02390183  2.1357917  -1.84922732 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Tue Mar 19 08:32:42 2024]  Iteration number: 0 with current cost as 0.22424481755829995 and parameters 
[-3.01220175  2.13973075 -1.87124237 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Tue Mar 19 08:33:00 2024]  Iteration number: 0 with current cost as 0.2268624586649289 and parameters 
[-3.02506662  2.1316456  -1.84408749 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60271511  1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 95.63305187225342 seconds. 
Discarding model... 

Training complete taking 2373.4939699172974 total seconds. 
Now scoring model... 
Scoring complete taking 0.36687254905700684 seconds. 
Saved predicted values as A2-A2-CNOT_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (135.53407644747557,), 'R2_train': 0.34338288700552877, 'MAE_train': 10.75948909842871, 'MSE_test': 137.809009963769, 'R2_test': 0.16931293281151805, 'MAE_test': 10.655559793897101}. 
Saved model results as A2-A2-CNOT_HWE-CZ_results.json. 
