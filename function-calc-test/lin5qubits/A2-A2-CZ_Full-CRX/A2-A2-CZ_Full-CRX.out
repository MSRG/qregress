test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Wed Mar 20 05:51:56 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 20 05:54:30 2024]  Iteration number: 0 with current cost as 0.40206921785744676 and parameters 
[-4.25425889  2.23743495 -2.12427932 -0.11653071  0.55388739 -2.77010897
  3.06858498  2.18960177  1.18552045 -1.06648293  0.60271542  1.14432476
  1.31029914 -1.87354649  0.7296508   2.88578451 -0.54534304 -0.47522454
 -2.02654209  0.72897401  1.60512695  2.83077107 -1.26456694 -0.25136105
 -2.39279218 -2.27309774  3.1333717   2.54856974 -0.67550787 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 20 05:59:37 2024]  Iteration number: 0 with current cost as 0.32432523471465174 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653103  0.55388708 -2.77010926
  3.06858469  2.1896016   1.18551998 -1.06648308  0.6027151   1.1443246
  1.31029899 -1.87354651  0.7296508   2.88578419 -0.54534335 -0.47522456
 -2.0265424   0.7289737   1.60512664  2.83077093 -1.26456724 -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 20 06:04:45 2024]  Iteration number: 0 with current cost as 0.3677723206822532 and parameters 
[-4.3440553   2.23743487 -2.1242794  -0.11653103  0.55388732 -2.77010897
  3.06858475  2.18960169  1.18552022 -1.06648308  0.60271534  1.14432469
  1.31029922 -1.87354633  0.72965104  2.88578443 -0.54534311 -0.47522461
 -2.0265424   0.72897393  1.60512687  2.83077083 -1.26456733 -0.25136105
 -2.39279194 -2.27309774  3.13337179  2.54856982 -0.67550764 -2.69002178]. 
Working on 0.8 fold... 
[Wed Mar 20 06:09:50 2024]  Iteration number: 0 with current cost as 0.3637808400363888 and parameters 
[-4.3546006   2.23743479 -2.12427964 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960177  1.18552014 -1.06648308  0.6027151   1.14432461
  1.31029899 -1.87354664  0.72965065  2.88578419 -0.54534335 -0.47522485
 -2.02654256  0.7289737   1.60512679  2.83077091 -1.2645671  -0.25136105
 -2.39279202 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 20 06:14:56 2024]  Iteration number: 0 with current cost as 0.35971460533124766 and parameters 
[-7.59805129  2.23743527 -2.124279   -0.11653039  0.55388771 -2.77010961
  3.06858435  2.18960209  1.18552062 -1.06648308  0.60271574  1.14432508
  1.31029962 -1.87354553  0.72965017  2.88578483 -0.54534272 -0.47522422
 -2.0265424   0.72897433  1.60512727  2.83077044 -1.2645671  -0.25136041
 -2.39279155 -2.27309711  3.13337218  2.54857022 -0.67550724 -2.69002202]. 
Training complete taking 1495.579133272171 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 20 06:19:25 2024]  Iteration number: 0 with current cost as 0.40206921785744676 and parameters 
[-4.25425889  2.23743495 -2.12427932 -0.11653071  0.55388739 -2.77010897
  3.06858498  2.18960177  1.18552045 -1.06648293  0.60271542  1.14432476
  1.31029914 -1.87354649  0.7296508   2.88578451 -0.54534304 -0.47522454
 -2.02654209  0.72897401  1.60512695  2.83077107 -1.26456694 -0.25136105
 -2.39279218 -2.27309774  3.1333717   2.54856974 -0.67550787 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 20 06:24:33 2024]  Iteration number: 0 with current cost as 0.32432523471465174 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653103  0.55388708 -2.77010926
  3.06858469  2.1896016   1.18551998 -1.06648308  0.6027151   1.1443246
  1.31029899 -1.87354651  0.7296508   2.88578419 -0.54534335 -0.47522456
 -2.0265424   0.7289737   1.60512664  2.83077093 -1.26456724 -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 20 06:29:39 2024]  Iteration number: 0 with current cost as 0.3677723206822532 and parameters 
[-4.3440553   2.23743487 -2.1242794  -0.11653103  0.55388732 -2.77010897
  3.06858475  2.18960169  1.18552022 -1.06648308  0.60271534  1.14432469
  1.31029922 -1.87354633  0.72965104  2.88578443 -0.54534311 -0.47522461
 -2.0265424   0.72897393  1.60512687  2.83077083 -1.26456733 -0.25136105
 -2.39279194 -2.27309774  3.13337179  2.54856982 -0.67550764 -2.69002178]. 
Working on 0.8 fold... 
[Wed Mar 20 06:34:47 2024]  Iteration number: 0 with current cost as 0.3637808400363888 and parameters 
[-4.3546006   2.23743479 -2.12427964 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960177  1.18552014 -1.06648308  0.6027151   1.14432461
  1.31029899 -1.87354664  0.72965065  2.88578419 -0.54534335 -0.47522485
 -2.02654256  0.7289737   1.60512679  2.83077091 -1.2645671  -0.25136105
 -2.39279202 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 20 06:39:55 2024]  Iteration number: 0 with current cost as 0.35971460533124766 and parameters 
[-7.59805129  2.23743527 -2.124279   -0.11653039  0.55388771 -2.77010961
  3.06858435  2.18960209  1.18552062 -1.06648308  0.60271574  1.14432508
  1.31029962 -1.87354553  0.72965017  2.88578483 -0.54534272 -0.47522422
 -2.0265424   0.72897433  1.60512727  2.83077044 -1.2645671  -0.25136041
 -2.39279155 -2.27309711  3.13337218  2.54857022 -0.67550724 -2.69002202]. 
Training complete taking 1497.7599637508392 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 20 06:44:23 2024]  Iteration number: 0 with current cost as 0.40206921785744676 and parameters 
[-4.25425889  2.23743495 -2.12427932 -0.11653071  0.55388739 -2.77010897
  3.06858498  2.18960177  1.18552045 -1.06648293  0.60271542  1.14432476
  1.31029914 -1.87354649  0.7296508   2.88578451 -0.54534304 -0.47522454
 -2.02654209  0.72897401  1.60512695  2.83077107 -1.26456694 -0.25136105
 -2.39279218 -2.27309774  3.1333717   2.54856974 -0.67550787 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 20 06:49:32 2024]  Iteration number: 0 with current cost as 0.32432523471465174 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653103  0.55388708 -2.77010926
  3.06858469  2.1896016   1.18551998 -1.06648308  0.6027151   1.1443246
  1.31029899 -1.87354651  0.7296508   2.88578419 -0.54534335 -0.47522456
 -2.0265424   0.7289737   1.60512664  2.83077093 -1.26456724 -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 20 06:54:38 2024]  Iteration number: 0 with current cost as 0.3677723206822532 and parameters 
[-4.3440553   2.23743487 -2.1242794  -0.11653103  0.55388732 -2.77010897
  3.06858475  2.18960169  1.18552022 -1.06648308  0.60271534  1.14432469
  1.31029922 -1.87354633  0.72965104  2.88578443 -0.54534311 -0.47522461
 -2.0265424   0.72897393  1.60512687  2.83077083 -1.26456733 -0.25136105
 -2.39279194 -2.27309774  3.13337179  2.54856982 -0.67550764 -2.69002178]. 
Working on 0.8 fold... 
[Wed Mar 20 06:59:45 2024]  Iteration number: 0 with current cost as 0.3637808400363888 and parameters 
[-4.3546006   2.23743479 -2.12427964 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960177  1.18552014 -1.06648308  0.6027151   1.14432461
  1.31029899 -1.87354664  0.72965065  2.88578419 -0.54534335 -0.47522485
 -2.02654256  0.7289737   1.60512679  2.83077091 -1.2645671  -0.25136105
 -2.39279202 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 20 07:04:51 2024]  Iteration number: 0 with current cost as 0.35971460533124766 and parameters 
[-7.59805129  2.23743527 -2.124279   -0.11653039  0.55388771 -2.77010961
  3.06858435  2.18960209  1.18552062 -1.06648308  0.60271574  1.14432508
  1.31029962 -1.87354553  0.72965017  2.88578483 -0.54534272 -0.47522422
 -2.0265424   0.72897433  1.60512727  2.83077044 -1.2645671  -0.25136041
 -2.39279155 -2.27309711  3.13337218  2.54857022 -0.67550724 -2.69002202]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 1495.1056740283966 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 20 07:09:19 2024]  Iteration number: 0 with current cost as 0.40206921785744676 and parameters 
[-4.25425889  2.23743495 -2.12427932 -0.11653071  0.55388739 -2.77010897
  3.06858498  2.18960177  1.18552045 -1.06648293  0.60271542  1.14432476
  1.31029914 -1.87354649  0.7296508   2.88578451 -0.54534304 -0.47522454
 -2.02654209  0.72897401  1.60512695  2.83077107 -1.26456694 -0.25136105
 -2.39279218 -2.27309774  3.1333717   2.54856974 -0.67550787 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 20 07:14:27 2024]  Iteration number: 0 with current cost as 0.32432523471465174 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653103  0.55388708 -2.77010926
  3.06858469  2.1896016   1.18551998 -1.06648308  0.6027151   1.1443246
  1.31029899 -1.87354651  0.7296508   2.88578419 -0.54534335 -0.47522456
 -2.0265424   0.7289737   1.60512664  2.83077093 -1.26456724 -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 20 07:19:34 2024]  Iteration number: 0 with current cost as 0.3677723206822532 and parameters 
[-4.3440553   2.23743487 -2.1242794  -0.11653103  0.55388732 -2.77010897
  3.06858475  2.18960169  1.18552022 -1.06648308  0.60271534  1.14432469
  1.31029922 -1.87354633  0.72965104  2.88578443 -0.54534311 -0.47522461
 -2.0265424   0.72897393  1.60512687  2.83077083 -1.26456733 -0.25136105
 -2.39279194 -2.27309774  3.13337179  2.54856982 -0.67550764 -2.69002178]. 
Working on 0.8 fold... 
[Wed Mar 20 07:24:36 2024]  Iteration number: 0 with current cost as 0.3637808400363888 and parameters 
[-4.3546006   2.23743479 -2.12427964 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960177  1.18552014 -1.06648308  0.6027151   1.14432461
  1.31029899 -1.87354664  0.72965065  2.88578419 -0.54534335 -0.47522485
 -2.02654256  0.7289737   1.60512679  2.83077091 -1.2645671  -0.25136105
 -2.39279202 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 20 07:29:43 2024]  Iteration number: 0 with current cost as 0.35971460533124766 and parameters 
[-7.59805129  2.23743527 -2.124279   -0.11653039  0.55388771 -2.77010961
  3.06858435  2.18960209  1.18552062 -1.06648308  0.60271574  1.14432508
  1.31029962 -1.87354553  0.72965017  2.88578483 -0.54534272 -0.47522422
 -2.0265424   0.72897433  1.60512727  2.83077044 -1.2645671  -0.25136041
 -2.39279155 -2.27309711  3.13337218  2.54857022 -0.67550724 -2.69002202]. 
Training complete taking 1492.0940074920654 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 20 07:34:10 2024]  Iteration number: 0 with current cost as 0.40206921785744676 and parameters 
[-4.25425889  2.23743495 -2.12427932 -0.11653071  0.55388739 -2.77010897
  3.06858498  2.18960177  1.18552045 -1.06648293  0.60271542  1.14432476
  1.31029914 -1.87354649  0.7296508   2.88578451 -0.54534304 -0.47522454
 -2.02654209  0.72897401  1.60512695  2.83077107 -1.26456694 -0.25136105
 -2.39279218 -2.27309774  3.1333717   2.54856974 -0.67550787 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 20 07:39:15 2024]  Iteration number: 0 with current cost as 0.32432523471465174 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653103  0.55388708 -2.77010926
  3.06858469  2.1896016   1.18551998 -1.06648308  0.6027151   1.1443246
  1.31029899 -1.87354651  0.7296508   2.88578419 -0.54534335 -0.47522456
 -2.0265424   0.7289737   1.60512664  2.83077093 -1.26456724 -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 20 07:44:19 2024]  Iteration number: 0 with current cost as 0.3677723206822532 and parameters 
[-4.3440553   2.23743487 -2.1242794  -0.11653103  0.55388732 -2.77010897
  3.06858475  2.18960169  1.18552022 -1.06648308  0.60271534  1.14432469
  1.31029922 -1.87354633  0.72965104  2.88578443 -0.54534311 -0.47522461
 -2.0265424   0.72897393  1.60512687  2.83077083 -1.26456733 -0.25136105
 -2.39279194 -2.27309774  3.13337179  2.54856982 -0.67550764 -2.69002178]. 
Working on 0.8 fold... 
[Wed Mar 20 07:49:22 2024]  Iteration number: 0 with current cost as 0.3637808400363888 and parameters 
[-4.3546006   2.23743479 -2.12427964 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960177  1.18552014 -1.06648308  0.6027151   1.14432461
  1.31029899 -1.87354664  0.72965065  2.88578419 -0.54534335 -0.47522485
 -2.02654256  0.7289737   1.60512679  2.83077091 -1.2645671  -0.25136105
 -2.39279202 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 20 07:54:28 2024]  Iteration number: 0 with current cost as 0.35971460533124766 and parameters 
[-7.59805129  2.23743527 -2.124279   -0.11653039  0.55388771 -2.77010961
  3.06858435  2.18960209  1.18552062 -1.06648308  0.60271574  1.14432508
  1.31029962 -1.87354553  0.72965017  2.88578483 -0.54534272 -0.47522422
 -2.0265424   0.72897433  1.60512727  2.83077044 -1.2645671  -0.25136041
 -2.39279155 -2.27309711  3.13337218  2.54857022 -0.67550724 -2.69002202]. 
Training complete taking 1486.8122808933258 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 20 07:58:55 2024]  Iteration number: 0 with current cost as 0.40206921785744676 and parameters 
[-4.25425889  2.23743495 -2.12427932 -0.11653071  0.55388739 -2.77010897
  3.06858498  2.18960177  1.18552045 -1.06648293  0.60271542  1.14432476
  1.31029914 -1.87354649  0.7296508   2.88578451 -0.54534304 -0.47522454
 -2.02654209  0.72897401  1.60512695  2.83077107 -1.26456694 -0.25136105
 -2.39279218 -2.27309774  3.1333717   2.54856974 -0.67550787 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 20 08:03:57 2024]  Iteration number: 0 with current cost as 0.32432523471465174 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653103  0.55388708 -2.77010926
  3.06858469  2.1896016   1.18551998 -1.06648308  0.6027151   1.1443246
  1.31029899 -1.87354651  0.7296508   2.88578419 -0.54534335 -0.47522456
 -2.0265424   0.7289737   1.60512664  2.83077093 -1.26456724 -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 20 08:09:01 2024]  Iteration number: 0 with current cost as 0.3677723206822532 and parameters 
[-4.3440553   2.23743487 -2.1242794  -0.11653103  0.55388732 -2.77010897
  3.06858475  2.18960169  1.18552022 -1.06648308  0.60271534  1.14432469
  1.31029922 -1.87354633  0.72965104  2.88578443 -0.54534311 -0.47522461
 -2.0265424   0.72897393  1.60512687  2.83077083 -1.26456733 -0.25136105
 -2.39279194 -2.27309774  3.13337179  2.54856982 -0.67550764 -2.69002178]. 
Working on 0.8 fold... 
[Wed Mar 20 08:14:04 2024]  Iteration number: 0 with current cost as 0.3637808400363888 and parameters 
[-4.3546006   2.23743479 -2.12427964 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960177  1.18552014 -1.06648308  0.6027151   1.14432461
  1.31029899 -1.87354664  0.72965065  2.88578419 -0.54534335 -0.47522485
 -2.02654256  0.7289737   1.60512679  2.83077091 -1.2645671  -0.25136105
 -2.39279202 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 20 08:19:09 2024]  Iteration number: 0 with current cost as 0.35971460533124766 and parameters 
[-7.59805129  2.23743527 -2.124279   -0.11653039  0.55388771 -2.77010961
  3.06858435  2.18960209  1.18552062 -1.06648308  0.60271574  1.14432508
  1.31029962 -1.87354553  0.72965017  2.88578483 -0.54534272 -0.47522422
 -2.0265424   0.72897433  1.60512727  2.83077044 -1.2645671  -0.25136041
 -2.39279155 -2.27309711  3.13337218  2.54857022 -0.67550724 -2.69002202]. 
Training complete taking 1480.1951079368591 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 20 08:23:37 2024]  Iteration number: 0 with current cost as 0.40206921785744676 and parameters 
[-4.25425889  2.23743495 -2.12427932 -0.11653071  0.55388739 -2.77010897
  3.06858498  2.18960177  1.18552045 -1.06648293  0.60271542  1.14432476
  1.31029914 -1.87354649  0.7296508   2.88578451 -0.54534304 -0.47522454
 -2.02654209  0.72897401  1.60512695  2.83077107 -1.26456694 -0.25136105
 -2.39279218 -2.27309774  3.1333717   2.54856974 -0.67550787 -2.69002202]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Wed Mar 20 08:28:44 2024]  Iteration number: 0 with current cost as 0.32432523471465174 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653103  0.55388708 -2.77010926
  3.06858469  2.1896016   1.18551998 -1.06648308  0.6027151   1.1443246
  1.31029899 -1.87354651  0.7296508   2.88578419 -0.54534335 -0.47522456
 -2.0265424   0.7289737   1.60512664  2.83077093 -1.26456724 -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 20 08:33:51 2024]  Iteration number: 0 with current cost as 0.3677723206822532 and parameters 
[-4.3440553   2.23743487 -2.1242794  -0.11653103  0.55388732 -2.77010897
  3.06858475  2.18960169  1.18552022 -1.06648308  0.60271534  1.14432469
  1.31029922 -1.87354633  0.72965104  2.88578443 -0.54534311 -0.47522461
 -2.0265424   0.72897393  1.60512687  2.83077083 -1.26456733 -0.25136105
 -2.39279194 -2.27309774  3.13337179  2.54856982 -0.67550764 -2.69002178]. 
Working on 0.8 fold... 
[Wed Mar 20 08:38:58 2024]  Iteration number: 0 with current cost as 0.3637808400363888 and parameters 
[-4.3546006   2.23743479 -2.12427964 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960177  1.18552014 -1.06648308  0.6027151   1.14432461
  1.31029899 -1.87354664  0.72965065  2.88578419 -0.54534335 -0.47522485
 -2.02654256  0.7289737   1.60512679  2.83077091 -1.2645671  -0.25136105
 -2.39279202 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 20 08:44:03 2024]  Iteration number: 0 with current cost as 0.35971460533124766 and parameters 
[-7.59805129  2.23743527 -2.124279   -0.11653039  0.55388771 -2.77010961
  3.06858435  2.18960209  1.18552062 -1.06648308  0.60271574  1.14432508
  1.31029962 -1.87354553  0.72965017  2.88578483 -0.54534272 -0.47522422
 -2.0265424   0.72897433  1.60512727  2.83077044 -1.2645671  -0.25136041
 -2.39279155 -2.27309711  3.13337218  2.54857022 -0.67550724 -2.69002202]. 
Training complete taking 1493.4527926445007 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 20 08:48:28 2024]  Iteration number: 0 with current cost as 0.40206921785744676 and parameters 
[-4.25425889  2.23743495 -2.12427932 -0.11653071  0.55388739 -2.77010897
  3.06858498  2.18960177  1.18552045 -1.06648293  0.60271542  1.14432476
  1.31029914 -1.87354649  0.7296508   2.88578451 -0.54534304 -0.47522454
 -2.02654209  0.72897401  1.60512695  2.83077107 -1.26456694 -0.25136105
 -2.39279218 -2.27309774  3.1333717   2.54856974 -0.67550787 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 20 08:53:34 2024]  Iteration number: 0 with current cost as 0.32432523471465174 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653103  0.55388708 -2.77010926
  3.06858469  2.1896016   1.18551998 -1.06648308  0.6027151   1.1443246
  1.31029899 -1.87354651  0.7296508   2.88578419 -0.54534335 -0.47522456
 -2.0265424   0.7289737   1.60512664  2.83077093 -1.26456724 -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 20 08:58:41 2024]  Iteration number: 0 with current cost as 0.3677723206822532 and parameters 
[-4.3440553   2.23743487 -2.1242794  -0.11653103  0.55388732 -2.77010897
  3.06858475  2.18960169  1.18552022 -1.06648308  0.60271534  1.14432469
  1.31029922 -1.87354633  0.72965104  2.88578443 -0.54534311 -0.47522461
 -2.0265424   0.72897393  1.60512687  2.83077083 -1.26456733 -0.25136105
 -2.39279194 -2.27309774  3.13337179  2.54856982 -0.67550764 -2.69002178]. 
Working on 0.8 fold... 
[Wed Mar 20 09:03:46 2024]  Iteration number: 0 with current cost as 0.3637808400363888 and parameters 
[-4.3546006   2.23743479 -2.12427964 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960177  1.18552014 -1.06648308  0.6027151   1.14432461
  1.31029899 -1.87354664  0.72965065  2.88578419 -0.54534335 -0.47522485
 -2.02654256  0.7289737   1.60512679  2.83077091 -1.2645671  -0.25136105
 -2.39279202 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 20 09:08:51 2024]  Iteration number: 0 with current cost as 0.35971460533124766 and parameters 
[-7.59805129  2.23743527 -2.124279   -0.11653039  0.55388771 -2.77010961
  3.06858435  2.18960209  1.18552062 -1.06648308  0.60271574  1.14432508
  1.31029962 -1.87354553  0.72965017  2.88578483 -0.54534272 -0.47522422
 -2.0265424   0.72897433  1.60512727  2.83077044 -1.2645671  -0.25136041
 -2.39279155 -2.27309711  3.13337218  2.54857022 -0.67550724 -2.69002202]. 
Training complete taking 1487.740026473999 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 20 09:13:17 2024]  Iteration number: 0 with current cost as 0.40206921785744676 and parameters 
[-4.25425889  2.23743495 -2.12427932 -0.11653071  0.55388739 -2.77010897
  3.06858498  2.18960177  1.18552045 -1.06648293  0.60271542  1.14432476
  1.31029914 -1.87354649  0.7296508   2.88578451 -0.54534304 -0.47522454
 -2.02654209  0.72897401  1.60512695  2.83077107 -1.26456694 -0.25136105
 -2.39279218 -2.27309774  3.1333717   2.54856974 -0.67550787 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 20 09:18:26 2024]  Iteration number: 0 with current cost as 0.32432523471465174 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653103  0.55388708 -2.77010926
  3.06858469  2.1896016   1.18551998 -1.06648308  0.6027151   1.1443246
  1.31029899 -1.87354651  0.7296508   2.88578419 -0.54534335 -0.47522456
 -2.0265424   0.7289737   1.60512664  2.83077093 -1.26456724 -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 0.6 fold... 
[Wed Mar 20 09:23:35 2024]  Iteration number: 0 with current cost as 0.3677723206822532 and parameters 
[-4.3440553   2.23743487 -2.1242794  -0.11653103  0.55388732 -2.77010897
  3.06858475  2.18960169  1.18552022 -1.06648308  0.60271534  1.14432469
  1.31029922 -1.87354633  0.72965104  2.88578443 -0.54534311 -0.47522461
 -2.0265424   0.72897393  1.60512687  2.83077083 -1.26456733 -0.25136105
 -2.39279194 -2.27309774  3.13337179  2.54856982 -0.67550764 -2.69002178]. 
Working on 0.8 fold... 
[Wed Mar 20 09:28:43 2024]  Iteration number: 0 with current cost as 0.3637808400363888 and parameters 
[-4.3546006   2.23743479 -2.12427964 -0.11653087  0.55388724 -2.77010897
  3.06858483  2.18960177  1.18552014 -1.06648308  0.6027151   1.14432461
  1.31029899 -1.87354664  0.72965065  2.88578419 -0.54534335 -0.47522485
 -2.02654256  0.7289737   1.60512679  2.83077091 -1.2645671  -0.25136105
 -2.39279202 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. 
Working on 1.0 fold... 
[Wed Mar 20 09:33:50 2024]  Iteration number: 0 with current cost as 0.35971460533124766 and parameters 
[-7.59805129  2.23743527 -2.124279   -0.11653039  0.55388771 -2.77010961
  3.06858435  2.18960209  1.18552062 -1.06648308  0.60271574  1.14432508
  1.31029962 -1.87354553  0.72965017  2.88578483 -0.54534272 -0.47522422
 -2.0265424   0.72897433  1.60512727  2.83077044 -1.2645671  -0.25136041
 -2.39279155 -2.27309711  3.13337218  2.54857022 -0.67550724 -2.69002202]. 
Training complete taking 1499.9197108745575 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 20 09:38:19 2024]  Iteration number: 0 with current cost as 0.40206921785744676 and parameters 
[-4.25425889  2.23743495 -2.12427932 -0.11653071  0.55388739 -2.77010897
  3.06858498  2.18960177  1.18552045 -1.06648293  0.60271542  1.14432476
  1.31029914 -1.87354649  0.7296508   2.88578451 -0.54534304 -0.47522454
 -2.02654209  0.72897401  1.60512695  2.83077107 -1.26456694 -0.25136105
 -2.39279218 -2.27309774  3.1333717   2.54856974 -0.67550787 -2.69002202]. 
Working on 0.4 fold... 
[Wed Mar 20 09:43:26 2024]  Iteration number: 0 with current cost as 0.32432523471465174 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653103  0.55388708 -2.77010926
  3.06858469  2.1896016   1.18551998 -1.06648308  0.6027151   1.1443246
  1.31029899 -1.87354651  0.7296508   2.88578419 -0.54534335 -0.47522456
 -2.0265424   0.7289737   1.60512664  2.83077093 -1.26456724 -0.25136105
 -2.39279218 -2.27309774  3.13337155  2.54856958 -0.67550787 -2.69002202]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
