runall.sh: line 11: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Thu Mar 14 12:03:35 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 14 12:03:45 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 12:05:48 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 12:09:36 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 12:10:01 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 12:12:44 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 12:15:22 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 854.7438225746155 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 14 12:18:00 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 12:20:01 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 12:23:47 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 12:24:11 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 12:26:50 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 12:29:29 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 846.6383912563324 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 14 12:32:07 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 12:34:06 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 12:37:48 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 12:38:12 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 12:40:54 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 12:43:34 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 846.2792513370514 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 14 12:46:13 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 12:48:13 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 12:51:59 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 12:52:24 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 12:55:03 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 12:57:41 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 844.3828337192535 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 14 13:00:17 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 13:02:16 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 13:06:00 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 13:06:24 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 13:09:06 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 13:11:44 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 845.7685079574585 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 14 13:14:23 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 13:16:22 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 13:20:08 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 13:20:33 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 13:23:15 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 13:25:53 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 848.6940565109253 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 14 13:28:32 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Thu Mar 14 13:30:32 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 13:34:19 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 13:34:43 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 13:37:25 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 13:40:03 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 849.9721250534058 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 14 13:42:42 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 13:44:43 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 13:48:28 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 13:48:53 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 13:51:35 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 13:54:15 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 851.764746427536 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 14 13:56:53 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 13:58:54 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 14:02:40 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 14:03:04 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 14:05:48 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 14:08:28 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 851.086932182312 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 14 14:11:05 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 14:13:04 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

[Thu Mar 14 14:16:50 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 14:17:15 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 14:19:58 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 14:22:37 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 849.6412634849548 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 14 14:25:14 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 14:27:11 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 14:30:54 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 14:31:18 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 14:34:00 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 14:36:40 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 844.1434547901154 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 14 14:39:19 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 14:41:19 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 14:45:07 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 14:45:33 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 14:48:16 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 14:50:57 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 856.9971113204956 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 14 14:53:36 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 14:55:36 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 14:59:24 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Thu Mar 14 14:59:49 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 15:02:30 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 15:05:08 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 849.9835314750671 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 14 15:07:45 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 15:09:46 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 15:13:33 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 15:13:58 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 15:16:42 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 15:19:22 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 856.6302697658539 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 14 15:22:02 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 15:24:04 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 15:27:53 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 15:28:19 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 15:31:05 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 15:33:49 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 869.5299727916718 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 14 15:36:32 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 15:38:35 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 15:42:28 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 15:42:54 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Thu Mar 14 15:45:43 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 15:48:31 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 885.5918958187103 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 14 15:51:18 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 15:53:23 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 15:57:23 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 15:57:49 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 16:00:38 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 16:03:23 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 888.900395154953 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 14 16:06:07 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 16:08:09 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 16:12:01 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 16:12:26 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 16:15:14 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 16:18:00 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 877.8859996795654 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 14 16:20:44 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 16:22:49 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 16:26:41 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 16:27:07 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 16:29:54 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Thu Mar 14 16:32:37 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 876.529355764389 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 14 16:35:21 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 16:37:24 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 16:41:10 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 16:41:35 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 16:44:17 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 16:46:55 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 852.5554277896881 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 14 16:49:33 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 16:51:34 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 16:55:20 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 16:55:45 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 16:58:25 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 17:01:03 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 848.5552988052368 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 14 17:03:42 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 17:05:42 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 17:09:26 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 17:09:51 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 17:12:30 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 17:15:09 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 846.7072641849518 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 14 17:17:48 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 17:19:49 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 17:23:34 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 17:23:59 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 17:26:39 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 17:29:15 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 843.885178565979 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 14 17:31:52 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 17:33:53 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 17:37:38 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 17:38:03 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 17:40:43 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 17:43:20 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 845.3507907390594 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 14 17:45:58 2024]  Iteration number: 0 with current cost as 0.39496814263352037 and parameters 
[-3.07068163  2.7935733  -2.15404793 -0.11653101  0.5538871  -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308  0.76203631  1.14432447
  1.47509333 -1.8735468   0.72965078  2.88578419 -0.54534333 -0.47522485
 -2.02654242  0.72897368  1.60512664  2.83077107 -1.26456708 -0.25136103]. 
Working on 0.4 fold... 
[Thu Mar 14 17:47:57 2024]  Iteration number: 0 with current cost as 0.3329148811725703 and parameters 
[-2.94079931  2.28856967 -2.13340513 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648308  0.63440237  1.14432445
  1.35246954 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 14 17:51:42 2024]  Iteration number: 50 with current cost as 0.21464799072828575 and parameters 
[-4.71952024  3.47089358 -1.56859319 -0.11654515  0.55388296 -2.77011288
  3.06858617  2.18958808  1.18552218 -1.066493    2.70684675  1.14430987
  0.19754649 -1.87353559  0.72965564  2.88582167 -0.54530597 -0.47522398
 -2.02650675  0.72895751  1.60513546  2.83081868 -1.2645464  -0.25136735]. 
Working on 0.6 fold... 
[Thu Mar 14 17:52:07 2024]  Iteration number: 0 with current cost as 0.37594103803661155 and parameters 
[-2.93815107  2.32171377 -2.13236955 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.63540797  1.14432445
  1.34722192 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Mar 14 17:54:49 2024]  Iteration number: 0 with current cost as 0.37964965511427695 and parameters 
[-2.9482169   2.31995028 -2.13596513 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.64731679  1.14432446
  1.36289646 -1.87354679  0.72965081  2.8857842  -0.54534334 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 14 17:57:29 2024]  Iteration number: 0 with current cost as 0.3716893875232391 and parameters 
[-2.93592156  2.31289541 -2.1314094  -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.63142415  1.14432445
  1.34408722 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077108 -1.2645671  -0.25136105]. 
Training complete taking 850.695648431778 seconds. 
Discarding model... 

Training complete taking 21382.913867473602 total seconds. 
Now scoring model... 
Scoring complete taking 0.3846151828765869 seconds. 
Saved predicted values as A1-A1-CNOT_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (140.1564804212638,), 'R2_train': 0.3209888911048798, 'MAE_train': 10.8491588391182, 'MSE_test': 138.09858218449898, 'R2_test': 0.16756744535144052, 'MAE_test': 10.3570257840626}. 
Saved model results as A1-A1-CNOT_Full-Pauli-CRX_results.json. 
