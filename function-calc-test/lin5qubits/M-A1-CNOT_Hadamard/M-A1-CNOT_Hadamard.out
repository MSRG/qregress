/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:29:56 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:00 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:30:15 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:30:44 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:30:56 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:31:09 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 81.55248308181763 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:31:23 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:31:35 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:31:48 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:32:00 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:32:12 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.90883541107178 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:32:27 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:32:40 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:32:53 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:33:04 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:33:17 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.39220428466797 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:33:30 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:33:43 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:33:57 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:34:07 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:34:20 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.40912580490112 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:34:34 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:34:46 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:00 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:35:11 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:35:26 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.74720478057861 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:35:39 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:35:51 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:36:06 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:36:17 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:36:31 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.65289330482483 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:43 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:36:57 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:37:09 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:37:20 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:37:35 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.59651350975037 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:48 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:38:02 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:14 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:26 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:39 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.404815435409546 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:38:51 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:05 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:18 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:39:30 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:42 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.46053147315979 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:57 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:09 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:23 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:34 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:47 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.93741869926453 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:41:01 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:13 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:27 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:38 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:50 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.627970933914185 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:04 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:17 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:31 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:42 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:42:56 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.02688598632812 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:08 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:21 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:35 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:45 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:59 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.3262255191803 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:12 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:25 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:38 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:49 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:45:03 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.572718143463135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:15 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:29 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:42 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:45:54 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:06 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.53747320175171 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:19 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:33 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:46 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:58 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:10 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.20545792579651 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:24 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:37 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:49 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:02 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:48:14 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.4129991531372 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:28 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:41 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:55 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:49:05 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:18 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.509827852249146 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:32 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:44 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:58 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:09 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:22 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.7336368560791 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:36 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:48 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:02 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:13 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:51:27 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.66951370239258 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:39 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:52 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:06 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:17 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:32 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.1542158126831 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:44 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:58 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:11 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:22 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:35 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.40240240097046 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:48 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:02 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:14 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:27 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:39 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.66294980049133 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:51 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:05 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:18 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:55:30 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:43 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.86304569244385 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:57 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:09 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:22 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:34 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:46 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.07890009880066 seconds. 
Discarding model... 

Training complete taking 1620.847090959549 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.8551516532897949 seconds. 
Saved predicted values as M-A1-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (101.30764768555159,), 'R2_train': 0.5091984474227264, 'MAE_train': 8.256294164625706, 'MSE_test': 201.35877645229283, 'R2_test': -0.21375323360781562, 'MAE_test': 10.649848282478724}. 
Saved model results as M-A1-CNOT_Hadamard_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 11:28:41 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:28:46 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:28:59 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:29:11 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:29:23 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:29:36 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.52071070671082 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:29:50 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:30:02 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:30:16 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:30:27 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:30:39 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.52818942070007 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:30:53 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:31:06 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:31:19 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:31:30 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:31:43 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.199769020080566 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:31:56 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:32:09 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:32:34 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:32:46 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:32:59 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 74.75790214538574 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:33:11 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:33:25 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:33:38 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:33:51 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:34:04 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.39230966567993 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:34:18 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:34:30 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:34:43 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:34:55 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:35:07 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.50931668281555 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:35:21 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:35:33 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:35:47 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:35:58 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:36:11 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.675801277160645 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:36:25 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:36:37 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:36:51 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:37:02 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:37:16 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.33540201187134 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:37:28 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:37:40 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:37:54 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:38:05 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:38:19 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.465757608413696 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:38:32 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:38:45 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:38:58 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:39:08 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:39:23 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.52635741233826 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:39:37 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:39:50 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:40:03 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:40:15 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:40:27 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.74087071418762 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:40:40 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:40:54 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:41:06 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:41:18 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:41:31 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.612359285354614 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:41:45 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:41:57 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:42:10 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:42:22 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:42:34 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.53688931465149 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:42:48 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:43:01 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:43:15 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:43:26 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:43:38 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.69028544425964 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:43:53 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:44:05 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:44:19 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:44:30 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:44:42 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.2932550907135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:44:56 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:45:08 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:45:22 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:45:33 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:45:47 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.53056001663208 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:45:59 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:46:12 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:46:26 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:46:36 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:46:50 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.46721649169922 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:47:03 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:47:17 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:47:29 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:47:40 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:47:54 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.94405508041382 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:48:07 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:48:21 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:48:33 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:48:45 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:48:58 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.54804968833923 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:49:10 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:49:27 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:49:39 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:49:51 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:50:04 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.58340883255005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:50:17 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:50:30 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:50:42 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:50:55 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:51:07 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.19565892219543 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:51:21 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:51:34 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:51:48 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:51:58 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:52:12 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.33178496360779 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:52:27 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:52:39 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:52:53 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:53:04 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:53:18 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.568729877471924 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:53:30 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:53:43 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:53:56 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:54:07 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:54:21 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.32350993156433 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:54:33 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:54:51 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Thu Apr  4 11:55:03 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:55:14 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 11:55:30 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 69.08136940002441 seconds. 
Discarding model... 

Training complete taking 1618.3607032299042 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.7966334819793701 seconds. 
Saved predicted values as M-A1-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (101.30764768555159,), 'R2_train': 0.5091984474227264, 'MAE_train': 8.256294164625706, 'MSE_test': 201.35877645229283, 'R2_test': -0.21375323360781562, 'MAE_test': 10.649848282478724}. 
Saved model results as M-A1-CNOT_Hadamard_results.json. 
