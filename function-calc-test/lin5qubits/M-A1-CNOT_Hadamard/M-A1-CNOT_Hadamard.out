/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:29:56 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:00 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:30:15 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:30:44 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:30:56 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:31:09 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 81.55248308181763 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:31:23 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:31:35 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:31:48 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:32:00 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:32:12 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.90883541107178 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:32:27 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:32:40 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:32:53 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:33:04 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:33:17 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.39220428466797 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:33:30 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:33:43 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:33:57 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:34:07 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:34:20 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.40912580490112 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:34:34 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:34:46 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:00 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:35:11 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:35:26 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.74720478057861 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:35:39 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:35:51 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:36:06 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:36:17 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:36:31 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.65289330482483 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:43 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:36:57 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:37:09 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:37:20 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:37:35 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.59651350975037 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:48 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:38:02 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:14 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:26 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:39 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.404815435409546 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:38:51 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:05 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:18 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:39:30 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:42 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.46053147315979 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:57 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:09 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:23 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:34 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:47 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.93741869926453 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:41:01 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:13 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:27 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:38 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:50 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.627970933914185 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:04 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:17 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:31 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:42 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:42:56 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.02688598632812 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:08 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:21 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:35 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:45 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:59 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.3262255191803 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:12 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:25 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:38 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:49 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:45:03 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.572718143463135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:15 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:29 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:42 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:45:54 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:06 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.53747320175171 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:19 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:33 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:46 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:58 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:10 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.20545792579651 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:24 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:37 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:49 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:02 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:48:14 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.4129991531372 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:28 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:41 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:55 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:49:05 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:18 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.509827852249146 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:32 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:44 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:58 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:09 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:22 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.7336368560791 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:36 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:48 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:02 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:13 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:51:27 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.66951370239258 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:39 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:52 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:06 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:17 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:32 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.1542158126831 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:44 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:58 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:11 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:22 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:35 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.40240240097046 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:48 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:02 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:14 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:27 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:39 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.66294980049133 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:51 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:05 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:18 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:55:30 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:43 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.86304569244385 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:57 2024]  Iteration number: 0 with current cost as 0.18416667534620396 and parameters 
[-2.83367244  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:09 2024]  Iteration number: 0 with current cost as 0.17570168943475867 and parameters 
[-2.60038878  2.23743463 -2.12427965 -0.11653103  0.55388707]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:22 2024]  Iteration number: 0 with current cost as 0.16078694613774264 and parameters 
[-2.57275398  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:34 2024]  Iteration number: 0 with current cost as 0.16723787152763794 and parameters 
[-2.83939959  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:46 2024]  Iteration number: 0 with current cost as 0.17995283613238086 and parameters 
[-2.83945865  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 65.07890009880066 seconds. 
Discarding model... 

Training complete taking 1620.847090959549 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.8551516532897949 seconds. 
Saved predicted values as M-A1-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (101.30764768555159,), 'R2_train': 0.5091984474227264, 'MAE_train': 8.256294164625706, 'MSE_test': 201.35877645229283, 'R2_test': -0.21375323360781562, 'MAE_test': 10.649848282478724}. 
Saved model results as M-A1-CNOT_Hadamard_results.json. 
