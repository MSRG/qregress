test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Sun Mar 17 21:29:17 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 21:29:19 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:29:23 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:29:26 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:29:30 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:29:33 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.777954816818237 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 21:29:35 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:29:40 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:29:43 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:29:46 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:29:49 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.57743811607361 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 21:29:52 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:29:56 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:30:00 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:30:03 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:30:06 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.664353609085083 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 21:30:09 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:30:13 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:30:17 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:30:20 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:30:23 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 17.004996299743652 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 21:30:26 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:30:30 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:30:33 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:30:37 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:30:39 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.65831160545349 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 21:30:42 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:30:47 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:30:50 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:30:53 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:30:56 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.81980586051941 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 21:30:59 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:31:04 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:31:07 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:31:10 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:31:13 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 16.846783876419067 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 21:31:16 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:31:20 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:31:24 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:31:27 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:31:30 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.661807537078857 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 21:31:32 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:31:37 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:31:40 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:31:44 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:31:46 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.622334480285645 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 21:31:49 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:31:54 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:31:57 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:32:01 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:32:04 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 17.22345805168152 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 21:32:06 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:32:11 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:32:14 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:32:18 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:32:21 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 17.058124780654907 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 21:32:23 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:32:28 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:32:31 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:32:35 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:32:37 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.83736252784729 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 21:32:40 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:32:45 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:32:48 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:32:51 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:32:54 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.87109875679016 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 21:32:57 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:33:02 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:33:05 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:33:08 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:33:11 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.548615217208862 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 21:33:14 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:33:18 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Sun Mar 17 21:33:21 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:33:25 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:33:27 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.472886323928833 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 21:33:30 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:33:35 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:33:38 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:33:41 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:33:44 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.498793601989746 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 21:33:47 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:33:51 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:33:54 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:33:58 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:34:01 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.673320293426514 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 21:34:04 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:34:09 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:34:12 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:34:15 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:34:18 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 17.17272686958313 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 21:34:20 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:34:25 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:34:28 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:34:31 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:34:34 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.357261180877686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 21:34:37 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:34:41 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:34:45 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:34:48 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:34:51 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.677252054214478 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 17 21:34:54 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:34:58 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:35:01 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:35:05 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:35:07 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.6680908203125 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 17 21:35:10 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:35:15 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:35:18 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:35:22 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Sun Mar 17 21:35:24 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 17.00197982788086 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 17 21:35:27 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:35:32 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:35:35 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:35:38 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:35:41 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.765806436538696 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 17 21:35:44 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:35:49 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:35:52 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:35:55 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:35:58 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.738377809524536 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 17 21:36:01 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 17 21:36:06 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 17 21:36:09 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 17 21:36:12 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 17 21:36:15 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 16.6992084980011 seconds. 
Discarding model... 

Training complete taking 418.89845728874207 total seconds. 
Now scoring model... 
Scoring complete taking 0.2647378444671631 seconds. 
Saved predicted values as A1_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (2.3692445104512228,), 'R2_train': 0.9885218055030363, 'MAE_train': 1.1378145692389272, 'MSE_test': 1.7527889684814042, 'R2_test': 0.9894345142744226, 'MAE_test': 1.1771233276961397}. 
Saved model results as A1_Hadamard_results.json. 
