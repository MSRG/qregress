/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:30:21 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:26 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:30:40 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:30:52 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:31:03 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:31:11 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 56.42155480384827 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:31:22 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:31:37 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:31:48 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:31:58 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:32:08 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.90262722969055 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:32:20 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:32:34 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:32:45 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:32:55 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:33:04 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 56.409040451049805 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:33:14 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:33:29 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:33:38 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:33:50 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:33:59 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.73864126205444 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:34:08 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:34:23 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:34:33 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:34:45 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:34:54 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.80810785293579 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:35:02 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:35:18 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:28 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:35:38 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:35:48 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.727468729019165 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:35:57 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:36:11 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:36:23 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:36:33 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:36:41 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.62405753135681 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:52 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:37:06 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:37:17 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:37:27 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:37:36 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.19038391113281 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:47 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:38:01 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:11 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:22 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:31 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.83754634857178 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:38:40 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:38:56 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:05 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:39:17 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:26 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.713449239730835 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:34 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:51 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:01 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:11 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:22 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.94273495674133 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:30 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:46 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:56 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:06 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:17 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.184589862823486 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:41:26 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:40 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:51 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:01 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:42:10 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.80102777481079 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:21 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:36 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:47 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:57 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:06 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.57546520233154 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:16 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:31 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:41 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:52 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:01 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.20420432090759 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:10 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:26 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:36 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:47 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:56 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.762853145599365 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:05 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:21 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:31 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:45:40 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:45:51 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.731467962265015 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:00 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:15 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:25 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:35 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:46 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.94542217254639 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:55 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:09 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:20 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:30 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:39 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.19460892677307 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:49 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:04 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:16 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:26 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:48:35 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.513702392578125 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:47 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:01 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:11 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:49:22 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:31 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 56.564215898513794 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:40 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:56 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:06 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:17 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:26 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.695831298828125 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:35 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:50 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:00 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:10 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:51:21 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.75474572181702 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:29 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:45 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:55 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:05 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:15 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.67416834831238 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:24 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:38 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:50 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:00 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:08 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.294212341308594 seconds. 
Discarding model... 

Training complete taking 1371.2130653858185 total seconds. 
Now scoring model... 
Scoring complete taking 0.6986651420593262 seconds. 
Saved predicted values as A1_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (2.3692445104512228,), 'R2_train': 0.9885218055030363, 'MAE_train': 1.1378145692389272, 'MSE_test': 1.7527889684814042, 'R2_test': 0.9894345142744226, 'MAE_test': 1.1771233276961397}. 
Saved model results as A1_Hadamard_results.json. 
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Thu Apr  4 11:39:36 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:39:42 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:39:56 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:40:07 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:40:17 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:40:26 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.31737446784973 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:40:36 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:40:51 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:41:02 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:41:12 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:41:21 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.23360776901245 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:41:31 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:41:45 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:41:55 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:42:07 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:42:15 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.56773543357849 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:42:24 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:42:40 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:42:50 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:43:02 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:43:11 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.16490340232849 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:43:19 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:43:35 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:43:45 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:43:55 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:44:05 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.78969168663025 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:44:14 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:44:28 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:44:40 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:44:50 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:44:59 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.92056179046631 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:45:09 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:45:23 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:45:35 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:45:49 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:45:58 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 59.56276893615723 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:46:09 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:46:23 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:46:35 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:46:45 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:46:53 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.51649260520935 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:47:04 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:47:18 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:47:28 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:47:39 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:47:48 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.85194134712219 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:47:57 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:48:13 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:48:23 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:48:35 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:48:44 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.54205679893494 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:48:53 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:49:09 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:49:18 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:49:28 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:49:39 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.82517647743225 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:49:47 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:50:04 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:50:13 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:50:23 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:50:35 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 56.48147678375244 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:50:44 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:50:58 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:51:10 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:51:20 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:51:29 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.04533267021179 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:51:39 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:51:53 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:52:05 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:52:15 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:52:23 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.27680778503418 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:52:34 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:52:49 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:52:59 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:53:10 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:53:19 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.7704918384552 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:53:28 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:53:44 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:53:54 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:54:05 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:54:14 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.11189556121826 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:54:23 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:54:40 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:54:50 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:55:00 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:55:10 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.67167329788208 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:55:19 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:55:35 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:55:45 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:55:55 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:56:05 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.17900633811951 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 11:56:14 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:56:28 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:56:40 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:56:50 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:56:59 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.940916299819946 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 11:57:09 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:57:23 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:57:35 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:57:45 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:57:54 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.39396357536316 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 11:58:04 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:58:18 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:58:28 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:58:40 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:58:48 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.92957377433777 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 11:59:00 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 11:59:16 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 11:59:26 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 11:59:38 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 11:59:46 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 58.02073526382446 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 11:59:55 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:00:11 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:00:21 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:00:35 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 12:01:09 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 82.16985607147217 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 12:01:17 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:01:33 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:01:44 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:01:54 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 12:02:04 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.49603724479675 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 12:02:13 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 12:02:27 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 12:02:39 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 12:02:49 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Thu Apr  4 12:02:58 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.175824880599976 seconds. 
Discarding model... 

Training complete taking 1406.956990480423 total seconds. 
Now scoring model... 
Scoring complete taking 0.7022650241851807 seconds. 
Saved predicted values as A1_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (2.3692445104512228,), 'R2_train': 0.9885218055030363, 'MAE_train': 1.1378145692389272, 'MSE_test': 1.7527889684814042, 'R2_test': 0.9894345142744226, 'MAE_test': 1.1771233276961397}. 
Saved model results as A1_Hadamard_results.json. 
