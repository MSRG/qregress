/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:30:21 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:26 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:30:40 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:30:52 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:31:03 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:31:11 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 56.42155480384827 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:31:22 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:31:37 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:31:48 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:31:58 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:32:08 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.90262722969055 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:32:20 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:32:34 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:32:45 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:32:55 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:33:04 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 56.409040451049805 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:33:14 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:33:29 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:33:38 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:33:50 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:33:59 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.73864126205444 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:34:08 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:34:23 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:34:33 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:34:45 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:34:54 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.80810785293579 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:35:02 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:35:18 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:28 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:35:38 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:35:48 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.727468729019165 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:35:57 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:36:11 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:36:23 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:36:33 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:36:41 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.62405753135681 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:52 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:37:06 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:37:17 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:37:27 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:37:36 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.19038391113281 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:47 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:38:01 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:11 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:22 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:31 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.83754634857178 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:38:40 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:38:56 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:05 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:39:17 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:26 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.713449239730835 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:34 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:51 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:01 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:11 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:22 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.94273495674133 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:30 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:46 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:56 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:06 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:17 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.184589862823486 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:41:26 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:40 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:51 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:01 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:42:10 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.80102777481079 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:21 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:36 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:47 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:57 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:06 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.57546520233154 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:16 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:31 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:41 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:52 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:01 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.20420432090759 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:10 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:26 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:36 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:47 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:56 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.762853145599365 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:05 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:21 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:31 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:45:40 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:45:51 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.731467962265015 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:00 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:15 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:25 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:35 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:46 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.94542217254639 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:55 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:09 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:20 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:30 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:39 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.19460892677307 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:49 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:04 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:16 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:26 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:48:35 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 55.513702392578125 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:47 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:01 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:11 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:49:22 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:31 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 56.564215898513794 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:40 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:56 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:06 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:17 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:26 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.695831298828125 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:35 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:50 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:00 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:10 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:51:21 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.75474572181702 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:29 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:45 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:55 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:05 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:15 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 54.67416834831238 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:24 2024]  Iteration number: 0 with current cost as 0.027847919969595545 and parameters 
[-0.65132806  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:38 2024]  Iteration number: 0 with current cost as 0.005266204488246864 and parameters 
[-0.26375887  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:50 2024]  Iteration number: 0 with current cost as 0.008129826183994063 and parameters 
[-0.3976606   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:00 2024]  Iteration number: 0 with current cost as 0.010173054907303442 and parameters 
[-0.4439883   2.23743464 -2.1242795  -0.11653103  0.55388694]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:08 2024]  Iteration number: 0 with current cost as 0.009075001220184807 and parameters 
[-0.39162406  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 53.294212341308594 seconds. 
Discarding model... 

Training complete taking 1371.2130653858185 total seconds. 
Now scoring model... 
Scoring complete taking 0.6986651420593262 seconds. 
Saved predicted values as A1_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (2.3692445104512228,), 'R2_train': 0.9885218055030363, 'MAE_train': 1.1378145692389272, 'MSE_test': 1.7527889684814042, 'R2_test': 0.9894345142744226, 'MAE_test': 1.1771233276961397}. 
Saved model results as A1_Hadamard_results.json. 
