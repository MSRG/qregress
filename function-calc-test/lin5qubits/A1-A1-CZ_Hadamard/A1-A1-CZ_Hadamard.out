test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Sat Mar 16 16:21:19 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sat Mar 16 16:21:21 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:21:27 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:21:32 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:21:38 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:21:44 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.54265308380127 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sat Mar 16 16:21:49 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:21:54 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:22:00 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:22:06 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:22:11 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.57146382331848 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sat Mar 16 16:22:16 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:22:22 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:22:27 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:22:34 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:22:39 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.772645473480225 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sat Mar 16 16:22:44 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:22:50 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:22:55 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:23:01 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:23:07 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 28.75710105895996 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sat Mar 16 16:23:13 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:23:19 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:23:24 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:23:30 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:23:35 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 28.053046941757202 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sat Mar 16 16:23:41 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:23:47 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:23:52 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:23:59 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:24:04 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 28.18482255935669 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sat Mar 16 16:24:09 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:24:15 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:24:20 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:24:27 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:24:32 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 28.29519271850586 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sat Mar 16 16:24:37 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:24:43 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:24:48 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:24:55 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:25:00 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 28.175089120864868 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sat Mar 16 16:25:06 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:25:11 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:25:17 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:25:23 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:25:28 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 28.03226947784424 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sat Mar 16 16:25:34 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:25:39 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:25:44 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:25:51 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:25:56 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.6689875125885 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sat Mar 16 16:26:01 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:26:07 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:26:12 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:26:18 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:26:24 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.56178879737854 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sat Mar 16 16:26:29 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:26:35 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:26:40 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:26:46 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:26:52 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.912118673324585 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sat Mar 16 16:26:57 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:27:02 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:27:08 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:27:14 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:27:19 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.778743743896484 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sat Mar 16 16:27:25 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:27:30 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:27:36 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:27:42 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:27:47 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.97234010696411 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sat Mar 16 16:27:52 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:27:58 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Sat Mar 16 16:28:04 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:28:10 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:28:15 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.914827585220337 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sat Mar 16 16:28:20 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:28:26 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:28:31 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:28:38 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:28:43 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.935609817504883 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sat Mar 16 16:28:48 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:28:54 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:28:59 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:29:06 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:29:11 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.842493772506714 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sat Mar 16 16:29:16 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:29:22 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:29:27 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:29:34 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:29:39 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 28.23037815093994 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sat Mar 16 16:29:44 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:29:50 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:29:55 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:30:02 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:30:07 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.84804606437683 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sat Mar 16 16:30:12 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:30:18 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:30:23 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:30:30 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:30:35 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.764806985855103 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sat Mar 16 16:30:40 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:30:46 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:30:51 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:30:57 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:31:02 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.651886463165283 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sat Mar 16 16:31:08 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:31:13 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:31:19 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:31:25 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:31:30 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 28.063557386398315 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sat Mar 16 16:31:36 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:31:42 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:31:47 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:31:53 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:31:59 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 28.154848098754883 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sat Mar 16 16:32:04 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:32:10 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:32:15 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:32:21 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:32:27 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.93881058692932 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sat Mar 16 16:32:32 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sat Mar 16 16:32:38 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sat Mar 16 16:32:43 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sat Mar 16 16:32:49 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sat Mar 16 16:32:55 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 27.902392387390137 seconds. 
Discarding model... 

Training complete taking 698.526237487793 total seconds. 
Now scoring model... 
Scoring complete taking 0.3344292640686035 seconds. 
Saved predicted values as A1-A1-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (108.85860265806873,), 'R2_train': 0.4726166048015691, 'MAE_train': 7.646677513523848, 'MSE_test': 114.6270450613636, 'R2_test': 0.3090495033123021, 'MAE_test': 8.13478407161976}. 
Saved model results as A1-A1-CZ_Hadamard_results.json. 
