/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:30:00 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:30:08 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:30:27 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:30:44 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:31:04 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:31:21 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.81267762184143 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:31:36 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:31:55 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:32:11 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:32:32 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:32:49 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.51254963874817 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:33:05 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:33:24 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:33:39 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:34:06 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:34:23 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 93.94357705116272 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:34:39 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:34:58 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:35:15 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:35:34 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:35:51 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 87.86811637878418 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:36:07 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:36:26 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:36:41 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:37:02 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:37:19 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 87.96244430541992 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:35 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:37:54 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:09 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:30 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:47 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 87.7059874534607 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:03 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:25 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:41 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:02 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:19 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 91.55788731575012 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:34 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:53 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:09 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:30 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:47 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.15780830383301 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:02 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:21 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:37 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:58 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:15 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.15314316749573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:30 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:49 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:05 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:26 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:41 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.02986478805542 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:59 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:18 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:33 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:45:54 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:10 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.8658995628357 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:27 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:47 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:03 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:27 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:42 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 91.81624937057495 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:59 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:18 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:34 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:55 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:10 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.30121636390686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:27 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:46 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:02 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:23 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:38 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.50713872909546 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:56 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:15 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:31 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:52 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:07 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.25983786582947 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:24 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:42 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:59 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:21 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:37 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.88137745857239 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:54 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:12 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:29 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:49 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:05 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 86.58185362815857 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:23 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:40 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:57 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:18 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:34 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.92692422866821 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:56:51 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:09 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:26 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:57:47 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:02 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 88.19034886360168 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:58:20 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:58:38 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:56 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:17 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:32 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.9649453163147 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:00:04 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:00:27 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:00:42 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 18:01:03 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:20 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 108.05206537246704 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:01:36 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:01:55 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:02:10 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 18:02:32 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:02:49 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.23678517341614 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:03:05 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:03:24 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:03:40 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 18:04:03 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:04:20 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 90.76487684249878 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:04:36 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:04:56 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:05:11 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 18:05:32 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:05:49 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.3534677028656 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:06:05 2024]  Iteration number: 0 with current cost as 0.21339860318764237 and parameters 
[-0.60193032  2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:06:24 2024]  Iteration number: 0 with current cost as 0.1733350040085127 and parameters 
[-0.604708    2.23743464 -2.12427948 -0.11653087  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:06:40 2024]  Iteration number: 0 with current cost as 0.18374664129682966 and parameters 
[-0.68081387  2.23743448 -2.12427964 -0.11653103  0.55388692]. 
Working on 0.8 fold... 
[Sun Mar 24 18:07:01 2024]  Iteration number: 0 with current cost as 0.1809534746857943 and parameters 
[-0.60184834  2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:19 2024]  Iteration number: 0 with current cost as 0.1885322634936839 and parameters 
[-0.64825893  2.23743448 -2.12427948 -0.11653087  0.55388708]. 
Training complete taking 89.04473543167114 seconds. 
Discarding model... 

Training complete taking 2246.4529423713684 total seconds. 
Now scoring model... 
Scoring complete taking 0.921142578125 seconds. 
Saved predicted values as A1-A1-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (108.85860265806873,), 'R2_train': 0.4726166048015691, 'MAE_train': 7.646677513523848, 'MSE_test': 114.6270450613636, 'R2_test': 0.3090495033123021, 'MAE_test': 8.13478407161976}. 
Saved model results as A1-A1-CZ_Hadamard_results.json. 
