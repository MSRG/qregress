/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:39:05 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:14 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:22 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:32 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:39:42 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:53 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.887125730514526 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:02 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:12 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:22 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:31 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:42 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.914939641952515 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:52 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:00 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:12 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:21 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:31 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 48.83074450492859 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:41:42 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:50 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:01 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:10 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:42:21 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.04237151145935 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:32 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:42 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:53 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:01 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:13 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 51.41072154045105 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:22 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:30 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:42 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:50 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:01 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 48.35248780250549 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:12 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:20 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:31 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:40 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:51 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.950268507003784 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:00 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:09 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:21 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:45:30 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:45:42 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.64625692367554 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:51 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:59 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:11 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:21 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:33 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 51.725013971328735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:44 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:53 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:03 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:13 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:24 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.373169898986816 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:33 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:43 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:53 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:01 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:48:13 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.334078788757324 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:23 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:31 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:43 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:51 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:02 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 48.882771492004395 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:13 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:21 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:32 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:49:41 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:52 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.34977340698242 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:02 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:12 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:22 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:30 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:42 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.787392139434814 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:52 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:00 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:13 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:21 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:51:31 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.39343070983887 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:42 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:51 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:01 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:11 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:22 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.81889843940735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:32 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:43 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:53 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:01 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:14 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 51.966986417770386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:24 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:53:32 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:44 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:52 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:03 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 48.74825954437256 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:14 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:22 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:32 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:42 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:53 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.07989954948425 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:03 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:12 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:23 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:55:31 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:43 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.96133208274841 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:53 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:01 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:13 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:21 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:32 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.00597929954529 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:56:43 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:51 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:02 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:57:11 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:57:22 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 49.72596979141235 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:32 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:41 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:52 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:00 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:12 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.37814903259277 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:58:22 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:58:30 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:42 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:50 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:01 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 48.49708652496338 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:11 2024]  Iteration number: 0 with current cost as 0.07549003607030164 and parameters 
[ 0.09167625  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:59:20 2024]  Iteration number: 0 with current cost as 0.07514150179301678 and parameters 
[ 0.13972331  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:59:30 2024]  Iteration number: 0 with current cost as 0.0722202728085519 and parameters 
[-0.03245107  2.23743464 -2.12427941 -0.1165308   0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:39 2024]  Iteration number: 0 with current cost as 0.09841165903123633 and parameters 
[-0.48195762  2.23743464 -2.12427932 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:51 2024]  Iteration number: 0 with current cost as 0.07254989817656249 and parameters 
[ 0.0623246   2.23743448 -2.12427948 -0.11653103  0.55388708]. 
Training complete taking 50.060067653656006 seconds. 
Discarding model... 

Training complete taking 1248.1243436336517 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.6781158447265625 seconds. 
Saved predicted values as M_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (45.90449499854318,), 'R2_train': 0.7776081280113081, 'MAE_train': 6.070993943421847, 'MSE_test': 93.39513879228551, 'R2_test': 0.4370314832577218, 'MAE_test': 8.006546081928544}. 
Saved model results as M_Hadamard_results.json. 
