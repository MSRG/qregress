test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Tue Mar 19 13:40:12 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 13:40:43 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 13:41:48 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 13:42:49 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 13:43:50 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 13:44:51 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 302.67698764801025 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 13:45:43 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 13:46:43 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 13:47:44 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 13:48:42 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 13:49:41 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 288.80375695228577 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 13:50:32 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 13:51:31 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 13:52:31 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 13:53:31 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 13:54:28 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 289.31897711753845 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 13:55:23 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 13:56:22 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 13:57:22 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 13:58:21 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 13:59:20 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 289.0253224372864 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 14:00:09 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:01:07 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 14:02:12 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Tue Mar 19 14:03:13 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 14:04:22 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 304.60696291923523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 14:05:18 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:06:23 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 14:07:28 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 14:08:33 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 14:09:38 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 315.851744890213 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 14:10:33 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:11:37 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 14:12:41 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 14:13:45 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 14:14:50 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 312.38002943992615 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 14:15:49 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:16:55 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 14:17:59 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 14:19:02 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 14:20:05 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 314.9535503387451 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 14:21:01 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:22:04 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 14:23:08 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 14:24:11 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 14:25:14 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 308.2593114376068 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 14:26:09 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:27:12 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 14:28:15 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Tue Mar 19 14:29:18 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 14:30:21 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 306.9800992012024 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 14:31:16 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:32:19 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 14:33:23 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 14:34:28 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 14:35:33 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 314.92570662498474 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 14:36:31 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:37:36 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 14:38:43 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 14:39:47 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 14:40:51 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 315.2664897441864 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 14:41:48 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:42:53 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 14:44:00 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 14:45:13 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 14:46:23 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 333.353631734848 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 14:47:21 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:48:29 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 14:49:34 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 14:50:40 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 14:51:45 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 321.4162874221802 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 14:52:42 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:53:47 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 14:54:52 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Tue Mar 19 14:55:59 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 14:57:04 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 319.0105469226837 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 14:58:00 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 14:59:05 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 15:00:09 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 15:01:14 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 15:02:22 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 319.59870076179504 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 15:03:23 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 15:04:32 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 15:05:42 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 15:06:49 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 15:07:58 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 333.9078516960144 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 15:08:56 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 15:10:04 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 15:11:13 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 15:12:28 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 15:13:41 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 342.7802891731262 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 15:14:34 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 15:15:32 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 15:16:29 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 15:17:27 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 15:18:24 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 280.54908633232117 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 15:19:14 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 15:20:11 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 15:21:11 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Tue Mar 19 15:22:07 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 15:23:03 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 279.5466237068176 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 15:23:53 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 15:24:49 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 15:25:45 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 15:26:41 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 15:27:37 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 272.9148006439209 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 15:28:26 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 15:29:22 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 15:30:18 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 15:31:13 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 15:32:09 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 272.89560437202454 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 15:32:58 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 15:33:54 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 15:34:50 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 15:35:46 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 15:36:41 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 271.0636475086212 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 15:37:29 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 15:38:25 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 15:39:21 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. 
Working on 0.8 fold... 
[Tue Mar 19 15:40:16 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 15:41:12 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 270.7484440803528 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 15:42:00 2024]  Iteration number: 0 with current cost as 0.40206921848978855 and parameters 
[-4.2542592   2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010929
  3.06858483  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029914 -1.87354649]. 
Working on 0.4 fold... 
[Tue Mar 19 15:42:56 2024]  Iteration number: 0 with current cost as 0.32432523471485025 and parameters 
[-4.44706128  2.23743464 -2.12427949 -0.11653088  0.55388722 -2.77010912
  3.06858484  2.18960145  1.18551998 -1.06648308  0.60271525  1.1443246
  1.31029913 -1.87354637]. 
Working on 0.6 fold... 
[Tue Mar 19 15:43:51 2024]  Iteration number: 0 with current cost as 0.36777229855018734 and parameters 
[-4.34405591  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010945
  3.06858451  2.18960145  1.18551998 -1.06648332  0.60271534  1.14432445
  1.31029899 -1.87354633]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Tue Mar 19 15:44:47 2024]  Iteration number: 0 with current cost as 0.36378083578580267 and parameters 
[-4.35460075  2.23743479 -2.12427932 -0.11653087  0.55388708 -2.77010913
  3.06858498  2.18960161  1.18551998 -1.06648308  0.60271542  1.14432461
  1.31029899 -1.87354649]. 
Working on 1.0 fold... 
[Tue Mar 19 15:45:43 2024]  Iteration number: 0 with current cost as 0.3597146207892242 and parameters 
[-7.59805192  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77011024
  3.06858372  2.18960019  1.18551998 -1.06648435  0.6027151   1.14432445
  1.31029899 -1.87354553]. 
Training complete taking 271.9771246910095 seconds. 
Discarding model... 

Training complete taking 7552.811898231506 total seconds. 
Now scoring model... 
Scoring complete taking 0.8490185737609863 seconds. 
Saved predicted values as A2-A2-CZ_Efficient-CRX_predicted_values.csv
Model scores: {'MSE_train': (227.63053609303788,), 'R2_train': -0.10279355093933096, 'MAE_train': 13.23138567881667, 'MSE_test': 214.8609329043698, 'R2_test': -0.2951417200851849, 'MAE_test': 12.615998637258159}. 
Saved model results as A2-A2-CZ_Efficient-CRX_results.json. 
