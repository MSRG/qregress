/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/opt/miniconda/bin/python: can't open file '/home/gjones/scratch/lin5qubits/main.py': [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/home/gjones/scratch/lin5qubits/main.py", line 19, in <module>
    from quantum.Quantum import QuantumRegressor
ModuleNotFoundError: No module named 'quantum'
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/lin5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Wed Mar 27 09:48:33 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 09:48:55 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 09:59:47 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 10:01:32 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 10:09:56 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 10:18:48 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 10:19:30 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 10:29:52 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 10:31:25 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3135.6145825386047 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 10:41:10 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 10:51:50 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 10:53:34 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 11:01:53 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 11:10:43 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 11:11:25 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 11:21:43 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 11:23:16 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3104.612403869629 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 11:32:54 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 11:43:40 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 11:45:23 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 11:53:43 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 12:02:30 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 12:03:11 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 12:13:36 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 12:15:10 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3114.698097229004 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 12:24:49 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 12:35:33 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 12:37:16 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 12:45:38 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 12:54:29 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 12:55:11 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 13:05:33 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 13:07:06 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3116.5661945343018 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 13:16:45 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 13:27:21 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 13:29:05 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 13:37:24 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 13:46:10 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 13:46:52 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 13:57:17 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 13:58:51 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3108.2205362319946 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 14:08:34 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 14:19:19 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 14:21:03 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 14:29:23 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 14:38:10 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 14:38:57 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 14:49:17 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 14:50:50 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3116.7366194725037 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 15:00:30 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 15:11:14 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 15:13:00 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 15:21:22 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 15:30:11 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 15:30:54 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 15:41:18 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 15:42:51 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3125.8273482322693 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 15:52:36 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 16:03:21 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 16:05:06 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 16:13:21 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 16:22:12 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 16:22:54 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 16:33:18 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 16:34:52 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3124.232223033905 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 16:44:41 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 16:55:26 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 16:57:10 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 17:05:30 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 17:14:23 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 17:15:05 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 17:25:29 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 17:27:02 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3120.134242296219 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 17:36:41 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 17:47:25 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 17:49:08 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 17:57:27 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 18:06:19 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 18:07:01 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 18:17:25 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 18:18:59 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3118.6742203235626 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 18:28:39 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 18:39:32 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 18:41:17 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 18:49:37 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 18:58:23 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 18:59:04 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 19:09:26 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 19:11:00 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3122.189870595932 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 19:20:42 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 19:31:28 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 19:33:12 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 19:41:33 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 19:50:24 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 19:51:06 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 20:01:34 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 20:03:08 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3126.981262922287 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 27 20:12:48 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 20:23:30 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 20:25:13 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 20:33:33 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 20:42:28 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 20:43:09 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 20:53:36 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 20:55:09 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3121.1971452236176 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 27 21:04:50 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 21:15:35 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 21:17:21 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 21:25:40 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 21:34:30 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 21:35:11 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 21:45:30 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 21:47:03 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3115.182550907135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Wed Mar 27 21:56:45 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 22:07:29 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 22:09:14 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 22:17:33 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 22:26:22 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 22:27:05 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 22:37:32 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 22:39:13 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3130.6544530391693 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 27 22:48:56 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 22:59:43 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 23:01:27 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Wed Mar 27 23:09:40 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 27 23:18:29 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Wed Mar 27 23:19:11 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Wed Mar 27 23:29:37 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Wed Mar 27 23:31:10 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3119.9269409179688 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 27 23:40:56 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Wed Mar 27 23:51:41 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Wed Mar 27 23:53:25 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 28 00:01:43 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 00:10:33 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Thu Mar 28 00:11:15 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Thu Mar 28 00:21:39 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Thu Mar 28 00:23:12 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3115.965651512146 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 00:32:51 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Thu Mar 28 00:43:40 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Thu Mar 28 00:45:26 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 28 00:53:47 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 01:02:39 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Thu Mar 28 01:03:21 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Thu Mar 28 01:13:47 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Thu Mar 28 01:15:20 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3130.8398554325104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 01:25:02 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Thu Mar 28 01:35:51 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Thu Mar 28 01:37:36 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 28 01:45:56 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 01:54:43 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Thu Mar 28 01:55:25 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Thu Mar 28 02:05:49 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Thu Mar 28 02:07:23 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3127.318461894989 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 02:17:10 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Thu Mar 28 02:27:51 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Thu Mar 28 02:29:36 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 28 02:37:57 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 02:46:52 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Thu Mar 28 02:47:34 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Thu Mar 28 02:58:02 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Thu Mar 28 02:59:35 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3126.1146409511566 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 03:09:15 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Thu Mar 28 03:19:55 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Thu Mar 28 03:21:40 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 28 03:29:57 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 03:38:48 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Thu Mar 28 03:39:29 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Thu Mar 28 03:49:53 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Thu Mar 28 03:51:26 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3113.91592669487 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 04:01:10 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Thu Mar 28 04:11:51 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Thu Mar 28 04:13:34 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 28 04:21:54 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 04:30:44 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Thu Mar 28 04:31:25 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Thu Mar 28 04:41:51 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Thu Mar 28 04:43:24 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3115.558361053467 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 04:53:05 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Thu Mar 28 05:03:50 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Thu Mar 28 05:05:34 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 28 05:13:51 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 05:22:40 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Thu Mar 28 05:23:21 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Thu Mar 28 05:33:43 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Thu Mar 28 05:35:17 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3112.468537092209 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 05:44:58 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Thu Mar 28 05:55:37 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Thu Mar 28 05:57:20 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 28 06:05:34 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 06:14:20 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Thu Mar 28 06:15:01 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Thu Mar 28 06:25:29 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Thu Mar 28 06:27:03 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3106.6694190502167 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 06:36:45 2024]  Iteration number: 0 with current cost as 0.39145872035292484 and parameters 
[-3.02729926  2.50108491 -2.15614067 -0.11653103  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.70807014  1.14432444
  1.47874564 -1.87354681  0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Thu Mar 28 06:47:33 2024]  Iteration number: 50 with current cost as 0.1531189137852571 and parameters 
[-2.46387428  4.34110449 -4.36958802 -0.11652628  0.55389583 -2.77010124
  3.06858436  2.18960941  1.1855166  -1.06648143  0.50560663  1.14433955
  1.83416539 -1.87354687  0.72965956  2.88579091 -0.54534061 -0.47521499
 -2.02653639  0.72897748  1.60513748  2.83078646 -1.264526   -0.25136653]. 
Working on 0.4 fold... 
[Thu Mar 28 06:49:17 2024]  Iteration number: 0 with current cost as 0.3360030764754236 and parameters 
[-3.02443579  2.41050393 -2.16326067 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.72181713  1.14432444
  1.48866273 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Mar 28 06:57:33 2024]  Iteration number: 0 with current cost as 0.3482538493723086 and parameters 
[-3.02587353  2.45963212 -2.15790569 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648309  0.71056259  1.14432445
  1.47916782 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 28 07:06:23 2024]  Iteration number: 50 with current cost as 0.13985122491652324 and parameters 
[-2.25911034  4.4715111  -1.36455425 -0.11651427  0.55389684 -2.77010583
  3.06859983  2.18960796  1.18553099 -1.06646961 -0.54095844  1.14431957
  2.43544039 -1.87354429  0.72964315  2.88579198 -0.54534133 -0.47521063
 -2.02652477  0.72898524  1.60512359  2.83079387 -1.2645478  -0.25135232]. 
Working on 0.8 fold... 
[Thu Mar 28 07:07:04 2024]  Iteration number: 0 with current cost as 0.3524868398729238 and parameters 
[-3.04155423  2.45482781 -2.16527    -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.73481721  1.14432445
  1.50706779 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
[Thu Mar 28 07:17:24 2024]  Iteration number: 50 with current cost as 0.13059165204697543 and parameters 
[-2.41916217  4.40323127 -4.34515506 -0.11654302  0.55389344 -2.77012382
  3.06859201  2.18959709  1.18550671 -1.06647316  0.57086849  1.144311
  1.80029215 -1.87355758  0.72965933  2.88577122 -0.5453369  -0.47522904
 -2.02652942  0.72897824  1.60512981  2.83078011 -1.26457501 -0.25136695]. 
Working on 1.0 fold... 
[Thu Mar 28 07:18:57 2024]  Iteration number: 0 with current cost as 0.3566712319929574 and parameters 
[-3.02364546  2.4419583  -2.15913733 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.71518199  1.14432445
  1.48179692 -1.8735468   0.7296508   2.8857842  -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 3110.143228530884 seconds. 
Discarding model... 

Training complete taking 77980.44409179688 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 1.095931053161621 seconds. 
Saved predicted values as M-A1-CNOT_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (89.74714785628863,), 'R2_train': 0.5652051892077374, 'MAE_train': 8.481523444833792, 'MSE_test': 207.79773573772187, 'R2_test': -0.25256608195470753, 'MAE_test': 10.734442261312603}. 
Saved model results as M-A1-CNOT_Full-Pauli-CRX_results.json. 
