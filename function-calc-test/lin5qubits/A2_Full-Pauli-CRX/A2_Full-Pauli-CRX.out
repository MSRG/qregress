/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:51:52 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:23 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:27 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 18:05:03 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Sun Mar 24 18:09:59 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Sun Mar 24 18:13:24 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 18:22:12 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Sun Mar 24 18:24:36 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2137.989541053772 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:28:02 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Sun Mar 24 18:31:06 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 18:40:21 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Sun Mar 24 18:45:18 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Sun Mar 24 18:48:41 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 18:57:39 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Sun Mar 24 19:00:03 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2127.4457907676697 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 19:03:28 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Sun Mar 24 19:06:35 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 19:15:44 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Sun Mar 24 19:20:41 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Sun Mar 24 19:24:06 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 19:32:51 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Sun Mar 24 19:35:12 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2106.4503836631775 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 19:38:43 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Sun Mar 24 19:41:48 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 19:51:27 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Sun Mar 24 19:56:26 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Sun Mar 24 19:59:57 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 20:08:49 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Sun Mar 24 20:11:10 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2158.2982738018036 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 20:14:33 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Sun Mar 24 20:17:41 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 20:27:06 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Sun Mar 24 20:32:02 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Sun Mar 24 20:35:26 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 20:44:19 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Sun Mar 24 20:46:41 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2132.2661221027374 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 20:50:05 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Sun Mar 24 20:53:07 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 21:02:27 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Sun Mar 24 21:07:26 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Sun Mar 24 21:10:47 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 21:19:40 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Sun Mar 24 21:22:03 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2126.626802921295 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 21:25:32 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Sun Mar 24 21:28:36 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 21:38:15 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Sun Mar 24 21:43:08 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Sun Mar 24 21:46:35 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 21:55:46 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Sun Mar 24 21:58:23 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2174.298187017441 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 22:01:46 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Sun Mar 24 22:04:51 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 22:14:11 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Sun Mar 24 22:19:11 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Sun Mar 24 22:22:41 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 22:31:30 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Sun Mar 24 22:34:03 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2151.6630709171295 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 22:37:38 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Sun Mar 24 22:40:42 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 22:49:52 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Sun Mar 24 22:54:46 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Sun Mar 24 22:58:10 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 23:07:05 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Sun Mar 24 23:09:33 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2120.4097616672516 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 23:12:58 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Sun Mar 24 23:16:25 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 23:25:46 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Sun Mar 24 23:30:45 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Sun Mar 24 23:34:08 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Sun Mar 24 23:42:57 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Sun Mar 24 23:45:20 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2144.403345108032 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 23:48:42 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Sun Mar 24 23:51:45 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 00:01:22 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 00:06:35 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 00:10:01 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 00:19:09 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 00:21:29 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2190.2013323307037 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 00:25:12 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 00:28:16 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 00:37:45 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 00:42:53 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 00:46:19 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 00:55:10 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 00:57:36 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2146.500872373581 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 01:01:00 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 01:04:05 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 01:13:19 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 01:18:15 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 01:21:36 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 01:30:30 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 01:32:53 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2120.371528863907 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 01:36:19 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 01:39:20 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 01:48:43 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 01:54:08 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 01:57:34 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 02:06:39 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 02:09:02 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2165.987762928009 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 02:12:26 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 02:15:29 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 02:24:54 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 02:29:57 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 02:33:23 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 02:42:07 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 02:44:29 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2127.314850330353 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 25 02:47:53 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 02:51:10 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 03:00:20 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 03:05:17 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 03:09:03 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 03:17:56 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 03:20:16 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2145.4528110027313 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 03:23:39 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 03:26:45 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 03:36:07 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 03:41:01 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 03:44:24 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 03:53:10 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 03:55:33 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2118.837168455124 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 03:58:57 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 04:02:04 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 04:11:12 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 04:16:12 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 04:19:38 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 04:28:43 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 04:31:07 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2132.0962052345276 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 04:34:29 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 04:37:30 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 04:46:37 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 04:51:41 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 04:55:36 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 05:05:06 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 05:07:39 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2194.066204547882 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 05:11:04 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 05:14:07 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 05:23:17 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 05:28:13 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 05:31:42 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 05:40:41 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 05:43:04 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2123.855367422104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Mar 25 05:46:27 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 05:49:40 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 05:59:21 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 06:04:16 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 06:07:47 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 06:16:49 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 06:19:11 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2171.58673620224 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Mar 25 06:22:39 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 06:25:42 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 06:34:47 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 06:39:48 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 06:43:12 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 06:52:13 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 06:55:11 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2154.5765924453735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Mar 25 06:58:33 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 07:01:36 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 07:10:43 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 07:15:47 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 07:19:12 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 07:27:58 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 07:30:20 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2108.138251543045 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Mar 25 07:33:41 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 07:36:42 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 07:45:53 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 07:50:51 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 07:54:14 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 08:03:07 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 08:05:29 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2117.1628053188324 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Mar 25 08:08:59 2024]  Iteration number: 0 with current cost as 0.11678073324100832 and parameters 
[-2.81357337  2.13824775 -2.10179959 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.44057494  1.14432445
  1.1279041  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Mon Mar 25 08:12:07 2024]  Iteration number: 0 with current cost as 0.0956169657819254 and parameters 
[-2.83278333  2.17061555 -2.10547761 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.48026432  1.14432445
  1.17099977 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 08:21:38 2024]  Iteration number: 50 with current cost as 0.04166702021878999 and parameters 
[-3.23458804  1.57445476 -0.76510495 -0.11647673  0.55397488 -2.77005239
  3.0686902   2.18967541  1.18558375 -1.06637304  0.02270673  1.14453939
  1.56680405 -1.87348563  0.72978146  2.88587114 -0.54534887 -0.47525211
 -2.02658895  0.72901747  1.60518003  2.83077312 -1.26464509 -0.25137257]. 
Working on 0.6 fold... 
[Mon Mar 25 08:26:31 2024]  Iteration number: 0 with current cost as 0.09878187757510767 and parameters 
[-2.82416417  2.16080633 -2.10359567 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46454259  1.14432445
  1.15376436 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Mar 25 08:29:54 2024]  Iteration number: 0 with current cost as 0.10913781969723677 and parameters 
[-2.82282555  2.1516392  -2.10396382 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.45863434  1.14432445
  1.14781607 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Mon Mar 25 08:38:52 2024]  Iteration number: 50 with current cost as 0.04158091252606293 and parameters 
[-2.32363525  1.53308328 -4.514185   -0.1165482   0.55387874 -2.77012923
  3.06856793  2.18957937  1.18552898 -1.06651051  0.09441066  1.14431312
  1.48823947 -1.87355902  0.72965915  2.88579034 -0.5453772  -0.47524869
 -2.02654323  0.72897329  1.6051345   2.83076869 -1.26454435 -0.25137675]. 
Working on 1.0 fold... 
[Mon Mar 25 08:41:16 2024]  Iteration number: 0 with current cost as 0.10387431434027387 and parameters 
[-2.82589122  2.16153221 -2.10395751 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.46718694  1.14432445
  1.15659563 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Training complete taking 2151.517373085022 seconds. 
Discarding model... 

Training complete taking 53547.5185046196 total seconds. 
Now scoring model... 
Scoring complete taking 0.9929025173187256 seconds. 
Saved predicted values as A2_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (27.61296064674166,), 'R2_train': 0.8662244730156852, 'MAE_train': 3.713096917624143, 'MSE_test': 30.748108715798402, 'R2_test': 0.8146561225754806, 'MAE_test': 3.5692210550880246}. 
Saved model results as A2_Full-Pauli-CRX_results.json. 
