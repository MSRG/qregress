/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:37:33 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:37:36 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:37:47 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:37:57 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:05 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:15 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.1454131603241 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:38:21 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:38:31 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:38:41 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:38:50 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:38:58 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 43.743770360946655 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:05 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:39:16 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:39:26 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:39:34 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:39:42 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.666879415512085 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:39:50 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:00 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:09 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:40:19 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:40:27 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.097252368927 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:40:34 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:40:45 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:40:55 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:04 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:13 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 46.10783886909485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:41:20 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:41:30 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:41:40 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:41:49 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:41:57 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.07689046859741 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:04 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:42:15 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:42:26 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:42:34 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:42:43 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 46.22558236122131 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:42:50 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:00 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:10 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:43:20 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:43:28 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.44673681259155 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:43:35 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:43:45 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:43:55 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:04 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:12 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.99818682670593 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:44:20 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:44:30 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:44:40 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:44:49 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:44:57 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.33018755912781 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:04 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:15 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:45:25 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:45:33 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:45:41 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.30850672721863 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:45:49 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:45:59 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:09 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:46:18 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:46:27 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.078049182891846 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:46:33 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:46:44 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:46:54 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:02 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:11 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.15742802619934 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:47:18 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:47:28 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:47:38 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:47:48 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:47:56 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.6168737411499 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:03 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:14 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:48:24 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:48:32 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:48:41 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.1448974609375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:48:48 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:48:58 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:08 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:49:17 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:49:26 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 43.94034719467163 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:49:32 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:49:42 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:49:53 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:02 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:10 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.58795475959778 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:50:18 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:50:28 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:50:38 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:50:47 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:50:55 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.16153120994568 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:02 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:12 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:51:23 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:51:31 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:51:40 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.46319842338562 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:51:47 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:51:57 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:07 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:17 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:25 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.15935015678406 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:32 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:42 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:53 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:01 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:10 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.95928382873535 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:17 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:53:27 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:37 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:46 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:55 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.71382188796997 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:01 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:11 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:22 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:31 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:39 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.42978048324585 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:47 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:57 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:07 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:55:16 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:24 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 45.399715423583984 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:31 2024]  Iteration number: 0 with current cost as 0.2527743414656584 and parameters 
[-2.9089502   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:41 2024]  Iteration number: 0 with current cost as 0.23412586280440809 and parameters 
[-2.80828337  2.23743462 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:52 2024]  Iteration number: 0 with current cost as 0.23189760302654247 and parameters 
[-2.88254197  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:00 2024]  Iteration number: 0 with current cost as 0.23747071680593895 and parameters 
[-2.87891612  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:09 2024]  Iteration number: 0 with current cost as 0.2353416871278815 and parameters 
[-2.86206822  2.23743464 -2.12427965 -0.11653103  0.55388709]. 
Training complete taking 44.60968995094299 seconds. 
Discarding model... 

Training complete taking 1119.5699911117554 total seconds. 
Now scoring model... 
Scoring complete taking 0.7938284873962402 seconds. 
Saved predicted values as A2-A2-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (149.3261673368832,), 'R2_train': 0.27656483549160005, 'MAE_train': 10.659776152134427, 'MSE_test': 152.9774006211684, 'R2_test': 0.07788069661392127, 'MAE_test': 10.807596130858311}. 
Saved model results as A2-A2-CNOT_Hadamard_results.json. 
