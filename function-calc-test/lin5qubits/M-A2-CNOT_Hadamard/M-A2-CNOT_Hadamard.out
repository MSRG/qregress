/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /linear_train.bin... 
Successfully loaded /linear_train.bin into X and y data. 
Loading dataset from /linear_test.bin... 
Successfully loaded /linear_test.bin into X and y data. 
Training model with dataset /linear_train.bin 
 at time Sun Mar 24 17:51:59 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:52:03 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:52:17 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:52:27 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:52:40 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:52:52 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.07322406768799 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:53:04 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:53:17 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:53:27 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:53:40 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:53:52 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.2010498046875 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:54:04 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:54:17 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:54:27 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:54:41 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:54:52 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.26896929740906 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 17:55:04 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:55:18 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:55:28 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:55:43 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:55:55 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 62.19820475578308 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 17:56:06 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:56:20 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:56:30 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:56:43 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:56:55 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.18289279937744 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 17:57:07 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:57:20 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:57:30 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:57:43 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:57:55 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.738574504852295 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 17:58:07 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:58:21 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:58:31 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:58:44 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:58:56 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.4591851234436 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 17:59:08 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 17:59:21 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 17:59:31 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 17:59:44 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 17:59:56 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.441147804260254 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:00:08 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:00:22 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:00:32 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:00:45 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:00:57 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.76356625556946 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:01:11 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:01:23 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:01:32 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:01:46 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:01:58 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.55443620681763 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:02:11 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:02:23 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:02:34 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:02:47 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:02:59 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.99647665023804 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:03:13 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:03:25 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:03:35 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:03:48 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:04:00 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.28160238265991 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:04:13 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:04:25 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:04:35 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:04:50 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:05:02 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.39907193183899 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:05:15 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:05:27 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:05:37 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:05:51 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:06:03 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.40053200721741 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:06:17 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:06:29 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:06:38 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:06:52 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:07:04 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.31424951553345 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:07:17 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:07:29 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:07:39 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:07:52 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:08:04 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.42597579956055 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:08:17 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:08:29 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:08:39 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:08:53 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:09:05 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.23915410041809 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:09:18 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:09:30 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:09:41 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:09:53 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:10:05 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.50991892814636 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:10:18 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:10:30 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:10:42 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:10:54 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:11:06 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.9846887588501 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:11:19 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:11:31 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:11:42 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:11:54 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:12:06 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.98421311378479 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Sun Mar 24 18:12:20 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:12:32 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:12:44 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:12:56 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:13:08 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.314136266708374 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Sun Mar 24 18:13:21 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:13:33 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:13:45 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:13:57 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:14:09 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.50403547286987 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Sun Mar 24 18:14:22 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:14:34 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:14:45 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:14:57 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:15:09 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.51440715789795 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Sun Mar 24 18:15:22 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:15:34 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:15:46 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:15:58 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:16:10 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.5365514755249 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Sun Mar 24 18:16:23 2024]  Iteration number: 0 with current cost as 0.21065064236306963 and parameters 
[-2.8664182   2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Sun Mar 24 18:16:35 2024]  Iteration number: 0 with current cost as 0.19163519967806117 and parameters 
[-2.70381002  2.23743464 -2.12427965 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Sun Mar 24 18:16:46 2024]  Iteration number: 0 with current cost as 0.18596939464630682 and parameters 
[-2.86489205  2.23743464 -2.12427964 -0.11653102  0.55388708]. 
Working on 0.8 fold... 
[Sun Mar 24 18:16:58 2024]  Iteration number: 0 with current cost as 0.19026985437157942 and parameters 
[-2.86336574  2.23743463 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Sun Mar 24 18:17:11 2024]  Iteration number: 0 with current cost as 0.19524696203673586 and parameters 
[-2.86367679  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 60.37899398803711 seconds. 
Discarding model... 

Training complete taking 1520.6660678386688 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Ignoring NaN found at index: 0. With feature: 1.020408163265306. 
Scoring complete taking 0.8420021533966064 seconds. 
Saved predicted values as M-A2-CNOT_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (118.91465233650658,), 'R2_train': 0.42389841907988646, 'MAE_train': 8.931879724454841, 'MSE_test': 147.36950445631172, 'R2_test': 0.1116840511225059, 'MAE_test': 9.646020215290193}. 
Saved model results as M-A2-CNOT_Hadamard_results.json. 
