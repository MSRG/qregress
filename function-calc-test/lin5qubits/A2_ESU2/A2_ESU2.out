test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Fri Mar 22 04:41:14 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 22 04:41:29 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 04:42:04 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 04:42:31 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 04:43:02 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 04:43:33 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 155.1623933315277 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 22 04:44:05 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 04:44:40 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 04:45:07 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 04:45:38 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 04:46:09 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.85804438591003 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 22 04:46:39 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 04:47:14 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 04:47:41 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 04:48:12 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 04:48:43 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.84693360328674 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 22 04:49:14 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 04:49:48 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 04:50:15 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 04:50:46 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 04:51:17 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 153.93426203727722 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 22 04:51:48 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 04:52:23 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 04:52:51 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 04:53:22 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 04:53:52 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 155.23130798339844 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 22 04:54:23 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 04:54:57 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Fri Mar 22 04:55:24 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 04:55:54 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 04:56:25 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 152.3510615825653 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 22 04:56:56 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 04:57:30 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 04:57:57 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 04:58:28 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 04:58:59 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.53823590278625 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 22 04:59:30 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:00:05 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:00:32 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:01:03 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:01:34 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.81456923484802 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 22 05:02:05 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:02:40 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:03:07 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:03:37 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:04:07 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 152.4941806793213 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 22 05:04:37 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:05:12 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:05:38 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:06:09 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:06:40 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 153.5099413394928 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 22 05:07:11 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:07:46 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:08:13 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:08:44 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:09:15 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.58767986297607 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 22 05:09:46 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Fri Mar 22 05:10:20 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:10:48 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:11:18 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:11:49 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.50512194633484 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 22 05:12:20 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:12:55 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:13:21 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:13:52 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:14:23 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 153.8921093940735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 22 05:14:54 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:15:29 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:15:56 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:16:27 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:16:57 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.06351828575134 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 22 05:17:28 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:18:03 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:18:30 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:19:01 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:19:32 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.79549980163574 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 22 05:20:03 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:20:37 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:21:04 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:21:35 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:22:06 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.17536616325378 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 22 05:22:37 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:23:12 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:23:39 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:24:10 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:24:41 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.5364110469818 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.2 fold... 
[Fri Mar 22 05:25:12 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:25:46 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:26:13 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:26:44 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:27:15 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.5521764755249 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 22 05:27:46 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:28:20 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:28:47 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:29:17 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:29:47 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 151.5485405921936 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 22 05:30:18 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:30:52 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:31:19 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:31:50 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:32:21 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 153.8613634109497 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Mar 22 05:32:52 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:33:26 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:33:53 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:34:24 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:34:55 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.48741745948792 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Mar 22 05:35:26 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:36:01 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:36:28 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:36:59 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:37:30 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.56246328353882 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Mar 22 05:38:01 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:38:35 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:39:02 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:39:33 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:40:04 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Training complete taking 153.9768102169037 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Mar 22 05:40:34 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:41:09 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:41:36 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:42:07 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:42:38 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.27482104301453 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Mar 22 05:43:09 2024]  Iteration number: 0 with current cost as 0.08254126135184216 and parameters 
[-1.8061569   2.23743466 -2.12427959 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960148  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Mar 22 05:43:44 2024]  Iteration number: 0 with current cost as 0.04565948306169125 and parameters 
[-1.63842078  2.23743464 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Mar 22 05:44:11 2024]  Iteration number: 0 with current cost as 0.0636736913151231 and parameters 
[-1.75675894  2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Mar 22 05:44:42 2024]  Iteration number: 0 with current cost as 0.06242059885217759 and parameters 
[-1.74666116  2.23743464 -2.12427961 -0.11653101  0.55388708 -2.77010897
  3.06858496  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Mar 22 05:45:12 2024]  Iteration number: 0 with current cost as 0.06501695523109059 and parameters 
[-1.74143584  2.23743466 -2.12427958 -0.116531    0.55388709 -2.77010897
  3.06858498  2.18960148  1.18552001 -1.06648308]. 
Training complete taking 154.55154585838318 seconds. 
Discarding model... 

Training complete taking 3854.1121232509613 total seconds. 
Now scoring model... 
Scoring complete taking 0.6760740280151367 seconds. 
Saved predicted values as A2_ESU2_predicted_values.csv
Model scores: {'MSE_train': (27.708903467706307,), 'R2_train': 0.8657596622480495, 'MAE_train': 3.714968878299922, 'MSE_test': 29.353778752859398, 'R2_test': 0.8230608841212702, 'MAE_test': 3.5003653005580384}. 
Saved model results as A2_ESU2_results.json. 
