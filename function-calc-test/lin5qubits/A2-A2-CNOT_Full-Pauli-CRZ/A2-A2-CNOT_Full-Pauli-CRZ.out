test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Tue Mar 19 01:04:24 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 01:04:31 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 01:06:29 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 01:08:27 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 01:10:26 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 01:12:37 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 597.346129655838 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 01:14:28 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 01:16:27 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 01:18:25 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 01:20:23 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 01:22:34 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 597.9628286361694 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 01:24:26 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 01:26:25 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 01:28:24 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 01:30:23 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 01:32:34 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 599.3420875072479 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 01:34:25 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 01:36:22 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Tue Mar 19 01:38:21 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 01:40:21 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 01:42:32 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 598.7626888751984 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 01:44:24 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 01:46:23 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 01:48:22 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 01:50:21 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 01:52:34 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 603.7934603691101 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 01:54:28 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 01:56:27 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 01:58:26 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 02:00:26 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 02:02:39 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 602.8086912631989 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 02:04:31 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 02:06:30 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 02:08:29 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 02:10:28 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 02:12:40 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 600.5764298439026 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.2 fold... 
[Tue Mar 19 02:14:31 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 02:16:30 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 02:18:29 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 02:20:27 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 02:22:38 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 599.4457330703735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 02:24:31 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 02:26:29 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 02:28:27 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 02:30:25 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 02:32:37 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 599.2586259841919 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 02:34:30 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 02:36:30 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 02:38:27 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 02:40:26 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 02:42:37 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 598.4896230697632 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 02:44:29 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 02:46:28 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 02:48:28 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 02:50:27 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Tue Mar 19 02:52:40 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 605.0310289859772 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 02:54:33 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 02:56:32 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 02:58:32 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 03:00:34 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 03:02:48 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 608.3942663669586 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 03:04:42 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 03:06:42 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 03:08:41 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 03:10:42 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 03:12:54 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 605.9372968673706 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 03:14:48 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 03:16:49 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 03:18:48 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 03:20:47 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 03:23:01 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 607.2561075687408 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 03:24:55 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 03:26:55 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Tue Mar 19 03:28:56 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 03:30:55 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 03:33:08 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 606.4852061271667 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 03:35:02 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 03:37:02 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 03:39:02 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 03:41:01 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 03:43:14 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 606.4762029647827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 03:45:08 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 03:47:09 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 03:49:09 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 03:51:08 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 03:53:20 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 603.2427597045898 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 03:55:11 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 03:57:10 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 03:59:09 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 04:01:08 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 04:03:19 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 599.6216917037964 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.2 fold... 
[Tue Mar 19 04:05:11 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 04:07:09 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 04:09:06 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 04:11:05 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 04:13:18 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 598.2758984565735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 04:15:09 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 04:17:08 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 04:19:05 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 04:21:02 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 04:23:13 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 596.3829374313354 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Mar 19 04:25:06 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 04:27:05 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 04:29:03 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 04:31:01 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 04:33:11 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 597.3287265300751 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Mar 19 04:35:03 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 04:37:02 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 04:39:01 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 04:40:59 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 1.0 fold... 
[Tue Mar 19 04:43:10 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 597.9354798793793 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Mar 19 04:45:01 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 04:46:58 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 04:48:57 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 04:50:55 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 04:53:07 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 596.9600265026093 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Mar 19 04:54:58 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 04:56:57 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 04:58:54 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 05:00:53 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 05:03:04 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 598.336106300354 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Mar 19 05:04:56 2024]  Iteration number: 0 with current cost as 0.4958932821769848 and parameters 
[-3.15542828  2.25085835 -2.13066552 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.60731508  1.14432445
  1.59312264 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Mar 19 05:06:56 2024]  Iteration number: 0 with current cost as 0.3874226354927425 and parameters 
[-3.24266215  2.2198048  -2.13373569 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.59719529  1.14432445
  1.70546837 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 0.6 fold... 
[Tue Mar 19 05:08:54 2024]  Iteration number: 0 with current cost as 0.41798265330906825 and parameters 
[-3.21678442  2.23460078 -2.13022526 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.59973283  1.14432445
  1.6692523  -1.8735468   0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Mar 19 05:10:52 2024]  Iteration number: 0 with current cost as 0.42124815713418 and parameters 
[-3.21568305  2.23351791 -2.13089025 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.60027365  1.14432446
  1.66667753 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Mar 19 05:13:04 2024]  Iteration number: 0 with current cost as 0.41920775453777726 and parameters 
[-3.21823375  2.23304738 -2.13201937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6015229   1.14432445
  1.67294842 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Training complete taking 599.9610571861267 seconds. 
Discarding model... 

Training complete taking 15025.411470413208 total seconds. 
Now scoring model... 
Scoring complete taking 0.3662745952606201 seconds. 
Saved predicted values as A2-A2-CNOT_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (102.82277684020451,), 'R2_train': 0.5018581551698957, 'MAE_train': 9.204393632813472, 'MSE_test': 130.6888642620876, 'R2_test': 0.21223184611362644, 'MAE_test': 9.835769627389942}. 
Saved model results as A2-A2-CNOT_Full-Pauli-CRZ_results.json. 
