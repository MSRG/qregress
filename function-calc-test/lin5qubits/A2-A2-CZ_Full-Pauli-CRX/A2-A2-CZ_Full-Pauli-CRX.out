test.sh: line 9: python: command not found
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_train.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_train.bin into X and y data. 
Loading dataset from /home/grierjones/qregress/function-calc-test/linear/linear_test.bin... 
Successfully loaded /home/grierjones/qregress/function-calc-test/linear/linear_test.bin into X and y data. 
Training model with dataset /home/grierjones/qregress/function-calc-test/linear/linear_train.bin 
 at time Wed Mar 20 22:14:55 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Wed Mar 20 22:15:04 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 20 22:19:30 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Wed Mar 20 22:22:53 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 20 22:27:05 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 20 22:31:51 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Wed Mar 20 22:32:38 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 20 22:37:15 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 20 22:43:30 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1881.9924285411835 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Wed Mar 20 22:46:26 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 20 22:50:50 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Wed Mar 20 22:54:11 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 20 22:58:24 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 20 23:03:11 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Wed Mar 20 23:03:59 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 20 23:08:36 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 20 23:14:52 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1882.5245537757874 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Wed Mar 20 23:17:49 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 20 23:22:11 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.4 fold... 
[Wed Mar 20 23:25:31 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Wed Mar 20 23:29:43 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Wed Mar 20 23:34:27 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Wed Mar 20 23:35:14 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Wed Mar 20 23:39:51 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 20 23:46:05 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1873.7930545806885 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Wed Mar 20 23:49:03 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Wed Mar 20 23:53:25 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Wed Mar 20 23:56:45 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 00:00:57 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 00:05:41 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 00:06:29 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 00:11:06 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 00:17:23 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1876.1938722133636 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 00:20:19 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 00:24:41 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 00:28:02 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 00:32:16 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 00:36:59 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

[Thu Mar 21 00:37:47 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 00:42:24 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 00:48:43 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1882.689058303833 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 00:51:41 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 00:56:03 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 00:59:23 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 01:03:36 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 01:08:21 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 01:09:09 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 01:13:45 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 01:20:06 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1881.801109790802 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 01:23:03 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 01:27:26 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 01:30:45 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 01:34:55 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 01:39:43 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 01:40:32 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 01:45:08 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 01:51:23 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1875.9427738189697 seconds. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 01:54:19 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 01:58:41 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 02:02:00 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 02:06:12 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 02:10:56 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 02:11:44 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 02:16:22 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 02:22:39 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1876.391969203949 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 02:25:35 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 02:29:57 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 02:33:16 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 02:37:29 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 02:42:15 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 02:43:03 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 02:47:38 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 02:53:54 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1874.7200338840485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 02:56:50 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 03:01:10 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 03:04:28 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Thu Mar 21 03:08:41 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 03:13:25 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 03:14:12 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 03:18:49 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 03:25:06 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1873.4425826072693 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 03:28:04 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 03:32:30 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 03:35:54 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 03:40:08 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 03:44:59 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 03:45:47 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 03:50:30 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 03:56:57 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1915.0026478767395 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 03:59:59 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 04:04:34 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 04:08:04 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 04:12:28 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 04:17:28 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 04:18:18 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

[Thu Mar 21 04:23:04 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 04:29:34 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1956.431309223175 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 04:32:35 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 04:37:02 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 04:40:25 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 04:44:41 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 04:49:30 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 04:50:18 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 04:54:57 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 05:01:16 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1897.5048966407776 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 05:04:13 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 05:08:37 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 05:11:58 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 05:16:12 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 05:21:01 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 05:21:50 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 05:26:28 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 05:32:47 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1890.2986183166504 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 05:35:43 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

[Thu Mar 21 05:40:06 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 05:43:27 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 05:47:39 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 05:52:26 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 05:53:13 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 05:57:49 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 06:04:04 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1876.6975951194763 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 06:07:00 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 06:11:20 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 06:14:39 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 06:18:50 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 06:23:37 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 06:24:25 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 06:29:02 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 06:35:28 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1888.347915172577 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 06:38:28 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 06:42:58 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 06:46:23 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 06:50:43 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 06:55:34 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.8 fold... 
[Thu Mar 21 06:56:24 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 07:01:05 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 07:07:24 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1913.4234874248505 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 07:10:22 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 07:14:46 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 07:18:08 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 07:22:21 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 07:27:07 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 07:27:55 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 07:32:31 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 07:38:48 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1882.124472618103 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 07:41:43 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 07:46:06 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 07:49:26 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 07:53:35 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 07:58:20 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 07:59:07 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 08:03:42 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 08:09:57 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1869.223232269287 seconds. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 08:12:53 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 08:17:14 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 08:20:33 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 08:24:46 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 08:29:33 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 08:30:20 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 08:34:58 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 08:41:12 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1875.5712718963623 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 21 08:44:08 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 08:48:29 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 08:51:50 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 08:56:05 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 09:00:50 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 09:01:37 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 09:06:12 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 09:12:26 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1873.06471991539 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 21 09:15:21 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 09:19:45 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 09:23:07 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

Working on 0.6 fold... 
[Thu Mar 21 09:27:21 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 09:32:05 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 09:32:53 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 09:37:30 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 09:43:50 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1884.3012118339539 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 21 09:46:46 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 09:51:07 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 09:54:28 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 09:58:41 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 10:03:33 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 10:04:21 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 10:09:00 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 10:15:18 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1888.3220388889313 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 21 10:18:14 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 10:22:39 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 10:25:59 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 10:30:13 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 10:35:03 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 10:35:52 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... /home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/grierjones/qregress/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,

[Thu Mar 21 10:40:28 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 10:46:47 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1888.3884692192078 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 21 10:49:43 2024]  Iteration number: 0 with current cost as 0.5130844548199507 and parameters 
[-2.75197672  2.28632797 -2.12114867 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.3780341   1.14432444
  1.05067254 -1.8735468   0.7296508   2.88578419 -0.54534336 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 10:54:04 2024]  Iteration number: 50 with current cost as 0.2922076708079707 and parameters 
[-3.0891205   4.73091128 -1.47610708 -0.1165296   0.55388884 -2.77010604
  3.06858806  2.18960158  1.18552417 -1.06648173 -3.1855851   1.14432823
  4.59179632 -1.87354699  0.72965172  2.88578661 -0.54534199 -0.47522279
 -2.02654047  0.72897457  1.60512854  2.83077373 -1.26456463 -0.25135931]. 
Working on 0.4 fold... 
[Thu Mar 21 10:57:25 2024]  Iteration number: 0 with current cost as 0.39984353290736496 and parameters 
[-2.78170203  2.30084814 -2.10372696 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.44079888  1.14432445
  1.11421869 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Thu Mar 21 11:01:39 2024]  Iteration number: 0 with current cost as 0.4542592707457813 and parameters 
[-2.76195014  2.28494601 -2.1157579  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.39737909  1.14432444
  1.07144793 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Mar 21 11:06:28 2024]  Iteration number: 50 with current cost as 0.25081107143397174 and parameters 
[-1.48364425  4.91045823 -4.20794058 -0.11654464  0.55389596 -2.77010935
  3.06859177  2.18959892  1.18552562 -1.06647887 -2.07225309  1.14432942
  1.77848394 -1.87353668  0.7296217   2.88578837 -0.54534032 -0.47521938
 -2.02654316  0.72896423  1.60512732  2.83077449 -1.2645626  -0.25136462]. 
Working on 0.8 fold... 
[Thu Mar 21 11:07:16 2024]  Iteration number: 0 with current cost as 0.4455005133126537 and parameters 
[-2.762878    2.28586773 -2.11583923 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648309  0.3989516   1.14432445
  1.07219662 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.26456709 -0.25136104]. 
Working on 1.0 fold... 
[Thu Mar 21 11:11:51 2024]  Iteration number: 0 with current cost as 0.44686702545391777 and parameters 
[-2.76576605  2.29179712 -2.10875152 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40794771  1.14432445
  1.08088684 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Thu Mar 21 11:18:05 2024]  Iteration number: 50 with current cost as 0.2621264537097872 and parameters 
[-2.44400337  4.71579697 -4.53100036 -0.11666609  0.55373557 -2.77026768
  3.06854281  2.18938333  1.18545275 -1.06668114 -3.11446233  1.14416948
  1.5482242  -1.87355135  0.72942201  2.88584395 -0.54544727 -0.47528855
 -2.02661387  0.72898175  1.60494584  2.83067059 -1.26461416 -0.25144653]. 
Training complete taking 1878.89914560318 seconds. 
Discarding model... 

Training complete taking 47157.09285759926 total seconds. 
Now scoring model... 
Scoring complete taking 0.4569985866546631 seconds. 
Saved predicted values as A2-A2-CZ_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (163.36686653920984,), 'R2_train': 0.20854236013848582, 'MAE_train': 11.01906391740815, 'MSE_test': 161.7546996069079, 'R2_test': 0.024972771695098483, 'MAE_test': 10.776712120574945}. 
Saved model results as A2-A2-CZ_Full-Pauli-CRX_results.json. 
