/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:34 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:50 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:42:18 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:45:58 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:51:00 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:54:41 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1256.1565783023834 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:58:45 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:03:13 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:06:57 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:11:57 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:15:36 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1254.0846412181854 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:19:39 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:24:08 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:27:56 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:32:59 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:36:58 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1280.1139953136444 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:41:01 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:45:29 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:49:11 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:54:11 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:57:50 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1262.5278759002686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:02:04 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:06:31 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:10:12 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:15:33 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:19:15 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1277.5754368305206 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:23:20 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:27:46 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:31:28 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:36:24 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:40:05 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1247.3540704250336 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:44:09 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:48:42 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:52:21 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:57:36 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:01:15 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1273.1049180030823 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:05:20 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:09:46 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:13:27 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:18:51 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:22:46 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1296.658941745758 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:26:57 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:31:54 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:35:35 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:40:38 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:44:17 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1283.0501363277435 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:48:20 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:52:47 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:56:28 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:01:43 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:05:21 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1263.6299073696136 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:09:23 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:13:49 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:17:28 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:22:27 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:26:07 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1245.0765347480774 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:30:10 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:34:36 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:38:15 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:43:13 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:46:52 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1252.180332660675 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:51:01 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:55:37 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:59:20 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:04:17 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:07:57 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1258.9561722278595 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:12:00 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:16:28 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:20:15 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:25:28 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:29:07 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1271.6877310276031 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:33:13 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:37:54 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:41:49 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:46:46 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:50:30 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1282.5314569473267 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:54:34 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:59:00 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:02:47 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:07:45 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:11:25 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1256.859634399414 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 03:15:31 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:19:57 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:23:37 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:28:35 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:32:15 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1248.3911066055298 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:36:21 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:41:01 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:44:40 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:49:38 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:53:18 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1260.983081817627 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:57:22 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:01:53 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:05:32 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:10:29 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:14:08 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1252.1530611515045 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 04:18:12 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:22:44 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:26:23 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:31:21 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:35:05 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1255.8650088310242 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 04:39:08 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:43:42 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:47:23 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:52:21 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:56:01 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1255.724856376648 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 05:00:04 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:04:36 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:08:17 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:13:26 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:17:04 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1264.3442602157593 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 05:21:09 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:25:37 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:29:16 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:34:16 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:37:57 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1251.2563440799713 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:42:01 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:46:29 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:50:07 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:55:06 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:58:44 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1246.2652428150177 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 06:02:46 2024]  Iteration number: 0 with current cost as 0.14763923666288709 and parameters 
[-3.28698667  2.16601748 -2.22288521 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.06648309  1.3840422   1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 06:07:11 2024]  Iteration number: 0 with current cost as 0.16480714733382165 and parameters 
[-3.29825992  2.19838689 -2.21079751 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  1.32926825  1.14432446
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:10:52 2024]  Iteration number: 0 with current cost as 0.16654278048982288 and parameters 
[-3.27058344  2.17469278 -2.21303883 -0.11653103  0.55388706 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  1.3361963   1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:15:48 2024]  Iteration number: 0 with current cost as 0.1442055536175917 and parameters 
[-3.3394072   2.18858348 -2.22073084 -0.11653103  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  1.40900889  1.14432446
  1.31029899 -1.87354679  0.7296508   2.8857842  -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:19:30 2024]  Iteration number: 0 with current cost as 0.16468629899499593 and parameters 
[-3.27789718  2.17868825 -2.22088944 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551999 -1.0664831   1.34389213  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1245.895345211029 seconds. 
Discarding model... 

Training complete taking 31542.42879962921 total seconds. 
Now scoring model... 
Scoring complete taking 1.1886775493621826 seconds. 
Saved predicted values as A2_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.14355663437376,), 'R2_train': 0.7141449451716836, 'MAE_train': 0.3201495451844707, 'MSE_test': 0.17466469449044314, 'R2_test': 0.6742564667069493, 'MAE_test': 0.36525110926143534}. 
Saved model results as A2_Modified-Pauli-CRX_results.json. 
