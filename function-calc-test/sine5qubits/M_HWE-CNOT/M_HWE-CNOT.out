/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:41:13 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:41:21 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 21:43:27 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 21:45:34 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 21:47:41 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 21:49:46 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 631.3385150432587 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:51:52 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 21:54:02 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 21:56:07 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 21:58:12 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 22:00:18 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 634.6929121017456 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:02:26 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 22:04:32 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 22:06:38 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 22:08:44 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 22:10:51 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 630.8962421417236 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:12:57 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 22:15:03 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 22:17:09 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 22:19:17 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 22:21:23 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 630.406411409378 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:23:28 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 22:25:32 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 22:27:36 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 22:29:41 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 22:31:49 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 626.520724773407 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:33:54 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 22:36:00 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 22:38:15 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 22:40:40 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 22:42:45 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 655.7373116016388 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:44:50 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 22:47:02 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 22:49:07 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 22:51:13 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 22:53:25 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 640.6784081459045 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:55:31 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 22:57:36 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 22:59:41 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 23:01:47 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 23:04:02 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 637.1933236122131 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:06:08 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 23:08:14 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 23:10:20 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 23:12:24 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 23:14:34 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 633.2852458953857 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:16:41 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 23:18:46 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 23:20:52 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 23:23:00 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 23:25:05 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 629.2022738456726 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:27:10 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 23:29:15 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 23:31:22 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 23:33:27 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 23:35:32 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 627.6537175178528 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:37:38 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 23:39:43 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 23:41:48 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 23:43:54 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 23:46:04 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 631.7954113483429 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:48:10 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Thu Apr  4 23:50:15 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Thu Apr  4 23:52:20 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Thu Apr  4 23:54:32 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Thu Apr  4 23:56:38 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 633.4769837856293 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:58:43 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 00:00:48 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 00:02:54 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 00:05:00 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 00:07:04 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 625.4548058509827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:09:09 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 00:11:14 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 00:13:21 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 00:15:27 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 00:17:33 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 630.971696138382 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:19:40 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 00:21:48 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 00:23:55 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 00:26:00 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 00:28:06 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 632.9952700138092 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:30:12 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 00:32:21 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 00:34:27 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 00:36:32 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 00:38:37 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 629.4201180934906 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:40:42 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 00:42:48 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 00:44:53 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 00:46:58 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 00:49:03 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 627.798990726471 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:51:10 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 00:53:21 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 00:55:27 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 00:57:36 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 00:59:41 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 649.1709983348846 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:01:59 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 01:04:05 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 01:06:10 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 01:08:15 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 01:10:35 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 645.3786540031433 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:12:44 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 01:14:50 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 01:16:56 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 01:19:06 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 01:21:11 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 632.1805975437164 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:23:17 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 01:25:32 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 01:27:37 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 01:29:43 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 01:31:49 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 637.3142230510712 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:33:54 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 01:35:59 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 01:38:04 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 01:40:26 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 01:42:32 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 646.5258104801178 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:44:40 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 01:46:45 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 01:48:49 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 01:50:54 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 01:53:00 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 625.7054634094238 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:55:06 2024]  Iteration number: 0 with current cost as 0.28895695738413807 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11457796  0.55352016 -2.76839506
  3.15654716  2.13174582  1.06682604 -1.07152996  0.61954787  1.14346099
  1.41663928 -1.77520745  0.72502991]. 
Working on 0.4 fold... 
[Fri Apr  5 01:57:11 2024]  Iteration number: 0 with current cost as 0.29742930402219775 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.1134126   0.55288088 -2.76803974
  3.14673392  2.13633966  1.08112743 -1.07019119  0.61955714  1.14508901
  1.42559935 -1.76852392  0.71890409]. 
Working on 0.6 fold... 
[Fri Apr  5 01:59:19 2024]  Iteration number: 0 with current cost as 0.29820047119380083 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.11490151  0.55324584 -2.769211
  3.14670253  2.13808613  1.08018691 -1.07185255  0.61887645  1.14285949
  1.42695986 -1.76730796  0.71869395]. 
Working on 0.8 fold... 
[Fri Apr  5 02:01:24 2024]  Iteration number: 0 with current cost as 0.2835649948888492 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.11817074  0.5528335  -2.77370957
  3.15979729  2.12951931  1.06249096 -1.07616953  0.61957831  1.13783861
  1.42172487 -1.76695346  0.73752149]. 
Working on 1.0 fold... 
[Fri Apr  5 02:03:31 2024]  Iteration number: 0 with current cost as 0.28652872095153903 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.11209433  0.55272877 -2.7667312
  3.15820111  2.1309282   1.06444035 -1.06816803  0.61853566  1.14722552
  1.41414053 -1.78110424  0.71230068]. 
Training complete taking 630.4206483364105 seconds. 
Discarding model... 

Training complete taking 15856.216358661652 total seconds. 
Now scoring model... 
Scoring complete taking 1.598379373550415 seconds. 
Saved predicted values as M_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (0.20202966553838922,), 'R2_train': 0.5977113745292797, 'MAE_train': 0.3866769871512122, 'MSE_test': 0.21867930164571833, 'R2_test': 0.5921707670577312, 'MAE_test': 0.41533097461685886}. 
Saved model results as M_HWE-CNOT_results.json. 
