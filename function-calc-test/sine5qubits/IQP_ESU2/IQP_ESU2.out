/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:45:43 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:46:14 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 21:47:37 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 21:48:58 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 21:50:21 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 21:51:29 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 396.53214502334595 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:51 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 21:54:12 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 21:55:33 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 21:56:54 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 21:58:00 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 391.52306842803955 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:59:25 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:00:48 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:02:06 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:03:28 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:04:32 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 389.11065888404846 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:05:54 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:07:16 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:08:40 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:10:06 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:11:12 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 401.5641670227051 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:12:36 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:13:57 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:15:18 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:16:38 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:17:43 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 390.8451693058014 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:19:05 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:20:26 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:21:41 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:22:59 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:24:02 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 377.65291023254395 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:25:23 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:26:42 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:28:07 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:29:27 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:30:32 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 389.57998275756836 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:31:53 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:33:10 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:34:31 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:35:51 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:36:54 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 383.2175488471985 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:38:15 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:39:33 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:40:54 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:42:10 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:43:12 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 378.44539165496826 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:44:33 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:45:51 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:47:14 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:48:31 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:49:33 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 379.5387580394745 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:50:51 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:52:11 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:53:31 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 22:54:51 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:55:53 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 379.6299340724945 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:57:13 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:58:32 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:59:49 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:01:11 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:02:17 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 383.51850509643555 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:03:38 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:04:58 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:06:17 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:07:39 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:08:41 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 384.8367164134979 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:10:00 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:11:23 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:12:43 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:14:04 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:15:09 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 387.47097992897034 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:16:28 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:17:45 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:19:07 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:20:25 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:21:26 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 375.2319767475128 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:22:42 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:24:02 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:25:22 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:26:44 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:27:47 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 384.6698935031891 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:29:08 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:30:32 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:31:54 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:33:19 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:34:26 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 397.76219725608826 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:35:45 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:37:05 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:38:25 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:39:46 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:40:49 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 382.22916078567505 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:42:07 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:43:28 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:44:50 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:46:10 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:47:12 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 383.9601950645447 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:48:33 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:49:54 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:51:11 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:52:32 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:53:36 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 382.02441358566284 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:54:53 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:56:13 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:57:31 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Thu Apr  4 23:58:50 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:59:52 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 377.04432344436646 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:01:12 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:02:32 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:03:53 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 00:05:12 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:06:15 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 383.04955649375916 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:07:34 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:08:54 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:10:08 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 00:11:28 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:12:31 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 376.9340224266052 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:13:51 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:15:09 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:16:29 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 00:17:49 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:18:52 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 380.9295346736908 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:20:12 2024]  Iteration number: 0 with current cost as 0.30348315502753753 and parameters 
[-3.23256692  2.23743464 -2.12427963 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:21:32 2024]  Iteration number: 0 with current cost as 0.30856816459643366 and parameters 
[-3.28078053  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:22:49 2024]  Iteration number: 0 with current cost as 0.31179930671635536 and parameters 
[-3.29412793  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Fri Apr  5 00:24:08 2024]  Iteration number: 0 with current cost as 0.2915533592773666 and parameters 
[-3.18818689  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:25:11 2024]  Iteration number: 0 with current cost as 0.3038384160156242 and parameters 
[-3.25358074  2.23743464 -2.12427964 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308]. 
Training complete taking 378.78037548065186 seconds. 
Discarding model... 

Training complete taking 9616.083231925964 total seconds. 
Now scoring model... 
Scoring complete taking 2.256300926208496 seconds. 
Saved predicted values as IQP_ESU2_predicted_values.csv
Model scores: {'MSE_train': (0.5020917512631774,), 'R2_train': 0.00021712188861888748, 'MAE_train': 0.6187143190264797, 'MSE_test': 0.5742250054672107, 'R2_test': -0.0709095088266114, 'MAE_test': 0.6784095303134896}. 
Saved model results as IQP_ESU2_results.json. 
