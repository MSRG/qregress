/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 22:03:30 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:04:35 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Thu Apr  4 22:06:20 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:08:25 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Thu Apr  4 22:10:11 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:12:35 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 634.0519464015961 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:15:09 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Thu Apr  4 22:16:52 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:18:49 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Thu Apr  4 22:20:35 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:22:58 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 625.1857304573059 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:25:36 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Thu Apr  4 22:27:17 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:29:17 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Thu Apr  4 22:31:02 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:33:27 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 625.4900133609772 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:36:00 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Thu Apr  4 22:37:41 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:39:40 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Thu Apr  4 22:41:23 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:43:45 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 621.0535163879395 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:46:22 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Thu Apr  4 22:48:12 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:50:08 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Thu Apr  4 22:51:55 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:54:17 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 635.7311553955078 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:56:54 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Thu Apr  4 22:58:35 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:00:32 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Thu Apr  4 23:02:14 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:04:35 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 613.1162433624268 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:07:09 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Thu Apr  4 23:08:55 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:10:54 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Thu Apr  4 23:12:38 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:15:00 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 629.574967622757 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:17:38 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Thu Apr  4 23:19:24 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:21:26 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Thu Apr  4 23:23:12 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:25:34 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 629.2262053489685 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:28:09 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Thu Apr  4 23:30:01 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:32:03 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Thu Apr  4 23:33:45 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:36:14 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 643.7221522331238 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:38:50 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Thu Apr  4 23:40:39 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:42:40 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Thu Apr  4 23:44:20 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:46:45 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 631.2050445079803 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:49:25 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Thu Apr  4 23:51:11 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:53:08 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Thu Apr  4 23:54:52 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:57:11 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 623.8203067779541 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:59:46 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 00:01:34 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:03:30 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 00:05:15 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:07:37 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 625.4389007091522 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:10:09 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 00:11:55 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:13:48 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 00:15:32 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:17:53 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 612.4352283477783 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:20:28 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 00:22:11 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:24:07 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 00:25:51 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:28:16 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 627.8479475975037 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:30:50 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 00:32:32 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:34:23 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 00:36:08 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:38:32 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 619.6878352165222 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:41:12 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 00:42:57 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:44:59 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 00:46:46 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:49:05 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 632.3543694019318 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:51:46 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 00:53:29 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:55:29 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 00:57:11 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:59:31 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 621.7981324195862 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:02:03 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 01:03:47 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 01:05:46 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 01:07:27 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:09:52 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 623.7944180965424 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:12:30 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 01:14:12 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 01:16:11 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 01:18:00 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:20:22 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 627.6952753067017 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:22:55 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 01:24:37 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 01:26:32 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 01:28:14 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:30:38 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 613.40616106987 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:33:11 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 01:34:55 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 01:36:47 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 01:38:29 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:40:56 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 620.5405309200287 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:43:32 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 01:45:15 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 01:47:23 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 01:49:10 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:51:39 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 643.359988451004 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:54:15 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 01:56:02 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 01:58:07 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 01:59:53 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 02:02:20 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 640.8454871177673 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:04:54 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 02:06:39 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 02:08:36 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 02:10:21 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 02:12:46 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 622.5368843078613 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:15:17 2024]  Iteration number: 0 with current cost as 0.37427971547740024 and parameters 
[-1.62040785  2.23743468 -2.12427959 -0.11653103  0.55388713 -2.77010897
  3.06858498  2.1896015   1.18552003 -1.06648313]. 
Working on 0.4 fold... 
[Fri Apr  5 02:17:02 2024]  Iteration number: 0 with current cost as 0.39862973917640054 and parameters 
[-1.74448784  2.23743464 -2.12427952 -0.11653097  0.55388708 -2.77010897
  3.06858498  2.18960151  1.18552004 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 02:18:57 2024]  Iteration number: 0 with current cost as 0.4037442351260631 and parameters 
[-1.64905302  2.23743464 -2.12427958 -0.11653103  0.55388714 -2.77010903
  3.06858498  2.18960151  1.18552004 -1.06648314]. 
Working on 0.8 fold... 
[Fri Apr  5 02:20:39 2024]  Iteration number: 0 with current cost as 0.6283623968887386 and parameters 
[12.50867809  2.23743527 -2.12427837 -0.11653039  0.55388835 -2.77010834
  3.06858562  2.18960272  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 02:23:03 2024]  Iteration number: 0 with current cost as 0.6517275381789074 and parameters 
[12.51512415  2.23743464 -2.12427904 -0.11653103  0.55388767 -2.77010897
  3.06858498  2.18960205  1.18551998 -1.06648308]. 
Training complete taking 619.8772675991058 seconds. 
Discarding model... 

Training complete taking 15663.796740055084 total seconds. 
Now scoring model... 
Scoring complete taking 2.312404155731201 seconds. 
Saved predicted values as A2-A2-CNOT_ESU2_predicted_values.csv
Model scores: {'MSE_train': (0.41742320468513816,), 'R2_train': 0.1688121306103002, 'MAE_train': 0.5503388090834523, 'MSE_test': 0.4974459654861807, 'R2_test': 0.07228070966163369, 'MAE_test': 0.6248984108958592}. 
Saved model results as A2-A2-CNOT_ESU2_results.json. 
