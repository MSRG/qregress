/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:37 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:58 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 21:40:02 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 21:42:30 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 21:44:34 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 21:46:57 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 671.8727185726166 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:49:08 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 21:51:13 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 21:53:26 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 21:55:30 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 21:57:55 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 655.5765030384064 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:00:03 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 22:02:08 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 22:04:23 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 22:06:27 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 22:08:52 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 655.6034235954285 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:11:01 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 22:13:05 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 22:15:21 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 22:17:26 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 22:19:51 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 658.8538014888763 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:21:59 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 22:24:04 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 22:26:21 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 22:28:28 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 22:30:56 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 667.9309306144714 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:33:06 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 22:35:55 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 22:38:12 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 22:40:18 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 22:42:53 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 715.2466042041779 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:45:03 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 22:47:07 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 22:49:22 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 22:51:26 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 22:53:52 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 658.7915604114532 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:56:02 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 22:58:06 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 23:00:22 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 23:02:28 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 23:04:55 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 675.0584635734558 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:07:15 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 23:09:21 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 23:11:48 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 23:13:53 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 23:16:19 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 670.9483654499054 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:18:28 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 23:20:31 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 23:22:45 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 23:25:07 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 23:27:36 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 678.7801175117493 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:29:45 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 23:31:53 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 23:34:18 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 23:36:26 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 23:38:51 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 673.2032630443573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:40:59 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 23:43:09 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 23:45:24 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 23:47:28 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Thu Apr  4 23:50:02 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 672.8568615913391 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:52:11 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Thu Apr  4 23:54:39 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Thu Apr  4 23:56:56 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Thu Apr  4 23:59:00 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 00:01:24 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 695.1162095069885 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:03:46 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 00:05:52 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 00:08:05 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 00:10:08 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 00:12:33 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 655.238847732544 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:14:41 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 00:16:44 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 00:18:58 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 00:21:03 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 00:23:28 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 655.5294487476349 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:25:38 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 00:27:42 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 00:29:57 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 00:32:02 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 00:34:26 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 655.945458650589 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:36:34 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 00:38:38 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 00:40:53 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 00:42:58 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 00:45:21 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 658.2564854621887 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:47:33 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 00:49:41 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 00:51:56 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 00:54:00 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 00:56:24 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 661.1328287124634 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:58:33 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 01:00:39 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 01:02:54 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 01:04:59 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 01:07:22 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 660.6207685470581 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:09:34 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 01:11:38 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 01:13:57 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 01:16:00 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 01:18:26 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 662.4323625564575 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:20:37 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 01:22:41 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 01:24:58 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 01:27:02 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 01:29:26 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 661.4698460102081 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:31:38 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 01:33:42 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 01:35:57 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 01:38:00 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 01:40:23 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 655.508706331253 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:42:34 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 01:44:38 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 01:47:01 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 01:49:04 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 01:51:28 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 663.968982219696 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:53:37 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 01:55:49 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 01:58:04 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 02:00:08 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 02:02:33 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 665.0195145606995 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:04:42 2024]  Iteration number: 0 with current cost as 0.1910035463516479 and parameters 
[-2.90318337  2.23743464 -2.12427964  0.65122559  0.20034135 -2.42865645
  3.0149585   2.35025855  1.18647558 -0.86404917  0.59218379  1.38676371
  1.10208059 -1.83866989  1.55288422]. 
Working on 0.4 fold... 
[Fri Apr  5 02:06:46 2024]  Iteration number: 0 with current cost as 0.21566213875992907 and parameters 
[-2.90318337  2.23743471 -2.12427956  0.66977801  0.13654663 -2.50812039
  3.01517818  2.37326225  1.17299613 -0.87353524  0.5464635   1.36095387
  1.10955126 -1.84996873  1.48737764]. 
Working on 0.6 fold... 
[Fri Apr  5 02:09:01 2024]  Iteration number: 0 with current cost as 0.21631975445777846 and parameters 
[-2.90318337  2.23743464 -2.12427971  0.68972381  0.14609466 -2.46950998
  3.01459434  2.3664024   1.17790935 -0.8799782   0.56643848  1.35937821
  1.11266236 -1.84644465  1.48955904]. 
Working on 0.8 fold... 
[Fri Apr  5 02:11:05 2024]  Iteration number: 0 with current cost as 0.18411913472429983 and parameters 
[-2.90318345  2.23743456 -2.12427964  0.62624538  0.17124345 -2.5042226
  3.01410187  2.37185839  1.17565098 -0.86510662  0.55442336  1.37367409
  1.08050891 -1.84431896  1.60501327]. 
Working on 1.0 fold... 
[Fri Apr  5 02:13:29 2024]  Iteration number: 0 with current cost as 0.193414909503206 and parameters 
[-2.90318345  2.23743464 -2.12427964  0.69063959  0.20805134 -2.37007364
  3.01238134  2.34651269  1.19305192 -0.84169573  0.61139719  1.41990554
  1.11779401 -1.83498458  1.51337368]. 
Training complete taking 655.5097754001617 seconds. 
Discarding model... 

Training complete taking 16660.47339606285 total seconds. 
Now scoring model... 
Scoring complete taking 1.1410436630249023 seconds. 
Saved predicted values as IQP_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (0.18129675078880902,), 'R2_train': 0.6389954886933225, 'MAE_train': 0.3586514294617157, 'MSE_test': 0.21231099853954527, 'R2_test': 0.6040474291441235, 'MAE_test': 0.41466555578376213}. 
Saved model results as IQP_HWE-CNOT_results.json. 
