/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:24:04 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:24:16 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:25:28 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:26:34 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:27:40 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:28:50 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 343.42079043388367 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:29:59 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:31:11 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:32:17 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:33:27 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:34:33 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 341.0964241027832 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:35:40 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:36:52 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:37:58 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:39:04 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:40:11 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 337.40599393844604 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:41:18 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:42:32 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:43:39 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:44:46 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:45:52 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 340.8680648803711 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:46:58 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:48:12 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:49:19 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:50:26 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:51:33 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 341.30353236198425 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:40 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:53:52 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:54:58 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:56:06 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:57:12 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 339.8789646625519 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:58:20 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:59:34 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:00:45 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:01:51 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:02:58 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 345.23431515693665 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:04:05 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:05:18 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:06:25 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:07:32 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:08:38 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 339.9238247871399 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:09:45 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:10:57 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:12:04 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:13:11 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:14:18 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 338.94545125961304 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:15:24 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:16:37 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:17:44 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:18:50 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:19:57 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 338.96235394477844 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:21:03 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:22:15 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:23:22 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:24:52 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:25:58 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 362.1067249774933 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:27:05 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:28:17 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:29:23 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:30:31 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:31:38 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 339.5944559574127 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:32:45 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:33:57 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:35:03 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:36:10 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:37:17 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 339.2370572090149 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:38:24 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:39:38 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:40:45 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:41:53 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:43:00 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 361.8453001976013 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:44:26 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:45:39 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:46:46 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:47:53 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:48:59 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 340.2340567111969 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:50:06 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:51:19 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:52:26 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:53:33 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:54:40 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 339.9760570526123 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:55:46 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:56:59 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:58:06 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:59:13 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:00:20 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 344.6512072086334 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:01:33 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:02:56 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:04:02 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:05:09 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:06:15 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 351.39580059051514 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:07:22 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:08:34 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:09:40 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:10:46 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:11:53 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 337.6186246871948 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:12:59 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:14:12 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:15:18 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:16:24 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:17:30 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 338.32597613334656 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:18:38 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:19:52 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:20:58 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:22:08 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:23:15 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 343.1510474681854 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:24:21 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:25:34 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:26:40 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:27:47 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:28:54 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 338.9759774208069 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:30:00 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:31:12 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:32:19 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:33:30 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:34:37 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 342.71527433395386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:35:43 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:36:55 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:38:01 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:39:07 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:40:14 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 338.33761191368103 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:41:21 2024]  Iteration number: 0 with current cost as 0.27558741309426393 and parameters 
[-3.05090272  2.10834595 -1.78400669 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:42:34 2024]  Iteration number: 0 with current cost as 0.2870589207883137 and parameters 
[-3.03775077  2.10216065 -1.8004186  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:43:40 2024]  Iteration number: 0 with current cost as 0.2704926156545777 and parameters 
[-3.04650158  2.09699673 -1.78221121 -0.11653103  0.55388708 -2.77010898
  3.06858499  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:44:46 2024]  Iteration number: 0 with current cost as 0.2846731136272589 and parameters 
[-3.0288877   2.11199582 -1.82247608 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:45:52 2024]  Iteration number: 0 with current cost as 0.284027460956468 and parameters 
[-3.03974421  2.11294282 -1.80566252 -0.11653103  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18551999 -1.06648308  0.6027151   1.14432446
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 337.2764985561371 seconds. 
Discarding model... 

Training complete taking 8562.48300242424 total seconds. 
Now scoring model... 
Scoring complete taking 0.8628354072570801 seconds. 
Saved predicted values as A2-A2-CNOT_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (0.3972320495510976,), 'R2_train': 0.20901747383993496, 'MAE_train': 0.5452952917115335, 'MSE_test': 0.45864980543394, 'R2_test': 0.1446341883682939, 'MAE_test': 0.5960471348299766}. 
Saved model results as A2-A2-CNOT_HWE-CZ_results.json. 
